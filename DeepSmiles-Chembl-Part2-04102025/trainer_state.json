{
  "best_global_step": 133000,
  "best_metric": 0.8670433759689331,
  "best_model_checkpoint": "./output_chempbl/fbdd_smiles/checkpoint-133000",
  "epoch": 11.350059737156512,
  "eval_steps": 1000,
  "global_step": 133000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008533879501621437,
      "grad_norm": 2.16137957572937,
      "learning_rate": 4.99715537349946e-05,
      "loss": 4.2717,
      "step": 100
    },
    {
      "epoch": 0.017067759003242873,
      "grad_norm": 2.373614549636841,
      "learning_rate": 4.994310746998919e-05,
      "loss": 3.6866,
      "step": 200
    },
    {
      "epoch": 0.025601638504864313,
      "grad_norm": 2.069648265838623,
      "learning_rate": 4.991466120498379e-05,
      "loss": 3.556,
      "step": 300
    },
    {
      "epoch": 0.034135518006485746,
      "grad_norm": 1.6923892498016357,
      "learning_rate": 4.988621493997838e-05,
      "loss": 3.4791,
      "step": 400
    },
    {
      "epoch": 0.042669397508107186,
      "grad_norm": 2.0084388256073,
      "learning_rate": 4.985776867497298e-05,
      "loss": 3.4073,
      "step": 500
    },
    {
      "epoch": 0.051203277009728626,
      "grad_norm": 2.369971513748169,
      "learning_rate": 4.982932240996757e-05,
      "loss": 3.3444,
      "step": 600
    },
    {
      "epoch": 0.05973715651135006,
      "grad_norm": 2.350560426712036,
      "learning_rate": 4.980087614496217e-05,
      "loss": 3.2632,
      "step": 700
    },
    {
      "epoch": 0.06827103601297149,
      "grad_norm": 2.87176251411438,
      "learning_rate": 4.977242987995677e-05,
      "loss": 3.1292,
      "step": 800
    },
    {
      "epoch": 0.07680491551459294,
      "grad_norm": 2.687894105911255,
      "learning_rate": 4.9743983614951365e-05,
      "loss": 2.8179,
      "step": 900
    },
    {
      "epoch": 0.08533879501621437,
      "grad_norm": 3.104512929916382,
      "learning_rate": 4.971553734994596e-05,
      "loss": 2.6509,
      "step": 1000
    },
    {
      "epoch": 0.08533879501621437,
      "eval_loss": 2.469109058380127,
      "eval_runtime": 64.4339,
      "eval_samples_per_second": 612.566,
      "eval_steps_per_second": 76.575,
      "step": 1000
    },
    {
      "epoch": 0.0938726745178358,
      "grad_norm": 2.77260160446167,
      "learning_rate": 4.968709108494055e-05,
      "loss": 2.5732,
      "step": 1100
    },
    {
      "epoch": 0.10240655401945725,
      "grad_norm": 3.270240545272827,
      "learning_rate": 4.965864481993514e-05,
      "loss": 2.4922,
      "step": 1200
    },
    {
      "epoch": 0.11094043352107869,
      "grad_norm": 2.5800423622131348,
      "learning_rate": 4.963019855492974e-05,
      "loss": 2.4321,
      "step": 1300
    },
    {
      "epoch": 0.11947431302270012,
      "grad_norm": 2.997586965560913,
      "learning_rate": 4.960175228992433e-05,
      "loss": 2.4038,
      "step": 1400
    },
    {
      "epoch": 0.12800819252432155,
      "grad_norm": 2.7718565464019775,
      "learning_rate": 4.957330602491893e-05,
      "loss": 2.3582,
      "step": 1500
    },
    {
      "epoch": 0.13654207202594298,
      "grad_norm": 2.5298163890838623,
      "learning_rate": 4.954485975991352e-05,
      "loss": 2.3249,
      "step": 1600
    },
    {
      "epoch": 0.14507595152756442,
      "grad_norm": 3.305227756500244,
      "learning_rate": 4.951641349490812e-05,
      "loss": 2.2995,
      "step": 1700
    },
    {
      "epoch": 0.15360983102918588,
      "grad_norm": 2.5757062435150146,
      "learning_rate": 4.9487967229902713e-05,
      "loss": 2.286,
      "step": 1800
    },
    {
      "epoch": 0.1621437105308073,
      "grad_norm": 3.0195679664611816,
      "learning_rate": 4.945952096489731e-05,
      "loss": 2.2318,
      "step": 1900
    },
    {
      "epoch": 0.17067759003242874,
      "grad_norm": 2.9286787509918213,
      "learning_rate": 4.9431074699891904e-05,
      "loss": 2.2318,
      "step": 2000
    },
    {
      "epoch": 0.17067759003242874,
      "eval_loss": 2.0236592292785645,
      "eval_runtime": 63.6784,
      "eval_samples_per_second": 619.834,
      "eval_steps_per_second": 77.483,
      "step": 2000
    },
    {
      "epoch": 0.17921146953405018,
      "grad_norm": 2.9860141277313232,
      "learning_rate": 4.94026284348865e-05,
      "loss": 2.2136,
      "step": 2100
    },
    {
      "epoch": 0.1877453490356716,
      "grad_norm": 2.5942599773406982,
      "learning_rate": 4.9374182169881094e-05,
      "loss": 2.1751,
      "step": 2200
    },
    {
      "epoch": 0.19627922853729304,
      "grad_norm": 2.863783359527588,
      "learning_rate": 4.934573590487569e-05,
      "loss": 2.1591,
      "step": 2300
    },
    {
      "epoch": 0.2048131080389145,
      "grad_norm": 3.404669761657715,
      "learning_rate": 4.931728963987029e-05,
      "loss": 2.1363,
      "step": 2400
    },
    {
      "epoch": 0.21334698754053594,
      "grad_norm": 3.4143176078796387,
      "learning_rate": 4.9288843374864886e-05,
      "loss": 2.1171,
      "step": 2500
    },
    {
      "epoch": 0.22188086704215737,
      "grad_norm": 2.9408822059631348,
      "learning_rate": 4.926039710985948e-05,
      "loss": 2.1003,
      "step": 2600
    },
    {
      "epoch": 0.2304147465437788,
      "grad_norm": 3.0595574378967285,
      "learning_rate": 4.9231950844854076e-05,
      "loss": 2.0879,
      "step": 2700
    },
    {
      "epoch": 0.23894862604540024,
      "grad_norm": 2.9504199028015137,
      "learning_rate": 4.920350457984867e-05,
      "loss": 2.0645,
      "step": 2800
    },
    {
      "epoch": 0.24748250554702167,
      "grad_norm": 2.803926467895508,
      "learning_rate": 4.9175058314843266e-05,
      "loss": 2.0452,
      "step": 2900
    },
    {
      "epoch": 0.2560163850486431,
      "grad_norm": 3.1208479404449463,
      "learning_rate": 4.914661204983786e-05,
      "loss": 2.0433,
      "step": 3000
    },
    {
      "epoch": 0.2560163850486431,
      "eval_loss": 1.8296740055084229,
      "eval_runtime": 63.114,
      "eval_samples_per_second": 625.377,
      "eval_steps_per_second": 78.176,
      "step": 3000
    },
    {
      "epoch": 0.26455026455026454,
      "grad_norm": 3.042544364929199,
      "learning_rate": 4.9118165784832456e-05,
      "loss": 2.0354,
      "step": 3100
    },
    {
      "epoch": 0.27308414405188597,
      "grad_norm": 3.096658229827881,
      "learning_rate": 4.908971951982705e-05,
      "loss": 1.9988,
      "step": 3200
    },
    {
      "epoch": 0.2816180235535074,
      "grad_norm": 3.1262238025665283,
      "learning_rate": 4.9061273254821646e-05,
      "loss": 1.9955,
      "step": 3300
    },
    {
      "epoch": 0.29015190305512883,
      "grad_norm": 2.9062325954437256,
      "learning_rate": 4.903282698981624e-05,
      "loss": 1.9952,
      "step": 3400
    },
    {
      "epoch": 0.2986857825567503,
      "grad_norm": 3.3791675567626953,
      "learning_rate": 4.9004380724810836e-05,
      "loss": 1.9746,
      "step": 3500
    },
    {
      "epoch": 0.30721966205837176,
      "grad_norm": 2.712261199951172,
      "learning_rate": 4.897593445980543e-05,
      "loss": 1.9577,
      "step": 3600
    },
    {
      "epoch": 0.3157535415599932,
      "grad_norm": 3.2296884059906006,
      "learning_rate": 4.8947488194800026e-05,
      "loss": 1.9472,
      "step": 3700
    },
    {
      "epoch": 0.3242874210616146,
      "grad_norm": 3.257575273513794,
      "learning_rate": 4.8919041929794615e-05,
      "loss": 1.9231,
      "step": 3800
    },
    {
      "epoch": 0.33282130056323606,
      "grad_norm": 3.247821569442749,
      "learning_rate": 4.8890595664789216e-05,
      "loss": 1.9405,
      "step": 3900
    },
    {
      "epoch": 0.3413551800648575,
      "grad_norm": 2.8556418418884277,
      "learning_rate": 4.886214939978381e-05,
      "loss": 1.9236,
      "step": 4000
    },
    {
      "epoch": 0.3413551800648575,
      "eval_loss": 1.7038090229034424,
      "eval_runtime": 63.8621,
      "eval_samples_per_second": 618.05,
      "eval_steps_per_second": 77.26,
      "step": 4000
    },
    {
      "epoch": 0.3498890595664789,
      "grad_norm": 3.2478830814361572,
      "learning_rate": 4.8833703134778407e-05,
      "loss": 1.9174,
      "step": 4100
    },
    {
      "epoch": 0.35842293906810035,
      "grad_norm": 2.993971586227417,
      "learning_rate": 4.8805256869773e-05,
      "loss": 1.8968,
      "step": 4200
    },
    {
      "epoch": 0.3669568185697218,
      "grad_norm": 3.502963066101074,
      "learning_rate": 4.87768106047676e-05,
      "loss": 1.8929,
      "step": 4300
    },
    {
      "epoch": 0.3754906980713432,
      "grad_norm": 2.5460944175720215,
      "learning_rate": 4.874836433976219e-05,
      "loss": 1.8843,
      "step": 4400
    },
    {
      "epoch": 0.38402457757296465,
      "grad_norm": 3.88651180267334,
      "learning_rate": 4.871991807475679e-05,
      "loss": 1.8659,
      "step": 4500
    },
    {
      "epoch": 0.3925584570745861,
      "grad_norm": 3.2556521892547607,
      "learning_rate": 4.869147180975138e-05,
      "loss": 1.8522,
      "step": 4600
    },
    {
      "epoch": 0.4010923365762075,
      "grad_norm": 3.2659547328948975,
      "learning_rate": 4.866302554474598e-05,
      "loss": 1.8625,
      "step": 4700
    },
    {
      "epoch": 0.409626216077829,
      "grad_norm": 3.0967862606048584,
      "learning_rate": 4.863457927974057e-05,
      "loss": 1.8518,
      "step": 4800
    },
    {
      "epoch": 0.41816009557945044,
      "grad_norm": 3.2160816192626953,
      "learning_rate": 4.860613301473517e-05,
      "loss": 1.8494,
      "step": 4900
    },
    {
      "epoch": 0.4266939750810719,
      "grad_norm": 2.69417405128479,
      "learning_rate": 4.857768674972976e-05,
      "loss": 1.8463,
      "step": 5000
    },
    {
      "epoch": 0.4266939750810719,
      "eval_loss": 1.624932885169983,
      "eval_runtime": 63.891,
      "eval_samples_per_second": 617.771,
      "eval_steps_per_second": 77.225,
      "step": 5000
    },
    {
      "epoch": 0.4352278545826933,
      "grad_norm": 3.0546436309814453,
      "learning_rate": 4.854924048472436e-05,
      "loss": 1.8331,
      "step": 5100
    },
    {
      "epoch": 0.44376173408431474,
      "grad_norm": 3.36678409576416,
      "learning_rate": 4.852079421971895e-05,
      "loss": 1.8244,
      "step": 5200
    },
    {
      "epoch": 0.4522956135859362,
      "grad_norm": 3.060981273651123,
      "learning_rate": 4.849234795471355e-05,
      "loss": 1.8228,
      "step": 5300
    },
    {
      "epoch": 0.4608294930875576,
      "grad_norm": 3.3355438709259033,
      "learning_rate": 4.846390168970814e-05,
      "loss": 1.8225,
      "step": 5400
    },
    {
      "epoch": 0.46936337258917904,
      "grad_norm": 3.210707902908325,
      "learning_rate": 4.8435455424702744e-05,
      "loss": 1.8019,
      "step": 5500
    },
    {
      "epoch": 0.4778972520908005,
      "grad_norm": 3.1938507556915283,
      "learning_rate": 4.840700915969734e-05,
      "loss": 1.8092,
      "step": 5600
    },
    {
      "epoch": 0.4864311315924219,
      "grad_norm": 2.8691213130950928,
      "learning_rate": 4.8378562894691934e-05,
      "loss": 1.7876,
      "step": 5700
    },
    {
      "epoch": 0.49496501109404334,
      "grad_norm": 3.4490768909454346,
      "learning_rate": 4.835011662968653e-05,
      "loss": 1.7795,
      "step": 5800
    },
    {
      "epoch": 0.5034988905956648,
      "grad_norm": 3.814077377319336,
      "learning_rate": 4.832167036468112e-05,
      "loss": 1.7795,
      "step": 5900
    },
    {
      "epoch": 0.5120327700972862,
      "grad_norm": 3.1894047260284424,
      "learning_rate": 4.829322409967571e-05,
      "loss": 1.7814,
      "step": 6000
    },
    {
      "epoch": 0.5120327700972862,
      "eval_loss": 1.566849708557129,
      "eval_runtime": 63.5973,
      "eval_samples_per_second": 620.623,
      "eval_steps_per_second": 77.582,
      "step": 6000
    },
    {
      "epoch": 0.5205666495989076,
      "grad_norm": 3.0303335189819336,
      "learning_rate": 4.826477783467031e-05,
      "loss": 1.7712,
      "step": 6100
    },
    {
      "epoch": 0.5291005291005291,
      "grad_norm": 3.5048575401306152,
      "learning_rate": 4.82363315696649e-05,
      "loss": 1.7437,
      "step": 6200
    },
    {
      "epoch": 0.5376344086021505,
      "grad_norm": 3.270599126815796,
      "learning_rate": 4.82078853046595e-05,
      "loss": 1.754,
      "step": 6300
    },
    {
      "epoch": 0.5461682881037719,
      "grad_norm": 3.210693120956421,
      "learning_rate": 4.817943903965409e-05,
      "loss": 1.7357,
      "step": 6400
    },
    {
      "epoch": 0.5547021676053934,
      "grad_norm": 3.4837963581085205,
      "learning_rate": 4.815099277464869e-05,
      "loss": 1.7594,
      "step": 6500
    },
    {
      "epoch": 0.5632360471070148,
      "grad_norm": 3.3115015029907227,
      "learning_rate": 4.812254650964328e-05,
      "loss": 1.7458,
      "step": 6600
    },
    {
      "epoch": 0.5717699266086362,
      "grad_norm": 3.316777229309082,
      "learning_rate": 4.809410024463788e-05,
      "loss": 1.761,
      "step": 6700
    },
    {
      "epoch": 0.5803038061102577,
      "grad_norm": 3.499178647994995,
      "learning_rate": 4.806565397963247e-05,
      "loss": 1.7443,
      "step": 6800
    },
    {
      "epoch": 0.5888376856118792,
      "grad_norm": 3.225656270980835,
      "learning_rate": 4.803720771462707e-05,
      "loss": 1.7206,
      "step": 6900
    },
    {
      "epoch": 0.5973715651135006,
      "grad_norm": 3.206437587738037,
      "learning_rate": 4.800876144962166e-05,
      "loss": 1.7231,
      "step": 7000
    },
    {
      "epoch": 0.5973715651135006,
      "eval_loss": 1.5115407705307007,
      "eval_runtime": 63.5722,
      "eval_samples_per_second": 620.869,
      "eval_steps_per_second": 77.613,
      "step": 7000
    },
    {
      "epoch": 0.6059054446151221,
      "grad_norm": 3.2703630924224854,
      "learning_rate": 4.7980315184616265e-05,
      "loss": 1.7286,
      "step": 7100
    },
    {
      "epoch": 0.6144393241167435,
      "grad_norm": 3.256101131439209,
      "learning_rate": 4.795186891961086e-05,
      "loss": 1.7182,
      "step": 7200
    },
    {
      "epoch": 0.622973203618365,
      "grad_norm": 3.195174217224121,
      "learning_rate": 4.7923422654605455e-05,
      "loss": 1.7111,
      "step": 7300
    },
    {
      "epoch": 0.6315070831199864,
      "grad_norm": 3.058039426803589,
      "learning_rate": 4.789497638960005e-05,
      "loss": 1.7132,
      "step": 7400
    },
    {
      "epoch": 0.6400409626216078,
      "grad_norm": 3.556474447250366,
      "learning_rate": 4.7866530124594645e-05,
      "loss": 1.7072,
      "step": 7500
    },
    {
      "epoch": 0.6485748421232292,
      "grad_norm": 2.964916944503784,
      "learning_rate": 4.783808385958924e-05,
      "loss": 1.6883,
      "step": 7600
    },
    {
      "epoch": 0.6571087216248507,
      "grad_norm": 3.138495445251465,
      "learning_rate": 4.7809637594583835e-05,
      "loss": 1.6918,
      "step": 7700
    },
    {
      "epoch": 0.6656426011264721,
      "grad_norm": 3.2276430130004883,
      "learning_rate": 4.778119132957843e-05,
      "loss": 1.7039,
      "step": 7800
    },
    {
      "epoch": 0.6741764806280935,
      "grad_norm": 2.7841544151306152,
      "learning_rate": 4.7752745064573026e-05,
      "loss": 1.6954,
      "step": 7900
    },
    {
      "epoch": 0.682710360129715,
      "grad_norm": 2.8654985427856445,
      "learning_rate": 4.772429879956762e-05,
      "loss": 1.6863,
      "step": 8000
    },
    {
      "epoch": 0.682710360129715,
      "eval_loss": 1.4627519845962524,
      "eval_runtime": 64.4096,
      "eval_samples_per_second": 612.796,
      "eval_steps_per_second": 76.603,
      "step": 8000
    },
    {
      "epoch": 0.6912442396313364,
      "grad_norm": 3.085723876953125,
      "learning_rate": 4.769613699721227e-05,
      "loss": 1.6839,
      "step": 8100
    },
    {
      "epoch": 0.6997781191329578,
      "grad_norm": 3.2271907329559326,
      "learning_rate": 4.766769073220687e-05,
      "loss": 1.6821,
      "step": 8200
    },
    {
      "epoch": 0.7083119986345793,
      "grad_norm": 3.349047899246216,
      "learning_rate": 4.763924446720146e-05,
      "loss": 1.6712,
      "step": 8300
    },
    {
      "epoch": 0.7168458781362007,
      "grad_norm": 3.196500778198242,
      "learning_rate": 4.761079820219606e-05,
      "loss": 1.6677,
      "step": 8400
    },
    {
      "epoch": 0.7253797576378221,
      "grad_norm": 3.51436185836792,
      "learning_rate": 4.758235193719065e-05,
      "loss": 1.6586,
      "step": 8500
    },
    {
      "epoch": 0.7339136371394436,
      "grad_norm": 3.421048879623413,
      "learning_rate": 4.755390567218525e-05,
      "loss": 1.6487,
      "step": 8600
    },
    {
      "epoch": 0.742447516641065,
      "grad_norm": 3.7807774543762207,
      "learning_rate": 4.752545940717984e-05,
      "loss": 1.6681,
      "step": 8700
    },
    {
      "epoch": 0.7509813961426864,
      "grad_norm": 3.488136053085327,
      "learning_rate": 4.749701314217444e-05,
      "loss": 1.6565,
      "step": 8800
    },
    {
      "epoch": 0.7595152756443079,
      "grad_norm": 3.298933744430542,
      "learning_rate": 4.7468566877169026e-05,
      "loss": 1.6517,
      "step": 8900
    },
    {
      "epoch": 0.7680491551459293,
      "grad_norm": 3.0142548084259033,
      "learning_rate": 4.744012061216362e-05,
      "loss": 1.6638,
      "step": 9000
    },
    {
      "epoch": 0.7680491551459293,
      "eval_loss": 1.4350947141647339,
      "eval_runtime": 63.2711,
      "eval_samples_per_second": 623.823,
      "eval_steps_per_second": 77.982,
      "step": 9000
    },
    {
      "epoch": 0.7765830346475507,
      "grad_norm": 3.1789298057556152,
      "learning_rate": 4.7411674347158216e-05,
      "loss": 1.6554,
      "step": 9100
    },
    {
      "epoch": 0.7851169141491722,
      "grad_norm": 2.9562501907348633,
      "learning_rate": 4.738322808215281e-05,
      "loss": 1.637,
      "step": 9200
    },
    {
      "epoch": 0.7936507936507936,
      "grad_norm": 3.069180488586426,
      "learning_rate": 4.7354781817147406e-05,
      "loss": 1.6472,
      "step": 9300
    },
    {
      "epoch": 0.802184673152415,
      "grad_norm": 3.335319757461548,
      "learning_rate": 4.7326335552142e-05,
      "loss": 1.6382,
      "step": 9400
    },
    {
      "epoch": 0.8107185526540365,
      "grad_norm": 3.1301233768463135,
      "learning_rate": 4.7297889287136596e-05,
      "loss": 1.6239,
      "step": 9500
    },
    {
      "epoch": 0.819252432155658,
      "grad_norm": 3.5391829013824463,
      "learning_rate": 4.72694430221312e-05,
      "loss": 1.6242,
      "step": 9600
    },
    {
      "epoch": 0.8277863116572794,
      "grad_norm": 3.4614017009735107,
      "learning_rate": 4.724099675712579e-05,
      "loss": 1.6224,
      "step": 9700
    },
    {
      "epoch": 0.8363201911589009,
      "grad_norm": 3.1839659214019775,
      "learning_rate": 4.721255049212039e-05,
      "loss": 1.6327,
      "step": 9800
    },
    {
      "epoch": 0.8448540706605223,
      "grad_norm": 3.6031978130340576,
      "learning_rate": 4.7184104227114983e-05,
      "loss": 1.62,
      "step": 9900
    },
    {
      "epoch": 0.8533879501621437,
      "grad_norm": 3.0043349266052246,
      "learning_rate": 4.715565796210958e-05,
      "loss": 1.6352,
      "step": 10000
    },
    {
      "epoch": 0.8533879501621437,
      "eval_loss": 1.4043227434158325,
      "eval_runtime": 62.9648,
      "eval_samples_per_second": 626.858,
      "eval_steps_per_second": 78.361,
      "step": 10000
    },
    {
      "epoch": 0.8619218296637652,
      "grad_norm": 3.21519136428833,
      "learning_rate": 4.7127496159754224e-05,
      "loss": 1.608,
      "step": 10100
    },
    {
      "epoch": 0.8704557091653866,
      "grad_norm": 3.069328546524048,
      "learning_rate": 4.709904989474882e-05,
      "loss": 1.6127,
      "step": 10200
    },
    {
      "epoch": 0.878989588667008,
      "grad_norm": 3.174375534057617,
      "learning_rate": 4.7070603629743414e-05,
      "loss": 1.6081,
      "step": 10300
    },
    {
      "epoch": 0.8875234681686295,
      "grad_norm": 3.336677074432373,
      "learning_rate": 4.704215736473801e-05,
      "loss": 1.5896,
      "step": 10400
    },
    {
      "epoch": 0.8960573476702509,
      "grad_norm": 3.356264352798462,
      "learning_rate": 4.7013711099732604e-05,
      "loss": 1.6073,
      "step": 10500
    },
    {
      "epoch": 0.9045912271718723,
      "grad_norm": 3.4123449325561523,
      "learning_rate": 4.6985264834727206e-05,
      "loss": 1.5997,
      "step": 10600
    },
    {
      "epoch": 0.9131251066734938,
      "grad_norm": 3.6641292572021484,
      "learning_rate": 4.69568185697218e-05,
      "loss": 1.5861,
      "step": 10700
    },
    {
      "epoch": 0.9216589861751152,
      "grad_norm": 3.075258493423462,
      "learning_rate": 4.6928372304716396e-05,
      "loss": 1.592,
      "step": 10800
    },
    {
      "epoch": 0.9301928656767366,
      "grad_norm": 3.62125563621521,
      "learning_rate": 4.689992603971099e-05,
      "loss": 1.5863,
      "step": 10900
    },
    {
      "epoch": 0.9387267451783581,
      "grad_norm": 3.4440369606018066,
      "learning_rate": 4.6871479774705586e-05,
      "loss": 1.5796,
      "step": 11000
    },
    {
      "epoch": 0.9387267451783581,
      "eval_loss": 1.3748810291290283,
      "eval_runtime": 63.5574,
      "eval_samples_per_second": 621.014,
      "eval_steps_per_second": 77.631,
      "step": 11000
    },
    {
      "epoch": 0.9472606246799795,
      "grad_norm": 3.297356367111206,
      "learning_rate": 4.684303350970018e-05,
      "loss": 1.5875,
      "step": 11100
    },
    {
      "epoch": 0.955794504181601,
      "grad_norm": 3.4222593307495117,
      "learning_rate": 4.6814587244694776e-05,
      "loss": 1.5804,
      "step": 11200
    },
    {
      "epoch": 0.9643283836832224,
      "grad_norm": 3.175448417663574,
      "learning_rate": 4.678614097968937e-05,
      "loss": 1.5688,
      "step": 11300
    },
    {
      "epoch": 0.9728622631848438,
      "grad_norm": 3.513543128967285,
      "learning_rate": 4.6757694714683966e-05,
      "loss": 1.5887,
      "step": 11400
    },
    {
      "epoch": 0.9813961426864652,
      "grad_norm": 3.0594751834869385,
      "learning_rate": 4.672924844967856e-05,
      "loss": 1.5775,
      "step": 11500
    },
    {
      "epoch": 0.9899300221880867,
      "grad_norm": 3.1217539310455322,
      "learning_rate": 4.6700802184673156e-05,
      "loss": 1.5919,
      "step": 11600
    },
    {
      "epoch": 0.9984639016897081,
      "grad_norm": 3.251706123352051,
      "learning_rate": 4.667235591966775e-05,
      "loss": 1.5799,
      "step": 11700
    },
    {
      "epoch": 1.0069977811913295,
      "grad_norm": 3.192302942276001,
      "learning_rate": 4.6643909654662346e-05,
      "loss": 1.5581,
      "step": 11800
    },
    {
      "epoch": 1.015531660692951,
      "grad_norm": 3.4043779373168945,
      "learning_rate": 4.661546338965694e-05,
      "loss": 1.5834,
      "step": 11900
    },
    {
      "epoch": 1.0240655401945724,
      "grad_norm": 3.476945638656616,
      "learning_rate": 4.658701712465153e-05,
      "loss": 1.5627,
      "step": 12000
    },
    {
      "epoch": 1.0240655401945724,
      "eval_loss": 1.3721917867660522,
      "eval_runtime": 63.4795,
      "eval_samples_per_second": 621.775,
      "eval_steps_per_second": 77.726,
      "step": 12000
    },
    {
      "epoch": 1.0325994196961938,
      "grad_norm": 3.3332278728485107,
      "learning_rate": 4.655885532229619e-05,
      "loss": 1.576,
      "step": 12100
    },
    {
      "epoch": 1.0411332991978153,
      "grad_norm": 3.6172919273376465,
      "learning_rate": 4.653040905729078e-05,
      "loss": 1.563,
      "step": 12200
    },
    {
      "epoch": 1.0496671786994367,
      "grad_norm": 3.2108874320983887,
      "learning_rate": 4.650196279228538e-05,
      "loss": 1.5637,
      "step": 12300
    },
    {
      "epoch": 1.0582010582010581,
      "grad_norm": 3.3561108112335205,
      "learning_rate": 4.6473516527279967e-05,
      "loss": 1.5566,
      "step": 12400
    },
    {
      "epoch": 1.0667349377026796,
      "grad_norm": 3.3403167724609375,
      "learning_rate": 4.644507026227456e-05,
      "loss": 1.5639,
      "step": 12500
    },
    {
      "epoch": 1.075268817204301,
      "grad_norm": 3.305147409439087,
      "learning_rate": 4.641662399726916e-05,
      "loss": 1.5485,
      "step": 12600
    },
    {
      "epoch": 1.0838026967059224,
      "grad_norm": 3.263017177581787,
      "learning_rate": 4.638817773226375e-05,
      "loss": 1.5449,
      "step": 12700
    },
    {
      "epoch": 1.0923365762075439,
      "grad_norm": 3.373403310775757,
      "learning_rate": 4.635973146725835e-05,
      "loss": 1.5463,
      "step": 12800
    },
    {
      "epoch": 1.1008704557091653,
      "grad_norm": 3.2604169845581055,
      "learning_rate": 4.633128520225294e-05,
      "loss": 1.5482,
      "step": 12900
    },
    {
      "epoch": 1.1094043352107867,
      "grad_norm": 3.0406901836395264,
      "learning_rate": 4.630283893724754e-05,
      "loss": 1.5538,
      "step": 13000
    },
    {
      "epoch": 1.1094043352107867,
      "eval_loss": 1.3325347900390625,
      "eval_runtime": 63.6093,
      "eval_samples_per_second": 620.507,
      "eval_steps_per_second": 77.567,
      "step": 13000
    },
    {
      "epoch": 1.1179382147124082,
      "grad_norm": 3.1187498569488525,
      "learning_rate": 4.627439267224214e-05,
      "loss": 1.5295,
      "step": 13100
    },
    {
      "epoch": 1.1264720942140296,
      "grad_norm": 3.3558123111724854,
      "learning_rate": 4.6245946407236734e-05,
      "loss": 1.5366,
      "step": 13200
    },
    {
      "epoch": 1.135005973715651,
      "grad_norm": 3.3772919178009033,
      "learning_rate": 4.621750014223133e-05,
      "loss": 1.5296,
      "step": 13300
    },
    {
      "epoch": 1.1435398532172725,
      "grad_norm": 3.842897891998291,
      "learning_rate": 4.6189053877225924e-05,
      "loss": 1.5282,
      "step": 13400
    },
    {
      "epoch": 1.1520737327188941,
      "grad_norm": 3.215423107147217,
      "learning_rate": 4.616060761222052e-05,
      "loss": 1.5421,
      "step": 13500
    },
    {
      "epoch": 1.1606076122205153,
      "grad_norm": 3.6885340213775635,
      "learning_rate": 4.6132161347215114e-05,
      "loss": 1.5259,
      "step": 13600
    },
    {
      "epoch": 1.169141491722137,
      "grad_norm": 3.1933839321136475,
      "learning_rate": 4.610371508220971e-05,
      "loss": 1.5312,
      "step": 13700
    },
    {
      "epoch": 1.1776753712237582,
      "grad_norm": 3.551806926727295,
      "learning_rate": 4.6075268817204304e-05,
      "loss": 1.5172,
      "step": 13800
    },
    {
      "epoch": 1.1862092507253799,
      "grad_norm": 3.173959970474243,
      "learning_rate": 4.60468225521989e-05,
      "loss": 1.521,
      "step": 13900
    },
    {
      "epoch": 1.194743130227001,
      "grad_norm": 3.2784039974212646,
      "learning_rate": 4.6018376287193494e-05,
      "loss": 1.5216,
      "step": 14000
    },
    {
      "epoch": 1.194743130227001,
      "eval_loss": 1.3108415603637695,
      "eval_runtime": 63.2576,
      "eval_samples_per_second": 623.956,
      "eval_steps_per_second": 77.998,
      "step": 14000
    },
    {
      "epoch": 1.2032770097286227,
      "grad_norm": 3.4983649253845215,
      "learning_rate": 4.5990214484838146e-05,
      "loss": 1.5261,
      "step": 14100
    },
    {
      "epoch": 1.2118108892302442,
      "grad_norm": 3.119891405105591,
      "learning_rate": 4.596176821983274e-05,
      "loss": 1.5126,
      "step": 14200
    },
    {
      "epoch": 1.2203447687318656,
      "grad_norm": 3.396480083465576,
      "learning_rate": 4.5933321954827336e-05,
      "loss": 1.517,
      "step": 14300
    },
    {
      "epoch": 1.228878648233487,
      "grad_norm": 3.2655622959136963,
      "learning_rate": 4.590487568982193e-05,
      "loss": 1.5279,
      "step": 14400
    },
    {
      "epoch": 1.2374125277351085,
      "grad_norm": 3.251757860183716,
      "learning_rate": 4.5876429424816526e-05,
      "loss": 1.4994,
      "step": 14500
    },
    {
      "epoch": 1.24594640723673,
      "grad_norm": 3.0978574752807617,
      "learning_rate": 4.584798315981112e-05,
      "loss": 1.5079,
      "step": 14600
    },
    {
      "epoch": 1.2544802867383513,
      "grad_norm": 3.4954240322113037,
      "learning_rate": 4.5819536894805716e-05,
      "loss": 1.4955,
      "step": 14700
    },
    {
      "epoch": 1.2630141662399728,
      "grad_norm": 3.3590011596679688,
      "learning_rate": 4.579109062980031e-05,
      "loss": 1.5056,
      "step": 14800
    },
    {
      "epoch": 1.2715480457415942,
      "grad_norm": 3.1207797527313232,
      "learning_rate": 4.5762644364794907e-05,
      "loss": 1.5175,
      "step": 14900
    },
    {
      "epoch": 1.2800819252432156,
      "grad_norm": 3.3555006980895996,
      "learning_rate": 4.57341980997895e-05,
      "loss": 1.5138,
      "step": 15000
    },
    {
      "epoch": 1.2800819252432156,
      "eval_loss": 1.2987644672393799,
      "eval_runtime": 63.9641,
      "eval_samples_per_second": 617.065,
      "eval_steps_per_second": 77.137,
      "step": 15000
    },
    {
      "epoch": 1.288615804744837,
      "grad_norm": 3.384371042251587,
      "learning_rate": 4.57057518347841e-05,
      "loss": 1.4948,
      "step": 15100
    },
    {
      "epoch": 1.2971496842464585,
      "grad_norm": 3.3514716625213623,
      "learning_rate": 4.567730556977869e-05,
      "loss": 1.5049,
      "step": 15200
    },
    {
      "epoch": 1.30568356374808,
      "grad_norm": 3.201160192489624,
      "learning_rate": 4.564885930477329e-05,
      "loss": 1.4914,
      "step": 15300
    },
    {
      "epoch": 1.3142174432497014,
      "grad_norm": 3.7157909870147705,
      "learning_rate": 4.562041303976788e-05,
      "loss": 1.4801,
      "step": 15400
    },
    {
      "epoch": 1.3227513227513228,
      "grad_norm": 3.415785551071167,
      "learning_rate": 4.559196677476247e-05,
      "loss": 1.5004,
      "step": 15500
    },
    {
      "epoch": 1.3312852022529442,
      "grad_norm": 3.709604501724243,
      "learning_rate": 4.5563520509757065e-05,
      "loss": 1.5013,
      "step": 15600
    },
    {
      "epoch": 1.3398190817545657,
      "grad_norm": 3.5308690071105957,
      "learning_rate": 4.553507424475167e-05,
      "loss": 1.49,
      "step": 15700
    },
    {
      "epoch": 1.348352961256187,
      "grad_norm": 3.2748076915740967,
      "learning_rate": 4.550662797974626e-05,
      "loss": 1.4988,
      "step": 15800
    },
    {
      "epoch": 1.3568868407578085,
      "grad_norm": 3.4235079288482666,
      "learning_rate": 4.547818171474086e-05,
      "loss": 1.4996,
      "step": 15900
    },
    {
      "epoch": 1.36542072025943,
      "grad_norm": 3.339237928390503,
      "learning_rate": 4.544973544973545e-05,
      "loss": 1.4987,
      "step": 16000
    },
    {
      "epoch": 1.36542072025943,
      "eval_loss": 1.2742325067520142,
      "eval_runtime": 66.8946,
      "eval_samples_per_second": 590.033,
      "eval_steps_per_second": 73.758,
      "step": 16000
    },
    {
      "epoch": 1.3739545997610514,
      "grad_norm": 3.5963850021362305,
      "learning_rate": 4.54215736473801e-05,
      "loss": 1.4856,
      "step": 16100
    },
    {
      "epoch": 1.3824884792626728,
      "grad_norm": 3.2588958740234375,
      "learning_rate": 4.539312738237469e-05,
      "loss": 1.4734,
      "step": 16200
    },
    {
      "epoch": 1.3910223587642943,
      "grad_norm": 3.0998692512512207,
      "learning_rate": 4.536468111736929e-05,
      "loss": 1.4769,
      "step": 16300
    },
    {
      "epoch": 1.3995562382659157,
      "grad_norm": 3.395703077316284,
      "learning_rate": 4.533623485236388e-05,
      "loss": 1.4893,
      "step": 16400
    },
    {
      "epoch": 1.4080901177675371,
      "grad_norm": 3.724271297454834,
      "learning_rate": 4.530778858735848e-05,
      "loss": 1.4865,
      "step": 16500
    },
    {
      "epoch": 1.4166239972691586,
      "grad_norm": 3.2629144191741943,
      "learning_rate": 4.527934232235308e-05,
      "loss": 1.484,
      "step": 16600
    },
    {
      "epoch": 1.42515787677078,
      "grad_norm": 2.951118230819702,
      "learning_rate": 4.5250896057347674e-05,
      "loss": 1.4746,
      "step": 16700
    },
    {
      "epoch": 1.4336917562724014,
      "grad_norm": 4.065720558166504,
      "learning_rate": 4.522244979234227e-05,
      "loss": 1.4825,
      "step": 16800
    },
    {
      "epoch": 1.4422256357740229,
      "grad_norm": 3.3477511405944824,
      "learning_rate": 4.5194003527336864e-05,
      "loss": 1.4814,
      "step": 16900
    },
    {
      "epoch": 1.4507595152756443,
      "grad_norm": 3.36088490486145,
      "learning_rate": 4.516555726233146e-05,
      "loss": 1.4893,
      "step": 17000
    },
    {
      "epoch": 1.4507595152756443,
      "eval_loss": 1.2687429189682007,
      "eval_runtime": 64.162,
      "eval_samples_per_second": 615.162,
      "eval_steps_per_second": 76.899,
      "step": 17000
    },
    {
      "epoch": 1.4592933947772657,
      "grad_norm": 3.3160574436187744,
      "learning_rate": 4.5137110997326055e-05,
      "loss": 1.4652,
      "step": 17100
    },
    {
      "epoch": 1.4678272742788872,
      "grad_norm": 3.3752758502960205,
      "learning_rate": 4.510866473232065e-05,
      "loss": 1.4626,
      "step": 17200
    },
    {
      "epoch": 1.4763611537805086,
      "grad_norm": 3.2189650535583496,
      "learning_rate": 4.5080218467315245e-05,
      "loss": 1.4631,
      "step": 17300
    },
    {
      "epoch": 1.48489503328213,
      "grad_norm": 3.21079158782959,
      "learning_rate": 4.505177220230984e-05,
      "loss": 1.4665,
      "step": 17400
    },
    {
      "epoch": 1.4934289127837514,
      "grad_norm": 3.1870410442352295,
      "learning_rate": 4.5023325937304435e-05,
      "loss": 1.4695,
      "step": 17500
    },
    {
      "epoch": 1.5019627922853729,
      "grad_norm": 3.320732355117798,
      "learning_rate": 4.499487967229903e-05,
      "loss": 1.4481,
      "step": 17600
    },
    {
      "epoch": 1.5104966717869943,
      "grad_norm": 3.3345139026641846,
      "learning_rate": 4.4966433407293625e-05,
      "loss": 1.4535,
      "step": 17700
    },
    {
      "epoch": 1.519030551288616,
      "grad_norm": 2.9612832069396973,
      "learning_rate": 4.493798714228822e-05,
      "loss": 1.4667,
      "step": 17800
    },
    {
      "epoch": 1.5275644307902372,
      "grad_norm": 3.022340774536133,
      "learning_rate": 4.4909540877282815e-05,
      "loss": 1.4811,
      "step": 17900
    },
    {
      "epoch": 1.5360983102918588,
      "grad_norm": 3.176027774810791,
      "learning_rate": 4.488109461227741e-05,
      "loss": 1.4534,
      "step": 18000
    },
    {
      "epoch": 1.5360983102918588,
      "eval_loss": 1.2554975748062134,
      "eval_runtime": 63.8472,
      "eval_samples_per_second": 618.195,
      "eval_steps_per_second": 77.278,
      "step": 18000
    },
    {
      "epoch": 1.54463218979348,
      "grad_norm": 3.352513074874878,
      "learning_rate": 4.485293280992206e-05,
      "loss": 1.4655,
      "step": 18100
    },
    {
      "epoch": 1.5531660692951017,
      "grad_norm": 3.293142318725586,
      "learning_rate": 4.482448654491666e-05,
      "loss": 1.463,
      "step": 18200
    },
    {
      "epoch": 1.561699948796723,
      "grad_norm": 3.210014581680298,
      "learning_rate": 4.479604027991125e-05,
      "loss": 1.463,
      "step": 18300
    },
    {
      "epoch": 1.5702338282983446,
      "grad_norm": 3.2145578861236572,
      "learning_rate": 4.476759401490585e-05,
      "loss": 1.4528,
      "step": 18400
    },
    {
      "epoch": 1.5787677077999658,
      "grad_norm": 3.7585771083831787,
      "learning_rate": 4.473914774990044e-05,
      "loss": 1.4504,
      "step": 18500
    },
    {
      "epoch": 1.5873015873015874,
      "grad_norm": 3.103877305984497,
      "learning_rate": 4.471070148489504e-05,
      "loss": 1.4383,
      "step": 18600
    },
    {
      "epoch": 1.5958354668032086,
      "grad_norm": 3.0417096614837646,
      "learning_rate": 4.468225521988963e-05,
      "loss": 1.4544,
      "step": 18700
    },
    {
      "epoch": 1.6043693463048303,
      "grad_norm": 3.1928019523620605,
      "learning_rate": 4.465380895488423e-05,
      "loss": 1.4498,
      "step": 18800
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 3.13789963722229,
      "learning_rate": 4.462536268987882e-05,
      "loss": 1.4514,
      "step": 18900
    },
    {
      "epoch": 1.6214371053080732,
      "grad_norm": 3.245657205581665,
      "learning_rate": 4.459691642487341e-05,
      "loss": 1.4458,
      "step": 19000
    },
    {
      "epoch": 1.6214371053080732,
      "eval_loss": 1.236750602722168,
      "eval_runtime": 64.247,
      "eval_samples_per_second": 614.348,
      "eval_steps_per_second": 76.797,
      "step": 19000
    },
    {
      "epoch": 1.6299709848096944,
      "grad_norm": 3.4813106060028076,
      "learning_rate": 4.4568470159868006e-05,
      "loss": 1.4579,
      "step": 19100
    },
    {
      "epoch": 1.638504864311316,
      "grad_norm": 3.128736972808838,
      "learning_rate": 4.454002389486261e-05,
      "loss": 1.4409,
      "step": 19200
    },
    {
      "epoch": 1.6470387438129372,
      "grad_norm": 3.4435505867004395,
      "learning_rate": 4.45115776298572e-05,
      "loss": 1.4458,
      "step": 19300
    },
    {
      "epoch": 1.655572623314559,
      "grad_norm": 3.308894395828247,
      "learning_rate": 4.44831313648518e-05,
      "loss": 1.4459,
      "step": 19400
    },
    {
      "epoch": 1.66410650281618,
      "grad_norm": 3.6296095848083496,
      "learning_rate": 4.445468509984639e-05,
      "loss": 1.4323,
      "step": 19500
    },
    {
      "epoch": 1.6726403823178018,
      "grad_norm": 3.354663372039795,
      "learning_rate": 4.442623883484099e-05,
      "loss": 1.4406,
      "step": 19600
    },
    {
      "epoch": 1.681174261819423,
      "grad_norm": 3.9035634994506836,
      "learning_rate": 4.439779256983558e-05,
      "loss": 1.4306,
      "step": 19700
    },
    {
      "epoch": 1.6897081413210446,
      "grad_norm": 3.6979825496673584,
      "learning_rate": 4.436934630483018e-05,
      "loss": 1.4327,
      "step": 19800
    },
    {
      "epoch": 1.6982420208226658,
      "grad_norm": 3.4592108726501465,
      "learning_rate": 4.434090003982477e-05,
      "loss": 1.4281,
      "step": 19900
    },
    {
      "epoch": 1.7067759003242875,
      "grad_norm": 3.2102880477905273,
      "learning_rate": 4.431245377481937e-05,
      "loss": 1.4367,
      "step": 20000
    },
    {
      "epoch": 1.7067759003242875,
      "eval_loss": 1.2210134267807007,
      "eval_runtime": 63.9332,
      "eval_samples_per_second": 617.364,
      "eval_steps_per_second": 77.174,
      "step": 20000
    },
    {
      "epoch": 1.7153097798259087,
      "grad_norm": 4.0875563621521,
      "learning_rate": 4.428429197246401e-05,
      "loss": 1.4456,
      "step": 20100
    },
    {
      "epoch": 1.7238436593275304,
      "grad_norm": 3.6081936359405518,
      "learning_rate": 4.4255845707458615e-05,
      "loss": 1.4493,
      "step": 20200
    },
    {
      "epoch": 1.7323775388291516,
      "grad_norm": 3.484161615371704,
      "learning_rate": 4.422739944245321e-05,
      "loss": 1.4305,
      "step": 20300
    },
    {
      "epoch": 1.7409114183307732,
      "grad_norm": 3.3488810062408447,
      "learning_rate": 4.4198953177447805e-05,
      "loss": 1.4305,
      "step": 20400
    },
    {
      "epoch": 1.7494452978323944,
      "grad_norm": 3.6035256385803223,
      "learning_rate": 4.41705069124424e-05,
      "loss": 1.4245,
      "step": 20500
    },
    {
      "epoch": 1.757979177334016,
      "grad_norm": 3.5478761196136475,
      "learning_rate": 4.4142060647436995e-05,
      "loss": 1.4415,
      "step": 20600
    },
    {
      "epoch": 1.7665130568356375,
      "grad_norm": 3.3313751220703125,
      "learning_rate": 4.411361438243159e-05,
      "loss": 1.4226,
      "step": 20700
    },
    {
      "epoch": 1.775046936337259,
      "grad_norm": 3.2933928966522217,
      "learning_rate": 4.4085168117426185e-05,
      "loss": 1.4275,
      "step": 20800
    },
    {
      "epoch": 1.7835808158388804,
      "grad_norm": 2.9732632637023926,
      "learning_rate": 4.405672185242078e-05,
      "loss": 1.4345,
      "step": 20900
    },
    {
      "epoch": 1.7921146953405018,
      "grad_norm": 3.0023512840270996,
      "learning_rate": 4.4028275587415375e-05,
      "loss": 1.4216,
      "step": 21000
    },
    {
      "epoch": 1.7921146953405018,
      "eval_loss": 1.2132827043533325,
      "eval_runtime": 63.5641,
      "eval_samples_per_second": 620.948,
      "eval_steps_per_second": 77.622,
      "step": 21000
    },
    {
      "epoch": 1.8006485748421233,
      "grad_norm": 3.3774847984313965,
      "learning_rate": 4.399982932240997e-05,
      "loss": 1.4348,
      "step": 21100
    },
    {
      "epoch": 1.8091824543437447,
      "grad_norm": 3.2223496437072754,
      "learning_rate": 4.3971383057404565e-05,
      "loss": 1.4161,
      "step": 21200
    },
    {
      "epoch": 1.8177163338453661,
      "grad_norm": 3.5767080783843994,
      "learning_rate": 4.394293679239916e-05,
      "loss": 1.4155,
      "step": 21300
    },
    {
      "epoch": 1.8262502133469876,
      "grad_norm": 3.4599032402038574,
      "learning_rate": 4.3914490527393755e-05,
      "loss": 1.4152,
      "step": 21400
    },
    {
      "epoch": 1.834784092848609,
      "grad_norm": 3.4529359340667725,
      "learning_rate": 4.388604426238835e-05,
      "loss": 1.4177,
      "step": 21500
    },
    {
      "epoch": 1.8433179723502304,
      "grad_norm": 3.8541078567504883,
      "learning_rate": 4.3857597997382946e-05,
      "loss": 1.4195,
      "step": 21600
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 3.155611515045166,
      "learning_rate": 4.382915173237754e-05,
      "loss": 1.4035,
      "step": 21700
    },
    {
      "epoch": 1.8603857313534733,
      "grad_norm": 3.384448766708374,
      "learning_rate": 4.3800705467372136e-05,
      "loss": 1.406,
      "step": 21800
    },
    {
      "epoch": 1.8689196108550947,
      "grad_norm": 3.905989646911621,
      "learning_rate": 4.377225920236673e-05,
      "loss": 1.4061,
      "step": 21900
    },
    {
      "epoch": 1.8774534903567162,
      "grad_norm": 3.3943333625793457,
      "learning_rate": 4.3743812937361326e-05,
      "loss": 1.4093,
      "step": 22000
    },
    {
      "epoch": 1.8774534903567162,
      "eval_loss": 1.20557701587677,
      "eval_runtime": 63.9735,
      "eval_samples_per_second": 616.974,
      "eval_steps_per_second": 77.126,
      "step": 22000
    },
    {
      "epoch": 1.8859873698583376,
      "grad_norm": 3.34073543548584,
      "learning_rate": 4.371565113500598e-05,
      "loss": 1.417,
      "step": 22100
    },
    {
      "epoch": 1.894521249359959,
      "grad_norm": 3.54538893699646,
      "learning_rate": 4.368720487000057e-05,
      "loss": 1.407,
      "step": 22200
    },
    {
      "epoch": 1.9030551288615805,
      "grad_norm": 3.145970344543457,
      "learning_rate": 4.365875860499517e-05,
      "loss": 1.4274,
      "step": 22300
    },
    {
      "epoch": 1.911589008363202,
      "grad_norm": 3.490968704223633,
      "learning_rate": 4.363031233998976e-05,
      "loss": 1.3918,
      "step": 22400
    },
    {
      "epoch": 1.9201228878648233,
      "grad_norm": 3.449810266494751,
      "learning_rate": 4.360186607498435e-05,
      "loss": 1.4058,
      "step": 22500
    },
    {
      "epoch": 1.9286567673664448,
      "grad_norm": 3.099680185317993,
      "learning_rate": 4.3573419809978946e-05,
      "loss": 1.402,
      "step": 22600
    },
    {
      "epoch": 1.9371906468680662,
      "grad_norm": 3.334333658218384,
      "learning_rate": 4.354497354497355e-05,
      "loss": 1.4037,
      "step": 22700
    },
    {
      "epoch": 1.9457245263696876,
      "grad_norm": 3.4019153118133545,
      "learning_rate": 4.351652727996814e-05,
      "loss": 1.391,
      "step": 22800
    },
    {
      "epoch": 1.954258405871309,
      "grad_norm": 3.3807411193847656,
      "learning_rate": 4.348808101496274e-05,
      "loss": 1.3924,
      "step": 22900
    },
    {
      "epoch": 1.9627922853729305,
      "grad_norm": 3.567509412765503,
      "learning_rate": 4.345963474995733e-05,
      "loss": 1.3984,
      "step": 23000
    },
    {
      "epoch": 1.9627922853729305,
      "eval_loss": 1.191894769668579,
      "eval_runtime": 63.8527,
      "eval_samples_per_second": 618.141,
      "eval_steps_per_second": 77.272,
      "step": 23000
    },
    {
      "epoch": 1.971326164874552,
      "grad_norm": 3.682561159133911,
      "learning_rate": 4.343118848495193e-05,
      "loss": 1.4087,
      "step": 23100
    },
    {
      "epoch": 1.9798600443761734,
      "grad_norm": 3.2979207038879395,
      "learning_rate": 4.340274221994652e-05,
      "loss": 1.3995,
      "step": 23200
    },
    {
      "epoch": 1.988393923877795,
      "grad_norm": 3.1071839332580566,
      "learning_rate": 4.337429595494112e-05,
      "loss": 1.4041,
      "step": 23300
    },
    {
      "epoch": 1.9969278033794162,
      "grad_norm": 3.6708755493164062,
      "learning_rate": 4.334584968993571e-05,
      "loss": 1.3983,
      "step": 23400
    },
    {
      "epoch": 2.005461682881038,
      "grad_norm": 3.2542426586151123,
      "learning_rate": 4.331740342493031e-05,
      "loss": 1.3927,
      "step": 23500
    },
    {
      "epoch": 2.013995562382659,
      "grad_norm": 3.343841075897217,
      "learning_rate": 4.3288957159924903e-05,
      "loss": 1.3836,
      "step": 23600
    },
    {
      "epoch": 2.0225294418842807,
      "grad_norm": 3.4955835342407227,
      "learning_rate": 4.32605108949195e-05,
      "loss": 1.3826,
      "step": 23700
    },
    {
      "epoch": 2.031063321385902,
      "grad_norm": 3.444777250289917,
      "learning_rate": 4.3232064629914094e-05,
      "loss": 1.378,
      "step": 23800
    },
    {
      "epoch": 2.0395972008875236,
      "grad_norm": 3.534733772277832,
      "learning_rate": 4.320361836490869e-05,
      "loss": 1.3939,
      "step": 23900
    },
    {
      "epoch": 2.048131080389145,
      "grad_norm": 2.927751064300537,
      "learning_rate": 4.3175172099903284e-05,
      "loss": 1.3969,
      "step": 24000
    },
    {
      "epoch": 2.048131080389145,
      "eval_loss": 1.182525396347046,
      "eval_runtime": 63.5572,
      "eval_samples_per_second": 621.015,
      "eval_steps_per_second": 77.631,
      "step": 24000
    },
    {
      "epoch": 2.0566649598907665,
      "grad_norm": 3.63796067237854,
      "learning_rate": 4.3147010297547935e-05,
      "loss": 1.4025,
      "step": 24100
    },
    {
      "epoch": 2.0651988393923877,
      "grad_norm": 3.3083603382110596,
      "learning_rate": 4.311856403254253e-05,
      "loss": 1.3923,
      "step": 24200
    },
    {
      "epoch": 2.0737327188940093,
      "grad_norm": 3.33308744430542,
      "learning_rate": 4.3090117767537126e-05,
      "loss": 1.3954,
      "step": 24300
    },
    {
      "epoch": 2.0822665983956306,
      "grad_norm": 3.1420483589172363,
      "learning_rate": 4.306167150253172e-05,
      "loss": 1.3792,
      "step": 24400
    },
    {
      "epoch": 2.090800477897252,
      "grad_norm": 3.730774164199829,
      "learning_rate": 4.3033225237526316e-05,
      "loss": 1.3953,
      "step": 24500
    },
    {
      "epoch": 2.0993343573988734,
      "grad_norm": 3.353583574295044,
      "learning_rate": 4.300477897252091e-05,
      "loss": 1.3838,
      "step": 24600
    },
    {
      "epoch": 2.107868236900495,
      "grad_norm": 3.497012138366699,
      "learning_rate": 4.2976332707515506e-05,
      "loss": 1.3864,
      "step": 24700
    },
    {
      "epoch": 2.1164021164021163,
      "grad_norm": 3.480480194091797,
      "learning_rate": 4.29478864425101e-05,
      "loss": 1.3888,
      "step": 24800
    },
    {
      "epoch": 2.124935995903738,
      "grad_norm": 3.5003888607025146,
      "learning_rate": 4.2919440177504696e-05,
      "loss": 1.3777,
      "step": 24900
    },
    {
      "epoch": 2.133469875405359,
      "grad_norm": 3.25541615486145,
      "learning_rate": 4.289099391249929e-05,
      "loss": 1.3772,
      "step": 25000
    },
    {
      "epoch": 2.133469875405359,
      "eval_loss": 1.1773916482925415,
      "eval_runtime": 63.4676,
      "eval_samples_per_second": 621.892,
      "eval_steps_per_second": 77.74,
      "step": 25000
    },
    {
      "epoch": 2.142003754906981,
      "grad_norm": 3.4808828830718994,
      "learning_rate": 4.2862547647493886e-05,
      "loss": 1.373,
      "step": 25100
    },
    {
      "epoch": 2.150537634408602,
      "grad_norm": 3.1592345237731934,
      "learning_rate": 4.283410138248848e-05,
      "loss": 1.383,
      "step": 25200
    },
    {
      "epoch": 2.1590715139102237,
      "grad_norm": 3.6066300868988037,
      "learning_rate": 4.2805655117483076e-05,
      "loss": 1.3699,
      "step": 25300
    },
    {
      "epoch": 2.167605393411845,
      "grad_norm": 2.9385948181152344,
      "learning_rate": 4.277720885247767e-05,
      "loss": 1.3761,
      "step": 25400
    },
    {
      "epoch": 2.1761392729134665,
      "grad_norm": 3.515637159347534,
      "learning_rate": 4.2748762587472266e-05,
      "loss": 1.3606,
      "step": 25500
    },
    {
      "epoch": 2.1846731524150877,
      "grad_norm": 3.0314536094665527,
      "learning_rate": 4.272031632246686e-05,
      "loss": 1.3786,
      "step": 25600
    },
    {
      "epoch": 2.1932070319167094,
      "grad_norm": 3.2419540882110596,
      "learning_rate": 4.2691870057461456e-05,
      "loss": 1.3841,
      "step": 25700
    },
    {
      "epoch": 2.2017409114183306,
      "grad_norm": 3.150798797607422,
      "learning_rate": 4.266342379245605e-05,
      "loss": 1.3631,
      "step": 25800
    },
    {
      "epoch": 2.2102747909199523,
      "grad_norm": 3.3413453102111816,
      "learning_rate": 4.2634977527450646e-05,
      "loss": 1.3747,
      "step": 25900
    },
    {
      "epoch": 2.2188086704215735,
      "grad_norm": 3.1467204093933105,
      "learning_rate": 4.260653126244524e-05,
      "loss": 1.363,
      "step": 26000
    },
    {
      "epoch": 2.2188086704215735,
      "eval_loss": 1.1653778553009033,
      "eval_runtime": 63.9555,
      "eval_samples_per_second": 617.148,
      "eval_steps_per_second": 77.147,
      "step": 26000
    },
    {
      "epoch": 2.227342549923195,
      "grad_norm": 3.219052791595459,
      "learning_rate": 4.2578369460089887e-05,
      "loss": 1.3596,
      "step": 26100
    },
    {
      "epoch": 2.2358764294248163,
      "grad_norm": 3.2959141731262207,
      "learning_rate": 4.254992319508449e-05,
      "loss": 1.3688,
      "step": 26200
    },
    {
      "epoch": 2.244410308926438,
      "grad_norm": 3.195122003555298,
      "learning_rate": 4.2521476930079083e-05,
      "loss": 1.3837,
      "step": 26300
    },
    {
      "epoch": 2.252944188428059,
      "grad_norm": 3.5006465911865234,
      "learning_rate": 4.249303066507368e-05,
      "loss": 1.3759,
      "step": 26400
    },
    {
      "epoch": 2.261478067929681,
      "grad_norm": 3.4558088779449463,
      "learning_rate": 4.2464584400068274e-05,
      "loss": 1.3689,
      "step": 26500
    },
    {
      "epoch": 2.270011947431302,
      "grad_norm": 3.516594409942627,
      "learning_rate": 4.243613813506287e-05,
      "loss": 1.3643,
      "step": 26600
    },
    {
      "epoch": 2.2785458269329237,
      "grad_norm": 3.721177101135254,
      "learning_rate": 4.2407691870057464e-05,
      "loss": 1.3596,
      "step": 26700
    },
    {
      "epoch": 2.287079706434545,
      "grad_norm": 3.7317190170288086,
      "learning_rate": 4.237924560505206e-05,
      "loss": 1.3648,
      "step": 26800
    },
    {
      "epoch": 2.2956135859361666,
      "grad_norm": 3.056779623031616,
      "learning_rate": 4.2350799340046654e-05,
      "loss": 1.3742,
      "step": 26900
    },
    {
      "epoch": 2.3041474654377883,
      "grad_norm": 3.6559536457061768,
      "learning_rate": 4.232235307504125e-05,
      "loss": 1.3701,
      "step": 27000
    },
    {
      "epoch": 2.3041474654377883,
      "eval_loss": 1.1519463062286377,
      "eval_runtime": 63.7893,
      "eval_samples_per_second": 618.756,
      "eval_steps_per_second": 77.348,
      "step": 27000
    },
    {
      "epoch": 2.3126813449394095,
      "grad_norm": 3.4308581352233887,
      "learning_rate": 4.2293906810035844e-05,
      "loss": 1.3603,
      "step": 27100
    },
    {
      "epoch": 2.3212152244410307,
      "grad_norm": 3.2582287788391113,
      "learning_rate": 4.226546054503044e-05,
      "loss": 1.369,
      "step": 27200
    },
    {
      "epoch": 2.3297491039426523,
      "grad_norm": 3.912299633026123,
      "learning_rate": 4.2237014280025034e-05,
      "loss": 1.3622,
      "step": 27300
    },
    {
      "epoch": 2.338282983444274,
      "grad_norm": 3.6567978858947754,
      "learning_rate": 4.220856801501963e-05,
      "loss": 1.3604,
      "step": 27400
    },
    {
      "epoch": 2.346816862945895,
      "grad_norm": 3.3136653900146484,
      "learning_rate": 4.2180121750014224e-05,
      "loss": 1.3555,
      "step": 27500
    },
    {
      "epoch": 2.3553507424475164,
      "grad_norm": 3.2469863891601562,
      "learning_rate": 4.215167548500882e-05,
      "loss": 1.3734,
      "step": 27600
    },
    {
      "epoch": 2.363884621949138,
      "grad_norm": 3.164180278778076,
      "learning_rate": 4.2123229220003414e-05,
      "loss": 1.3664,
      "step": 27700
    },
    {
      "epoch": 2.3724185014507597,
      "grad_norm": 3.4038612842559814,
      "learning_rate": 4.2094782954998016e-05,
      "loss": 1.3563,
      "step": 27800
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 3.3532843589782715,
      "learning_rate": 4.206633668999261e-05,
      "loss": 1.3663,
      "step": 27900
    },
    {
      "epoch": 2.389486260454002,
      "grad_norm": 2.9846348762512207,
      "learning_rate": 4.2037890424987206e-05,
      "loss": 1.3395,
      "step": 28000
    },
    {
      "epoch": 2.389486260454002,
      "eval_loss": 1.1429312229156494,
      "eval_runtime": 63.3601,
      "eval_samples_per_second": 622.947,
      "eval_steps_per_second": 77.872,
      "step": 28000
    },
    {
      "epoch": 2.398020139955624,
      "grad_norm": 3.2327234745025635,
      "learning_rate": 4.200972862263185e-05,
      "loss": 1.3428,
      "step": 28100
    },
    {
      "epoch": 2.4065540194572455,
      "grad_norm": 3.768333911895752,
      "learning_rate": 4.1981282357626446e-05,
      "loss": 1.3666,
      "step": 28200
    },
    {
      "epoch": 2.4150878989588667,
      "grad_norm": 3.2721171379089355,
      "learning_rate": 4.195283609262104e-05,
      "loss": 1.3589,
      "step": 28300
    },
    {
      "epoch": 2.4236217784604883,
      "grad_norm": 2.9363460540771484,
      "learning_rate": 4.1924389827615636e-05,
      "loss": 1.363,
      "step": 28400
    },
    {
      "epoch": 2.4321556579621095,
      "grad_norm": 3.064887523651123,
      "learning_rate": 4.189594356261023e-05,
      "loss": 1.3447,
      "step": 28500
    },
    {
      "epoch": 2.440689537463731,
      "grad_norm": 3.5460925102233887,
      "learning_rate": 4.1867497297604826e-05,
      "loss": 1.34,
      "step": 28600
    },
    {
      "epoch": 2.4492234169653524,
      "grad_norm": 3.448817491531372,
      "learning_rate": 4.183905103259942e-05,
      "loss": 1.3389,
      "step": 28700
    },
    {
      "epoch": 2.457757296466974,
      "grad_norm": 3.524291753768921,
      "learning_rate": 4.1810604767594017e-05,
      "loss": 1.3416,
      "step": 28800
    },
    {
      "epoch": 2.4662911759685953,
      "grad_norm": 3.233910322189331,
      "learning_rate": 4.178215850258861e-05,
      "loss": 1.3524,
      "step": 28900
    },
    {
      "epoch": 2.474825055470217,
      "grad_norm": 3.393068313598633,
      "learning_rate": 4.175371223758321e-05,
      "loss": 1.3443,
      "step": 29000
    },
    {
      "epoch": 2.474825055470217,
      "eval_loss": 1.1508665084838867,
      "eval_runtime": 63.8062,
      "eval_samples_per_second": 618.592,
      "eval_steps_per_second": 77.328,
      "step": 29000
    },
    {
      "epoch": 2.483358934971838,
      "grad_norm": 3.243048906326294,
      "learning_rate": 4.17252659725778e-05,
      "loss": 1.3458,
      "step": 29100
    },
    {
      "epoch": 2.49189281447346,
      "grad_norm": 2.9472572803497314,
      "learning_rate": 4.16968197075724e-05,
      "loss": 1.3628,
      "step": 29200
    },
    {
      "epoch": 2.500426693975081,
      "grad_norm": 3.1089930534362793,
      "learning_rate": 4.166837344256699e-05,
      "loss": 1.3395,
      "step": 29300
    },
    {
      "epoch": 2.5089605734767026,
      "grad_norm": 3.34859299659729,
      "learning_rate": 4.163992717756159e-05,
      "loss": 1.3401,
      "step": 29400
    },
    {
      "epoch": 2.517494452978324,
      "grad_norm": 3.8547990322113037,
      "learning_rate": 4.161148091255618e-05,
      "loss": 1.3306,
      "step": 29500
    },
    {
      "epoch": 2.5260283324799455,
      "grad_norm": 3.567659378051758,
      "learning_rate": 4.158303464755078e-05,
      "loss": 1.3454,
      "step": 29600
    },
    {
      "epoch": 2.5345622119815667,
      "grad_norm": 3.0844664573669434,
      "learning_rate": 4.155458838254537e-05,
      "loss": 1.3298,
      "step": 29700
    },
    {
      "epoch": 2.5430960914831884,
      "grad_norm": 2.9965248107910156,
      "learning_rate": 4.152614211753997e-05,
      "loss": 1.353,
      "step": 29800
    },
    {
      "epoch": 2.5516299709848096,
      "grad_norm": 3.8031694889068604,
      "learning_rate": 4.149769585253456e-05,
      "loss": 1.3435,
      "step": 29900
    },
    {
      "epoch": 2.5601638504864312,
      "grad_norm": 3.03635311126709,
      "learning_rate": 4.146924958752916e-05,
      "loss": 1.3513,
      "step": 30000
    },
    {
      "epoch": 2.5601638504864312,
      "eval_loss": 1.1354827880859375,
      "eval_runtime": 64.0133,
      "eval_samples_per_second": 616.59,
      "eval_steps_per_second": 77.078,
      "step": 30000
    },
    {
      "epoch": 2.5686977299880525,
      "grad_norm": 3.1233913898468018,
      "learning_rate": 4.144108778517381e-05,
      "loss": 1.3411,
      "step": 30100
    },
    {
      "epoch": 2.577231609489674,
      "grad_norm": 3.264650344848633,
      "learning_rate": 4.1412641520168404e-05,
      "loss": 1.3371,
      "step": 30200
    },
    {
      "epoch": 2.5857654889912953,
      "grad_norm": 3.2612340450286865,
      "learning_rate": 4.1384195255163e-05,
      "loss": 1.3351,
      "step": 30300
    },
    {
      "epoch": 2.594299368492917,
      "grad_norm": 3.080625295639038,
      "learning_rate": 4.1355748990157594e-05,
      "loss": 1.3385,
      "step": 30400
    },
    {
      "epoch": 2.602833247994538,
      "grad_norm": 3.3877313137054443,
      "learning_rate": 4.132730272515219e-05,
      "loss": 1.338,
      "step": 30500
    },
    {
      "epoch": 2.61136712749616,
      "grad_norm": 2.9047794342041016,
      "learning_rate": 4.1298856460146784e-05,
      "loss": 1.3246,
      "step": 30600
    },
    {
      "epoch": 2.619901006997781,
      "grad_norm": 3.6690924167633057,
      "learning_rate": 4.127041019514138e-05,
      "loss": 1.3368,
      "step": 30700
    },
    {
      "epoch": 2.6284348864994027,
      "grad_norm": 3.275855541229248,
      "learning_rate": 4.1241963930135974e-05,
      "loss": 1.327,
      "step": 30800
    },
    {
      "epoch": 2.636968766001024,
      "grad_norm": 3.5474448204040527,
      "learning_rate": 4.121351766513057e-05,
      "loss": 1.3356,
      "step": 30900
    },
    {
      "epoch": 2.6455026455026456,
      "grad_norm": 3.5434410572052,
      "learning_rate": 4.1185071400125165e-05,
      "loss": 1.328,
      "step": 31000
    },
    {
      "epoch": 2.6455026455026456,
      "eval_loss": 1.1228218078613281,
      "eval_runtime": 63.6105,
      "eval_samples_per_second": 620.496,
      "eval_steps_per_second": 77.566,
      "step": 31000
    },
    {
      "epoch": 2.654036525004267,
      "grad_norm": 3.180030584335327,
      "learning_rate": 4.115662513511976e-05,
      "loss": 1.3382,
      "step": 31100
    },
    {
      "epoch": 2.6625704045058884,
      "grad_norm": 3.345736503601074,
      "learning_rate": 4.1128178870114355e-05,
      "loss": 1.3191,
      "step": 31200
    },
    {
      "epoch": 2.6711042840075097,
      "grad_norm": 3.4590327739715576,
      "learning_rate": 4.1099732605108957e-05,
      "loss": 1.3404,
      "step": 31300
    },
    {
      "epoch": 2.6796381635091313,
      "grad_norm": 3.3219821453094482,
      "learning_rate": 4.107128634010355e-05,
      "loss": 1.3324,
      "step": 31400
    },
    {
      "epoch": 2.688172043010753,
      "grad_norm": 3.263681173324585,
      "learning_rate": 4.104284007509815e-05,
      "loss": 1.3237,
      "step": 31500
    },
    {
      "epoch": 2.696705922512374,
      "grad_norm": 3.855211019515991,
      "learning_rate": 4.1014393810092735e-05,
      "loss": 1.3292,
      "step": 31600
    },
    {
      "epoch": 2.7052398020139954,
      "grad_norm": 3.2127532958984375,
      "learning_rate": 4.098594754508733e-05,
      "loss": 1.3434,
      "step": 31700
    },
    {
      "epoch": 2.713773681515617,
      "grad_norm": 3.4177896976470947,
      "learning_rate": 4.0957501280081925e-05,
      "loss": 1.3164,
      "step": 31800
    },
    {
      "epoch": 2.7223075610172387,
      "grad_norm": 3.424905300140381,
      "learning_rate": 4.092905501507652e-05,
      "loss": 1.3284,
      "step": 31900
    },
    {
      "epoch": 2.73084144051886,
      "grad_norm": 3.3437530994415283,
      "learning_rate": 4.0900608750071115e-05,
      "loss": 1.3132,
      "step": 32000
    },
    {
      "epoch": 2.73084144051886,
      "eval_loss": 1.1179289817810059,
      "eval_runtime": 63.9294,
      "eval_samples_per_second": 617.4,
      "eval_steps_per_second": 77.179,
      "step": 32000
    },
    {
      "epoch": 2.739375320020481,
      "grad_norm": 3.423180103302002,
      "learning_rate": 4.087244694771577e-05,
      "loss": 1.3359,
      "step": 32100
    },
    {
      "epoch": 2.7479091995221028,
      "grad_norm": 3.1127960681915283,
      "learning_rate": 4.084400068271036e-05,
      "loss": 1.3324,
      "step": 32200
    },
    {
      "epoch": 2.7564430790237244,
      "grad_norm": 3.1477580070495605,
      "learning_rate": 4.081555441770496e-05,
      "loss": 1.3435,
      "step": 32300
    },
    {
      "epoch": 2.7649769585253456,
      "grad_norm": 3.681553363800049,
      "learning_rate": 4.078710815269955e-05,
      "loss": 1.3057,
      "step": 32400
    },
    {
      "epoch": 2.773510838026967,
      "grad_norm": 3.8529200553894043,
      "learning_rate": 4.075866188769415e-05,
      "loss": 1.3153,
      "step": 32500
    },
    {
      "epoch": 2.7820447175285885,
      "grad_norm": 3.107945680618286,
      "learning_rate": 4.073021562268874e-05,
      "loss": 1.3339,
      "step": 32600
    },
    {
      "epoch": 2.79057859703021,
      "grad_norm": 3.3138480186462402,
      "learning_rate": 4.070176935768334e-05,
      "loss": 1.3288,
      "step": 32700
    },
    {
      "epoch": 2.7991124765318314,
      "grad_norm": 3.2677788734436035,
      "learning_rate": 4.067332309267793e-05,
      "loss": 1.3131,
      "step": 32800
    },
    {
      "epoch": 2.8076463560334526,
      "grad_norm": 3.4112374782562256,
      "learning_rate": 4.064487682767253e-05,
      "loss": 1.3062,
      "step": 32900
    },
    {
      "epoch": 2.8161802355350742,
      "grad_norm": 3.426994562149048,
      "learning_rate": 4.061643056266712e-05,
      "loss": 1.3069,
      "step": 33000
    },
    {
      "epoch": 2.8161802355350742,
      "eval_loss": 1.1109591722488403,
      "eval_runtime": 64.0099,
      "eval_samples_per_second": 616.624,
      "eval_steps_per_second": 77.082,
      "step": 33000
    },
    {
      "epoch": 2.824714115036696,
      "grad_norm": 3.883253812789917,
      "learning_rate": 4.058798429766172e-05,
      "loss": 1.3352,
      "step": 33100
    },
    {
      "epoch": 2.833247994538317,
      "grad_norm": 3.8295562267303467,
      "learning_rate": 4.055953803265631e-05,
      "loss": 1.3187,
      "step": 33200
    },
    {
      "epoch": 2.8417818740399383,
      "grad_norm": 3.5693397521972656,
      "learning_rate": 4.053109176765091e-05,
      "loss": 1.3064,
      "step": 33300
    },
    {
      "epoch": 2.85031575354156,
      "grad_norm": 3.104084014892578,
      "learning_rate": 4.05026455026455e-05,
      "loss": 1.311,
      "step": 33400
    },
    {
      "epoch": 2.8588496330431816,
      "grad_norm": 3.3936078548431396,
      "learning_rate": 4.04741992376401e-05,
      "loss": 1.3148,
      "step": 33500
    },
    {
      "epoch": 2.867383512544803,
      "grad_norm": 4.039450645446777,
      "learning_rate": 4.044575297263469e-05,
      "loss": 1.3092,
      "step": 33600
    },
    {
      "epoch": 2.875917392046424,
      "grad_norm": 3.0925190448760986,
      "learning_rate": 4.041730670762929e-05,
      "loss": 1.3168,
      "step": 33700
    },
    {
      "epoch": 2.8844512715480457,
      "grad_norm": 2.9722096920013428,
      "learning_rate": 4.038886044262389e-05,
      "loss": 1.3136,
      "step": 33800
    },
    {
      "epoch": 2.8929851510496674,
      "grad_norm": 3.2061853408813477,
      "learning_rate": 4.0360414177618485e-05,
      "loss": 1.3163,
      "step": 33900
    },
    {
      "epoch": 2.9015190305512886,
      "grad_norm": 3.6906659603118896,
      "learning_rate": 4.033196791261308e-05,
      "loss": 1.3046,
      "step": 34000
    },
    {
      "epoch": 2.9015190305512886,
      "eval_loss": 1.098864197731018,
      "eval_runtime": 63.7663,
      "eval_samples_per_second": 618.979,
      "eval_steps_per_second": 77.376,
      "step": 34000
    },
    {
      "epoch": 2.91005291005291,
      "grad_norm": 3.7131009101867676,
      "learning_rate": 4.0303806110257725e-05,
      "loss": 1.305,
      "step": 34100
    },
    {
      "epoch": 2.9185867895545314,
      "grad_norm": 3.710953950881958,
      "learning_rate": 4.027535984525232e-05,
      "loss": 1.3172,
      "step": 34200
    },
    {
      "epoch": 2.927120669056153,
      "grad_norm": 3.5139567852020264,
      "learning_rate": 4.0246913580246915e-05,
      "loss": 1.312,
      "step": 34300
    },
    {
      "epoch": 2.9356545485577743,
      "grad_norm": 2.95455002784729,
      "learning_rate": 4.021846731524151e-05,
      "loss": 1.3181,
      "step": 34400
    },
    {
      "epoch": 2.944188428059396,
      "grad_norm": 3.522986888885498,
      "learning_rate": 4.0190021050236105e-05,
      "loss": 1.3014,
      "step": 34500
    },
    {
      "epoch": 2.952722307561017,
      "grad_norm": 3.390503406524658,
      "learning_rate": 4.01615747852307e-05,
      "loss": 1.3172,
      "step": 34600
    },
    {
      "epoch": 2.961256187062639,
      "grad_norm": 3.412750244140625,
      "learning_rate": 4.0133128520225295e-05,
      "loss": 1.2994,
      "step": 34700
    },
    {
      "epoch": 2.96979006656426,
      "grad_norm": 3.359952688217163,
      "learning_rate": 4.01046822552199e-05,
      "loss": 1.2932,
      "step": 34800
    },
    {
      "epoch": 2.9783239460658817,
      "grad_norm": 3.0910964012145996,
      "learning_rate": 4.007623599021449e-05,
      "loss": 1.3139,
      "step": 34900
    },
    {
      "epoch": 2.986857825567503,
      "grad_norm": 3.556232452392578,
      "learning_rate": 4.004778972520909e-05,
      "loss": 1.3025,
      "step": 35000
    },
    {
      "epoch": 2.986857825567503,
      "eval_loss": 1.0935637950897217,
      "eval_runtime": 63.211,
      "eval_samples_per_second": 624.417,
      "eval_steps_per_second": 78.056,
      "step": 35000
    },
    {
      "epoch": 2.9953917050691246,
      "grad_norm": 3.1512043476104736,
      "learning_rate": 4.0019343460203675e-05,
      "loss": 1.3098,
      "step": 35100
    },
    {
      "epoch": 3.0039255845707458,
      "grad_norm": 3.296532392501831,
      "learning_rate": 3.999089719519827e-05,
      "loss": 1.3132,
      "step": 35200
    },
    {
      "epoch": 3.0124594640723674,
      "grad_norm": 3.8668975830078125,
      "learning_rate": 3.9962450930192865e-05,
      "loss": 1.3091,
      "step": 35300
    },
    {
      "epoch": 3.0209933435739886,
      "grad_norm": 2.8443355560302734,
      "learning_rate": 3.993400466518746e-05,
      "loss": 1.3046,
      "step": 35400
    },
    {
      "epoch": 3.0295272230756103,
      "grad_norm": 3.223306179046631,
      "learning_rate": 3.9905558400182056e-05,
      "loss": 1.2972,
      "step": 35500
    },
    {
      "epoch": 3.0380611025772315,
      "grad_norm": 3.9737699031829834,
      "learning_rate": 3.987711213517665e-05,
      "loss": 1.2988,
      "step": 35600
    },
    {
      "epoch": 3.046594982078853,
      "grad_norm": 3.59132981300354,
      "learning_rate": 3.9848665870171246e-05,
      "loss": 1.3117,
      "step": 35700
    },
    {
      "epoch": 3.0551288615804744,
      "grad_norm": 3.4315314292907715,
      "learning_rate": 3.982021960516584e-05,
      "loss": 1.2814,
      "step": 35800
    },
    {
      "epoch": 3.063662741082096,
      "grad_norm": 3.7288036346435547,
      "learning_rate": 3.9791773340160436e-05,
      "loss": 1.3076,
      "step": 35900
    },
    {
      "epoch": 3.0721966205837172,
      "grad_norm": 3.3671984672546387,
      "learning_rate": 3.976332707515503e-05,
      "loss": 1.2996,
      "step": 36000
    },
    {
      "epoch": 3.0721966205837172,
      "eval_loss": 1.0998820066452026,
      "eval_runtime": 63.7758,
      "eval_samples_per_second": 618.887,
      "eval_steps_per_second": 77.365,
      "step": 36000
    },
    {
      "epoch": 3.080730500085339,
      "grad_norm": 3.2652878761291504,
      "learning_rate": 3.973516527279968e-05,
      "loss": 1.2865,
      "step": 36100
    },
    {
      "epoch": 3.08926437958696,
      "grad_norm": 3.075014591217041,
      "learning_rate": 3.970671900779428e-05,
      "loss": 1.2895,
      "step": 36200
    },
    {
      "epoch": 3.0977982590885818,
      "grad_norm": 3.110914468765259,
      "learning_rate": 3.967827274278887e-05,
      "loss": 1.2837,
      "step": 36300
    },
    {
      "epoch": 3.106332138590203,
      "grad_norm": 3.6269335746765137,
      "learning_rate": 3.964982647778347e-05,
      "loss": 1.2756,
      "step": 36400
    },
    {
      "epoch": 3.1148660180918246,
      "grad_norm": 3.6571109294891357,
      "learning_rate": 3.962138021277806e-05,
      "loss": 1.2909,
      "step": 36500
    },
    {
      "epoch": 3.123399897593446,
      "grad_norm": 3.0375871658325195,
      "learning_rate": 3.959293394777266e-05,
      "loss": 1.2976,
      "step": 36600
    },
    {
      "epoch": 3.1319337770950675,
      "grad_norm": 3.3284366130828857,
      "learning_rate": 3.956448768276725e-05,
      "loss": 1.2885,
      "step": 36700
    },
    {
      "epoch": 3.1404676565966887,
      "grad_norm": 3.41428804397583,
      "learning_rate": 3.953604141776185e-05,
      "loss": 1.2941,
      "step": 36800
    },
    {
      "epoch": 3.1490015360983103,
      "grad_norm": 3.380556583404541,
      "learning_rate": 3.950759515275644e-05,
      "loss": 1.305,
      "step": 36900
    },
    {
      "epoch": 3.1575354155999316,
      "grad_norm": 3.458930015563965,
      "learning_rate": 3.947914888775104e-05,
      "loss": 1.3042,
      "step": 37000
    },
    {
      "epoch": 3.1575354155999316,
      "eval_loss": 1.0901674032211304,
      "eval_runtime": 64.0905,
      "eval_samples_per_second": 615.848,
      "eval_steps_per_second": 76.985,
      "step": 37000
    },
    {
      "epoch": 3.166069295101553,
      "grad_norm": 3.469543933868408,
      "learning_rate": 3.945070262274563e-05,
      "loss": 1.3027,
      "step": 37100
    },
    {
      "epoch": 3.1746031746031744,
      "grad_norm": 3.649451494216919,
      "learning_rate": 3.942225635774023e-05,
      "loss": 1.297,
      "step": 37200
    },
    {
      "epoch": 3.183137054104796,
      "grad_norm": 3.083327531814575,
      "learning_rate": 3.939381009273482e-05,
      "loss": 1.2932,
      "step": 37300
    },
    {
      "epoch": 3.1916709336064173,
      "grad_norm": 3.0045974254608154,
      "learning_rate": 3.9365363827729425e-05,
      "loss": 1.294,
      "step": 37400
    },
    {
      "epoch": 3.200204813108039,
      "grad_norm": 3.0892205238342285,
      "learning_rate": 3.933691756272402e-05,
      "loss": 1.3065,
      "step": 37500
    },
    {
      "epoch": 3.20873869260966,
      "grad_norm": 3.1796507835388184,
      "learning_rate": 3.9308471297718615e-05,
      "loss": 1.3038,
      "step": 37600
    },
    {
      "epoch": 3.217272572111282,
      "grad_norm": 3.5982770919799805,
      "learning_rate": 3.928002503271321e-05,
      "loss": 1.2862,
      "step": 37700
    },
    {
      "epoch": 3.225806451612903,
      "grad_norm": 3.513226270675659,
      "learning_rate": 3.9251578767707805e-05,
      "loss": 1.2937,
      "step": 37800
    },
    {
      "epoch": 3.2343403311145247,
      "grad_norm": 3.209477663040161,
      "learning_rate": 3.92231325027024e-05,
      "loss": 1.2836,
      "step": 37900
    },
    {
      "epoch": 3.2428742106161463,
      "grad_norm": 3.4580726623535156,
      "learning_rate": 3.9194686237696996e-05,
      "loss": 1.2845,
      "step": 38000
    },
    {
      "epoch": 3.2428742106161463,
      "eval_loss": 1.0835797786712646,
      "eval_runtime": 63.8073,
      "eval_samples_per_second": 618.581,
      "eval_steps_per_second": 77.327,
      "step": 38000
    },
    {
      "epoch": 3.2514080901177675,
      "grad_norm": 3.131220817565918,
      "learning_rate": 3.916623997269159e-05,
      "loss": 1.2882,
      "step": 38100
    },
    {
      "epoch": 3.2599419696193888,
      "grad_norm": 3.1283488273620605,
      "learning_rate": 3.9138078170336236e-05,
      "loss": 1.2933,
      "step": 38200
    },
    {
      "epoch": 3.2684758491210104,
      "grad_norm": 4.169922351837158,
      "learning_rate": 3.910963190533084e-05,
      "loss": 1.2888,
      "step": 38300
    },
    {
      "epoch": 3.277009728622632,
      "grad_norm": 3.0927248001098633,
      "learning_rate": 3.908118564032543e-05,
      "loss": 1.286,
      "step": 38400
    },
    {
      "epoch": 3.2855436081242533,
      "grad_norm": 3.5368385314941406,
      "learning_rate": 3.905273937532003e-05,
      "loss": 1.2874,
      "step": 38500
    },
    {
      "epoch": 3.2940774876258745,
      "grad_norm": 3.492648124694824,
      "learning_rate": 3.9024293110314616e-05,
      "loss": 1.2983,
      "step": 38600
    },
    {
      "epoch": 3.302611367127496,
      "grad_norm": 3.0278191566467285,
      "learning_rate": 3.899584684530921e-05,
      "loss": 1.2917,
      "step": 38700
    },
    {
      "epoch": 3.311145246629118,
      "grad_norm": 3.106740713119507,
      "learning_rate": 3.8967400580303806e-05,
      "loss": 1.2809,
      "step": 38800
    },
    {
      "epoch": 3.319679126130739,
      "grad_norm": 3.5210373401641846,
      "learning_rate": 3.89389543152984e-05,
      "loss": 1.2885,
      "step": 38900
    },
    {
      "epoch": 3.32821300563236,
      "grad_norm": 3.212083101272583,
      "learning_rate": 3.8910508050292996e-05,
      "loss": 1.2732,
      "step": 39000
    },
    {
      "epoch": 3.32821300563236,
      "eval_loss": 1.0781866312026978,
      "eval_runtime": 63.5508,
      "eval_samples_per_second": 621.078,
      "eval_steps_per_second": 77.639,
      "step": 39000
    },
    {
      "epoch": 3.336746885133982,
      "grad_norm": 3.511385440826416,
      "learning_rate": 3.888206178528759e-05,
      "loss": 1.2813,
      "step": 39100
    },
    {
      "epoch": 3.3452807646356035,
      "grad_norm": 4.033181667327881,
      "learning_rate": 3.8853615520282186e-05,
      "loss": 1.2821,
      "step": 39200
    },
    {
      "epoch": 3.3538146441372247,
      "grad_norm": 3.6169838905334473,
      "learning_rate": 3.882516925527678e-05,
      "loss": 1.2923,
      "step": 39300
    },
    {
      "epoch": 3.3623485236388464,
      "grad_norm": 3.7457633018493652,
      "learning_rate": 3.8796722990271376e-05,
      "loss": 1.2892,
      "step": 39400
    },
    {
      "epoch": 3.3708824031404676,
      "grad_norm": 3.2925968170166016,
      "learning_rate": 3.876827672526597e-05,
      "loss": 1.2896,
      "step": 39500
    },
    {
      "epoch": 3.3794162826420893,
      "grad_norm": 2.9274470806121826,
      "learning_rate": 3.8739830460260566e-05,
      "loss": 1.2733,
      "step": 39600
    },
    {
      "epoch": 3.3879501621437105,
      "grad_norm": 3.193347692489624,
      "learning_rate": 3.871138419525516e-05,
      "loss": 1.2873,
      "step": 39700
    },
    {
      "epoch": 3.396484041645332,
      "grad_norm": 3.1999309062957764,
      "learning_rate": 3.8682937930249757e-05,
      "loss": 1.2637,
      "step": 39800
    },
    {
      "epoch": 3.4050179211469533,
      "grad_norm": 3.3805389404296875,
      "learning_rate": 3.865449166524436e-05,
      "loss": 1.2813,
      "step": 39900
    },
    {
      "epoch": 3.413551800648575,
      "grad_norm": 3.4805428981781006,
      "learning_rate": 3.8626045400238953e-05,
      "loss": 1.2781,
      "step": 40000
    },
    {
      "epoch": 3.413551800648575,
      "eval_loss": 1.075830340385437,
      "eval_runtime": 64.1835,
      "eval_samples_per_second": 614.955,
      "eval_steps_per_second": 76.873,
      "step": 40000
    },
    {
      "epoch": 3.422085680150196,
      "grad_norm": 3.327831983566284,
      "learning_rate": 3.859759913523355e-05,
      "loss": 1.2677,
      "step": 40100
    },
    {
      "epoch": 3.430619559651818,
      "grad_norm": 3.47035551071167,
      "learning_rate": 3.8569437332878193e-05,
      "loss": 1.2768,
      "step": 40200
    },
    {
      "epoch": 3.439153439153439,
      "grad_norm": 3.553236484527588,
      "learning_rate": 3.854099106787279e-05,
      "loss": 1.2781,
      "step": 40300
    },
    {
      "epoch": 3.4476873186550607,
      "grad_norm": 3.236232280731201,
      "learning_rate": 3.8512544802867384e-05,
      "loss": 1.2894,
      "step": 40400
    },
    {
      "epoch": 3.456221198156682,
      "grad_norm": 3.672182083129883,
      "learning_rate": 3.848409853786198e-05,
      "loss": 1.2756,
      "step": 40500
    },
    {
      "epoch": 3.4647550776583036,
      "grad_norm": 3.496187210083008,
      "learning_rate": 3.8455652272856574e-05,
      "loss": 1.2724,
      "step": 40600
    },
    {
      "epoch": 3.473288957159925,
      "grad_norm": 3.2745182514190674,
      "learning_rate": 3.842720600785117e-05,
      "loss": 1.2792,
      "step": 40700
    },
    {
      "epoch": 3.4818228366615465,
      "grad_norm": 3.3670566082000732,
      "learning_rate": 3.8398759742845764e-05,
      "loss": 1.2655,
      "step": 40800
    },
    {
      "epoch": 3.4903567161631677,
      "grad_norm": 3.319493532180786,
      "learning_rate": 3.8370313477840366e-05,
      "loss": 1.2778,
      "step": 40900
    },
    {
      "epoch": 3.4988905956647893,
      "grad_norm": 3.1735410690307617,
      "learning_rate": 3.834186721283496e-05,
      "loss": 1.2876,
      "step": 41000
    },
    {
      "epoch": 3.4988905956647893,
      "eval_loss": 1.0661453008651733,
      "eval_runtime": 63.6818,
      "eval_samples_per_second": 619.8,
      "eval_steps_per_second": 77.479,
      "step": 41000
    },
    {
      "epoch": 3.5074244751664105,
      "grad_norm": 3.2908735275268555,
      "learning_rate": 3.8313420947829556e-05,
      "loss": 1.2802,
      "step": 41100
    },
    {
      "epoch": 3.515958354668032,
      "grad_norm": 3.549670457839966,
      "learning_rate": 3.828497468282415e-05,
      "loss": 1.2746,
      "step": 41200
    },
    {
      "epoch": 3.5244922341696534,
      "grad_norm": 3.278367519378662,
      "learning_rate": 3.8256528417818746e-05,
      "loss": 1.2733,
      "step": 41300
    },
    {
      "epoch": 3.533026113671275,
      "grad_norm": 3.527291774749756,
      "learning_rate": 3.822808215281334e-05,
      "loss": 1.2628,
      "step": 41400
    },
    {
      "epoch": 3.5415599931728963,
      "grad_norm": 3.4204673767089844,
      "learning_rate": 3.8199635887807936e-05,
      "loss": 1.2691,
      "step": 41500
    },
    {
      "epoch": 3.550093872674518,
      "grad_norm": 3.5373685359954834,
      "learning_rate": 3.817118962280253e-05,
      "loss": 1.2654,
      "step": 41600
    },
    {
      "epoch": 3.558627752176139,
      "grad_norm": 4.036440372467041,
      "learning_rate": 3.814274335779712e-05,
      "loss": 1.272,
      "step": 41700
    },
    {
      "epoch": 3.567161631677761,
      "grad_norm": 3.477736711502075,
      "learning_rate": 3.8114297092791714e-05,
      "loss": 1.2824,
      "step": 41800
    },
    {
      "epoch": 3.575695511179382,
      "grad_norm": 3.187000036239624,
      "learning_rate": 3.808585082778631e-05,
      "loss": 1.2531,
      "step": 41900
    },
    {
      "epoch": 3.5842293906810037,
      "grad_norm": 3.3936307430267334,
      "learning_rate": 3.8057404562780905e-05,
      "loss": 1.2654,
      "step": 42000
    },
    {
      "epoch": 3.5842293906810037,
      "eval_loss": 1.0598253011703491,
      "eval_runtime": 63.3027,
      "eval_samples_per_second": 623.512,
      "eval_steps_per_second": 77.943,
      "step": 42000
    },
    {
      "epoch": 3.592763270182625,
      "grad_norm": 3.5919277667999268,
      "learning_rate": 3.80289582977755e-05,
      "loss": 1.2668,
      "step": 42100
    },
    {
      "epoch": 3.6012971496842465,
      "grad_norm": 3.3892271518707275,
      "learning_rate": 3.800079649542015e-05,
      "loss": 1.2642,
      "step": 42200
    },
    {
      "epoch": 3.6098310291858677,
      "grad_norm": 3.1725947856903076,
      "learning_rate": 3.7972350230414746e-05,
      "loss": 1.2681,
      "step": 42300
    },
    {
      "epoch": 3.6183649086874894,
      "grad_norm": 3.4359707832336426,
      "learning_rate": 3.794390396540934e-05,
      "loss": 1.2664,
      "step": 42400
    },
    {
      "epoch": 3.626898788189111,
      "grad_norm": 3.455021381378174,
      "learning_rate": 3.7915457700403937e-05,
      "loss": 1.2721,
      "step": 42500
    },
    {
      "epoch": 3.6354326676907323,
      "grad_norm": 3.4239537715911865,
      "learning_rate": 3.788701143539853e-05,
      "loss": 1.2731,
      "step": 42600
    },
    {
      "epoch": 3.6439665471923535,
      "grad_norm": 3.1577956676483154,
      "learning_rate": 3.785856517039313e-05,
      "loss": 1.2652,
      "step": 42700
    },
    {
      "epoch": 3.652500426693975,
      "grad_norm": 2.857548236846924,
      "learning_rate": 3.783011890538772e-05,
      "loss": 1.268,
      "step": 42800
    },
    {
      "epoch": 3.6610343061955968,
      "grad_norm": 3.4749903678894043,
      "learning_rate": 3.780167264038232e-05,
      "loss": 1.2691,
      "step": 42900
    },
    {
      "epoch": 3.669568185697218,
      "grad_norm": 3.4439873695373535,
      "learning_rate": 3.777322637537691e-05,
      "loss": 1.2621,
      "step": 43000
    },
    {
      "epoch": 3.669568185697218,
      "eval_loss": 1.0591539144515991,
      "eval_runtime": 63.8321,
      "eval_samples_per_second": 618.341,
      "eval_steps_per_second": 77.296,
      "step": 43000
    },
    {
      "epoch": 3.678102065198839,
      "grad_norm": 3.060347557067871,
      "learning_rate": 3.774478011037151e-05,
      "loss": 1.2601,
      "step": 43100
    },
    {
      "epoch": 3.686635944700461,
      "grad_norm": 3.5619492530822754,
      "learning_rate": 3.77163338453661e-05,
      "loss": 1.261,
      "step": 43200
    },
    {
      "epoch": 3.6951698242020825,
      "grad_norm": 3.3994510173797607,
      "learning_rate": 3.76878875803607e-05,
      "loss": 1.2583,
      "step": 43300
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 3.594463586807251,
      "learning_rate": 3.76594413153553e-05,
      "loss": 1.2491,
      "step": 43400
    },
    {
      "epoch": 3.712237583205325,
      "grad_norm": 3.2791683673858643,
      "learning_rate": 3.7630995050349894e-05,
      "loss": 1.262,
      "step": 43500
    },
    {
      "epoch": 3.7207714627069466,
      "grad_norm": 3.499831438064575,
      "learning_rate": 3.760254878534449e-05,
      "loss": 1.2719,
      "step": 43600
    },
    {
      "epoch": 3.7293053422085682,
      "grad_norm": 3.590055465698242,
      "learning_rate": 3.7574102520339084e-05,
      "loss": 1.2664,
      "step": 43700
    },
    {
      "epoch": 3.7378392217101895,
      "grad_norm": 3.344259262084961,
      "learning_rate": 3.754565625533368e-05,
      "loss": 1.2614,
      "step": 43800
    },
    {
      "epoch": 3.7463731012118107,
      "grad_norm": 3.2687389850616455,
      "learning_rate": 3.7517209990328274e-05,
      "loss": 1.2572,
      "step": 43900
    },
    {
      "epoch": 3.7549069807134323,
      "grad_norm": 3.4085679054260254,
      "learning_rate": 3.748876372532287e-05,
      "loss": 1.2523,
      "step": 44000
    },
    {
      "epoch": 3.7549069807134323,
      "eval_loss": 1.054488182067871,
      "eval_runtime": 64.0242,
      "eval_samples_per_second": 616.485,
      "eval_steps_per_second": 77.065,
      "step": 44000
    },
    {
      "epoch": 3.763440860215054,
      "grad_norm": 3.2340691089630127,
      "learning_rate": 3.7460317460317464e-05,
      "loss": 1.2721,
      "step": 44100
    },
    {
      "epoch": 3.771974739716675,
      "grad_norm": 3.460000514984131,
      "learning_rate": 3.743215565796211e-05,
      "loss": 1.2681,
      "step": 44200
    },
    {
      "epoch": 3.7805086192182964,
      "grad_norm": 3.3328497409820557,
      "learning_rate": 3.7403709392956704e-05,
      "loss": 1.2622,
      "step": 44300
    },
    {
      "epoch": 3.789042498719918,
      "grad_norm": 3.5702385902404785,
      "learning_rate": 3.7375263127951306e-05,
      "loss": 1.2647,
      "step": 44400
    },
    {
      "epoch": 3.7975763782215397,
      "grad_norm": 3.041316270828247,
      "learning_rate": 3.73468168629459e-05,
      "loss": 1.2548,
      "step": 44500
    },
    {
      "epoch": 3.806110257723161,
      "grad_norm": 3.712080240249634,
      "learning_rate": 3.7318370597940496e-05,
      "loss": 1.2606,
      "step": 44600
    },
    {
      "epoch": 3.814644137224782,
      "grad_norm": 3.795461654663086,
      "learning_rate": 3.728992433293509e-05,
      "loss": 1.24,
      "step": 44700
    },
    {
      "epoch": 3.823178016726404,
      "grad_norm": 3.2707767486572266,
      "learning_rate": 3.7261478067929686e-05,
      "loss": 1.2621,
      "step": 44800
    },
    {
      "epoch": 3.8317118962280254,
      "grad_norm": 3.8399851322174072,
      "learning_rate": 3.723303180292428e-05,
      "loss": 1.2663,
      "step": 44900
    },
    {
      "epoch": 3.8402457757296466,
      "grad_norm": 3.8412833213806152,
      "learning_rate": 3.7204585537918876e-05,
      "loss": 1.2497,
      "step": 45000
    },
    {
      "epoch": 3.8402457757296466,
      "eval_loss": 1.0541819334030151,
      "eval_runtime": 64.0075,
      "eval_samples_per_second": 616.646,
      "eval_steps_per_second": 77.085,
      "step": 45000
    },
    {
      "epoch": 3.848779655231268,
      "grad_norm": 3.3339390754699707,
      "learning_rate": 3.717613927291347e-05,
      "loss": 1.2549,
      "step": 45100
    },
    {
      "epoch": 3.8573135347328895,
      "grad_norm": 3.4419357776641846,
      "learning_rate": 3.714769300790806e-05,
      "loss": 1.2439,
      "step": 45200
    },
    {
      "epoch": 3.865847414234511,
      "grad_norm": 3.068282127380371,
      "learning_rate": 3.7119246742902655e-05,
      "loss": 1.2584,
      "step": 45300
    },
    {
      "epoch": 3.8743812937361324,
      "grad_norm": 3.5395658016204834,
      "learning_rate": 3.709080047789725e-05,
      "loss": 1.2458,
      "step": 45400
    },
    {
      "epoch": 3.882915173237754,
      "grad_norm": 3.4569714069366455,
      "learning_rate": 3.7062354212891845e-05,
      "loss": 1.2489,
      "step": 45500
    },
    {
      "epoch": 3.8914490527393752,
      "grad_norm": 3.5172617435455322,
      "learning_rate": 3.703390794788644e-05,
      "loss": 1.2442,
      "step": 45600
    },
    {
      "epoch": 3.899982932240997,
      "grad_norm": 3.104813575744629,
      "learning_rate": 3.700574614553109e-05,
      "loss": 1.2545,
      "step": 45700
    },
    {
      "epoch": 3.908516811742618,
      "grad_norm": 3.517486333847046,
      "learning_rate": 3.697729988052569e-05,
      "loss": 1.2575,
      "step": 45800
    },
    {
      "epoch": 3.9170506912442398,
      "grad_norm": 3.0949912071228027,
      "learning_rate": 3.694885361552028e-05,
      "loss": 1.2519,
      "step": 45900
    },
    {
      "epoch": 3.925584570745861,
      "grad_norm": 3.1049485206604004,
      "learning_rate": 3.692040735051488e-05,
      "loss": 1.2558,
      "step": 46000
    },
    {
      "epoch": 3.925584570745861,
      "eval_loss": 1.0483999252319336,
      "eval_runtime": 63.6892,
      "eval_samples_per_second": 619.728,
      "eval_steps_per_second": 77.47,
      "step": 46000
    },
    {
      "epoch": 3.9341184502474826,
      "grad_norm": 3.669196367263794,
      "learning_rate": 3.689196108550947e-05,
      "loss": 1.2395,
      "step": 46100
    },
    {
      "epoch": 3.942652329749104,
      "grad_norm": 3.0732853412628174,
      "learning_rate": 3.686351482050407e-05,
      "loss": 1.2555,
      "step": 46200
    },
    {
      "epoch": 3.9511862092507255,
      "grad_norm": 3.754887104034424,
      "learning_rate": 3.683506855549866e-05,
      "loss": 1.2614,
      "step": 46300
    },
    {
      "epoch": 3.9597200887523467,
      "grad_norm": 3.6316568851470947,
      "learning_rate": 3.680662229049326e-05,
      "loss": 1.2397,
      "step": 46400
    },
    {
      "epoch": 3.9682539682539684,
      "grad_norm": 3.080991268157959,
      "learning_rate": 3.677817602548785e-05,
      "loss": 1.2361,
      "step": 46500
    },
    {
      "epoch": 3.9767878477555896,
      "grad_norm": 3.8462088108062744,
      "learning_rate": 3.674972976048245e-05,
      "loss": 1.2467,
      "step": 46600
    },
    {
      "epoch": 3.9853217272572112,
      "grad_norm": 3.6651384830474854,
      "learning_rate": 3.672128349547704e-05,
      "loss": 1.2294,
      "step": 46700
    },
    {
      "epoch": 3.9938556067588324,
      "grad_norm": 3.342499017715454,
      "learning_rate": 3.669283723047164e-05,
      "loss": 1.2393,
      "step": 46800
    },
    {
      "epoch": 4.002389486260454,
      "grad_norm": 3.5407679080963135,
      "learning_rate": 3.666439096546624e-05,
      "loss": 1.2465,
      "step": 46900
    },
    {
      "epoch": 4.010923365762076,
      "grad_norm": 3.3710055351257324,
      "learning_rate": 3.6635944700460834e-05,
      "loss": 1.243,
      "step": 47000
    },
    {
      "epoch": 4.010923365762076,
      "eval_loss": 1.0437097549438477,
      "eval_runtime": 64.0063,
      "eval_samples_per_second": 616.658,
      "eval_steps_per_second": 77.086,
      "step": 47000
    },
    {
      "epoch": 4.0194572452636965,
      "grad_norm": 3.2590835094451904,
      "learning_rate": 3.660749843545543e-05,
      "loss": 1.2389,
      "step": 47100
    },
    {
      "epoch": 4.027991124765318,
      "grad_norm": 3.8167688846588135,
      "learning_rate": 3.6579052170450024e-05,
      "loss": 1.2469,
      "step": 47200
    },
    {
      "epoch": 4.03652500426694,
      "grad_norm": 3.6270833015441895,
      "learning_rate": 3.655060590544462e-05,
      "loss": 1.2434,
      "step": 47300
    },
    {
      "epoch": 4.0450588837685615,
      "grad_norm": 3.5868749618530273,
      "learning_rate": 3.6522159640439215e-05,
      "loss": 1.2305,
      "step": 47400
    },
    {
      "epoch": 4.053592763270182,
      "grad_norm": 3.2603538036346436,
      "learning_rate": 3.649371337543381e-05,
      "loss": 1.2446,
      "step": 47500
    },
    {
      "epoch": 4.062126642771804,
      "grad_norm": 3.518388509750366,
      "learning_rate": 3.6465267110428405e-05,
      "loss": 1.2539,
      "step": 47600
    },
    {
      "epoch": 4.070660522273426,
      "grad_norm": 3.644808530807495,
      "learning_rate": 3.6436820845423e-05,
      "loss": 1.2472,
      "step": 47700
    },
    {
      "epoch": 4.079194401775047,
      "grad_norm": 3.7483789920806885,
      "learning_rate": 3.6408374580417595e-05,
      "loss": 1.2402,
      "step": 47800
    },
    {
      "epoch": 4.087728281276668,
      "grad_norm": 2.9811339378356934,
      "learning_rate": 3.637992831541219e-05,
      "loss": 1.2467,
      "step": 47900
    },
    {
      "epoch": 4.09626216077829,
      "grad_norm": 3.3939104080200195,
      "learning_rate": 3.6351482050406785e-05,
      "loss": 1.2448,
      "step": 48000
    },
    {
      "epoch": 4.09626216077829,
      "eval_loss": 1.035013198852539,
      "eval_runtime": 63.7824,
      "eval_samples_per_second": 618.823,
      "eval_steps_per_second": 77.357,
      "step": 48000
    },
    {
      "epoch": 4.104796040279911,
      "grad_norm": 3.666835069656372,
      "learning_rate": 3.632303578540138e-05,
      "loss": 1.2333,
      "step": 48100
    },
    {
      "epoch": 4.113329919781533,
      "grad_norm": 3.239645481109619,
      "learning_rate": 3.6294589520395975e-05,
      "loss": 1.2415,
      "step": 48200
    },
    {
      "epoch": 4.121863799283154,
      "grad_norm": 3.1694178581237793,
      "learning_rate": 3.626614325539056e-05,
      "loss": 1.2368,
      "step": 48300
    },
    {
      "epoch": 4.130397678784775,
      "grad_norm": 3.13504695892334,
      "learning_rate": 3.623769699038516e-05,
      "loss": 1.2355,
      "step": 48400
    },
    {
      "epoch": 4.138931558286397,
      "grad_norm": 3.4787302017211914,
      "learning_rate": 3.620925072537976e-05,
      "loss": 1.237,
      "step": 48500
    },
    {
      "epoch": 4.147465437788019,
      "grad_norm": 3.4288065433502197,
      "learning_rate": 3.6180804460374355e-05,
      "loss": 1.2255,
      "step": 48600
    },
    {
      "epoch": 4.1559993172896394,
      "grad_norm": 3.8624370098114014,
      "learning_rate": 3.615235819536895e-05,
      "loss": 1.2356,
      "step": 48700
    },
    {
      "epoch": 4.164533196791261,
      "grad_norm": 3.4479191303253174,
      "learning_rate": 3.6123911930363545e-05,
      "loss": 1.2343,
      "step": 48800
    },
    {
      "epoch": 4.173067076292883,
      "grad_norm": 4.172523021697998,
      "learning_rate": 3.609546566535814e-05,
      "loss": 1.237,
      "step": 48900
    },
    {
      "epoch": 4.181600955794504,
      "grad_norm": 3.2069904804229736,
      "learning_rate": 3.6067019400352736e-05,
      "loss": 1.2385,
      "step": 49000
    },
    {
      "epoch": 4.181600955794504,
      "eval_loss": 1.0329755544662476,
      "eval_runtime": 63.2587,
      "eval_samples_per_second": 623.946,
      "eval_steps_per_second": 77.997,
      "step": 49000
    },
    {
      "epoch": 4.190134835296126,
      "grad_norm": 3.6241331100463867,
      "learning_rate": 3.603857313534733e-05,
      "loss": 1.2366,
      "step": 49100
    },
    {
      "epoch": 4.198668714797747,
      "grad_norm": 3.2716732025146484,
      "learning_rate": 3.6010126870341926e-05,
      "loss": 1.2352,
      "step": 49200
    },
    {
      "epoch": 4.2072025942993685,
      "grad_norm": 3.912886619567871,
      "learning_rate": 3.598168060533652e-05,
      "loss": 1.2584,
      "step": 49300
    },
    {
      "epoch": 4.21573647380099,
      "grad_norm": 3.795285940170288,
      "learning_rate": 3.5953234340331116e-05,
      "loss": 1.2452,
      "step": 49400
    },
    {
      "epoch": 4.224270353302611,
      "grad_norm": 3.4775047302246094,
      "learning_rate": 3.592478807532571e-05,
      "loss": 1.2471,
      "step": 49500
    },
    {
      "epoch": 4.232804232804233,
      "grad_norm": 3.729041814804077,
      "learning_rate": 3.5896341810320306e-05,
      "loss": 1.2445,
      "step": 49600
    },
    {
      "epoch": 4.241338112305854,
      "grad_norm": 3.4612412452697754,
      "learning_rate": 3.586818000796496e-05,
      "loss": 1.2342,
      "step": 49700
    },
    {
      "epoch": 4.249871991807476,
      "grad_norm": 2.922675371170044,
      "learning_rate": 3.583973374295955e-05,
      "loss": 1.2266,
      "step": 49800
    },
    {
      "epoch": 4.2584058713090975,
      "grad_norm": 3.5474884510040283,
      "learning_rate": 3.581128747795415e-05,
      "loss": 1.2216,
      "step": 49900
    },
    {
      "epoch": 4.266939750810718,
      "grad_norm": 3.9418046474456787,
      "learning_rate": 3.578284121294874e-05,
      "loss": 1.2393,
      "step": 50000
    },
    {
      "epoch": 4.266939750810718,
      "eval_loss": 1.031161904335022,
      "eval_runtime": 63.6468,
      "eval_samples_per_second": 620.141,
      "eval_steps_per_second": 77.522,
      "step": 50000
    },
    {
      "epoch": 4.27547363031234,
      "grad_norm": 3.063220739364624,
      "learning_rate": 3.575439494794334e-05,
      "loss": 1.2208,
      "step": 50100
    },
    {
      "epoch": 4.284007509813962,
      "grad_norm": 3.878382921218872,
      "learning_rate": 3.572594868293793e-05,
      "loss": 1.241,
      "step": 50200
    },
    {
      "epoch": 4.292541389315583,
      "grad_norm": 3.1572701930999756,
      "learning_rate": 3.569750241793253e-05,
      "loss": 1.2406,
      "step": 50300
    },
    {
      "epoch": 4.301075268817204,
      "grad_norm": 3.272484540939331,
      "learning_rate": 3.566905615292712e-05,
      "loss": 1.2301,
      "step": 50400
    },
    {
      "epoch": 4.309609148318826,
      "grad_norm": 3.579853057861328,
      "learning_rate": 3.564060988792172e-05,
      "loss": 1.228,
      "step": 50500
    },
    {
      "epoch": 4.318143027820447,
      "grad_norm": 3.357964038848877,
      "learning_rate": 3.561216362291631e-05,
      "loss": 1.2265,
      "step": 50600
    },
    {
      "epoch": 4.326676907322069,
      "grad_norm": 3.4854092597961426,
      "learning_rate": 3.558371735791091e-05,
      "loss": 1.2302,
      "step": 50700
    },
    {
      "epoch": 4.33521078682369,
      "grad_norm": 3.7092232704162598,
      "learning_rate": 3.55552710929055e-05,
      "loss": 1.2304,
      "step": 50800
    },
    {
      "epoch": 4.343744666325311,
      "grad_norm": 3.4502017498016357,
      "learning_rate": 3.55268248279001e-05,
      "loss": 1.2256,
      "step": 50900
    },
    {
      "epoch": 4.352278545826933,
      "grad_norm": 3.6997501850128174,
      "learning_rate": 3.5498378562894693e-05,
      "loss": 1.2345,
      "step": 51000
    },
    {
      "epoch": 4.352278545826933,
      "eval_loss": 1.028694748878479,
      "eval_runtime": 64.1956,
      "eval_samples_per_second": 614.839,
      "eval_steps_per_second": 76.859,
      "step": 51000
    },
    {
      "epoch": 4.360812425328555,
      "grad_norm": 3.8465523719787598,
      "learning_rate": 3.546993229788929e-05,
      "loss": 1.2396,
      "step": 51100
    },
    {
      "epoch": 4.3693463048301755,
      "grad_norm": 3.109318494796753,
      "learning_rate": 3.5441486032883884e-05,
      "loss": 1.2463,
      "step": 51200
    },
    {
      "epoch": 4.377880184331797,
      "grad_norm": 3.6320998668670654,
      "learning_rate": 3.5413324230528535e-05,
      "loss": 1.2349,
      "step": 51300
    },
    {
      "epoch": 4.386414063833419,
      "grad_norm": 3.227299928665161,
      "learning_rate": 3.538487796552313e-05,
      "loss": 1.2227,
      "step": 51400
    },
    {
      "epoch": 4.3949479433350405,
      "grad_norm": 3.6807172298431396,
      "learning_rate": 3.5356431700517725e-05,
      "loss": 1.2348,
      "step": 51500
    },
    {
      "epoch": 4.403481822836661,
      "grad_norm": 3.169285297393799,
      "learning_rate": 3.532798543551232e-05,
      "loss": 1.2286,
      "step": 51600
    },
    {
      "epoch": 4.412015702338283,
      "grad_norm": 3.6601598262786865,
      "learning_rate": 3.5299539170506916e-05,
      "loss": 1.2061,
      "step": 51700
    },
    {
      "epoch": 4.4205495818399045,
      "grad_norm": 3.4780237674713135,
      "learning_rate": 3.5271092905501504e-05,
      "loss": 1.2242,
      "step": 51800
    },
    {
      "epoch": 4.429083461341526,
      "grad_norm": 4.090949535369873,
      "learning_rate": 3.52426466404961e-05,
      "loss": 1.2154,
      "step": 51900
    },
    {
      "epoch": 4.437617340843147,
      "grad_norm": 3.135373830795288,
      "learning_rate": 3.52142003754907e-05,
      "loss": 1.2257,
      "step": 52000
    },
    {
      "epoch": 4.437617340843147,
      "eval_loss": 1.0232938528060913,
      "eval_runtime": 64.0071,
      "eval_samples_per_second": 616.651,
      "eval_steps_per_second": 77.085,
      "step": 52000
    },
    {
      "epoch": 4.446151220344769,
      "grad_norm": 3.7518444061279297,
      "learning_rate": 3.5185754110485296e-05,
      "loss": 1.2259,
      "step": 52100
    },
    {
      "epoch": 4.45468509984639,
      "grad_norm": 3.9508068561553955,
      "learning_rate": 3.515730784547989e-05,
      "loss": 1.2125,
      "step": 52200
    },
    {
      "epoch": 4.463218979348012,
      "grad_norm": 3.5180888175964355,
      "learning_rate": 3.5128861580474486e-05,
      "loss": 1.216,
      "step": 52300
    },
    {
      "epoch": 4.471752858849633,
      "grad_norm": 3.632807731628418,
      "learning_rate": 3.510041531546908e-05,
      "loss": 1.2207,
      "step": 52400
    },
    {
      "epoch": 4.480286738351254,
      "grad_norm": 3.3927478790283203,
      "learning_rate": 3.5071969050463676e-05,
      "loss": 1.2213,
      "step": 52500
    },
    {
      "epoch": 4.488820617852876,
      "grad_norm": 3.3333072662353516,
      "learning_rate": 3.504352278545827e-05,
      "loss": 1.2484,
      "step": 52600
    },
    {
      "epoch": 4.497354497354498,
      "grad_norm": 3.4583215713500977,
      "learning_rate": 3.5015076520452866e-05,
      "loss": 1.2523,
      "step": 52700
    },
    {
      "epoch": 4.505888376856118,
      "grad_norm": 3.23722767829895,
      "learning_rate": 3.498663025544746e-05,
      "loss": 1.2317,
      "step": 52800
    },
    {
      "epoch": 4.51442225635774,
      "grad_norm": 3.2781782150268555,
      "learning_rate": 3.4958183990442056e-05,
      "loss": 1.2238,
      "step": 52900
    },
    {
      "epoch": 4.522956135859362,
      "grad_norm": 3.791475534439087,
      "learning_rate": 3.492973772543665e-05,
      "loss": 1.2359,
      "step": 53000
    },
    {
      "epoch": 4.522956135859362,
      "eval_loss": 1.0229250192642212,
      "eval_runtime": 63.5856,
      "eval_samples_per_second": 620.738,
      "eval_steps_per_second": 77.596,
      "step": 53000
    },
    {
      "epoch": 4.531490015360983,
      "grad_norm": 3.4865200519561768,
      "learning_rate": 3.4901291460431246e-05,
      "loss": 1.2281,
      "step": 53100
    },
    {
      "epoch": 4.540023894862604,
      "grad_norm": 3.817202091217041,
      "learning_rate": 3.487284519542584e-05,
      "loss": 1.2239,
      "step": 53200
    },
    {
      "epoch": 4.548557774364226,
      "grad_norm": 3.3717617988586426,
      "learning_rate": 3.4844398930420436e-05,
      "loss": 1.2161,
      "step": 53300
    },
    {
      "epoch": 4.5570916538658475,
      "grad_norm": 3.623222827911377,
      "learning_rate": 3.481595266541503e-05,
      "loss": 1.2238,
      "step": 53400
    },
    {
      "epoch": 4.565625533367469,
      "grad_norm": 3.4928503036499023,
      "learning_rate": 3.4787506400409627e-05,
      "loss": 1.195,
      "step": 53500
    },
    {
      "epoch": 4.57415941286909,
      "grad_norm": 3.5759899616241455,
      "learning_rate": 3.475906013540423e-05,
      "loss": 1.2147,
      "step": 53600
    },
    {
      "epoch": 4.5826932923707115,
      "grad_norm": 3.4019320011138916,
      "learning_rate": 3.4730613870398823e-05,
      "loss": 1.2213,
      "step": 53700
    },
    {
      "epoch": 4.591227171872333,
      "grad_norm": 3.5013604164123535,
      "learning_rate": 3.470216760539342e-05,
      "loss": 1.2079,
      "step": 53800
    },
    {
      "epoch": 4.599761051373955,
      "grad_norm": 3.686025619506836,
      "learning_rate": 3.4674005803038063e-05,
      "loss": 1.2272,
      "step": 53900
    },
    {
      "epoch": 4.6082949308755765,
      "grad_norm": 3.288325548171997,
      "learning_rate": 3.464555953803266e-05,
      "loss": 1.232,
      "step": 54000
    },
    {
      "epoch": 4.6082949308755765,
      "eval_loss": 1.0134446620941162,
      "eval_runtime": 64.7351,
      "eval_samples_per_second": 609.715,
      "eval_steps_per_second": 76.218,
      "step": 54000
    },
    {
      "epoch": 4.616828810377197,
      "grad_norm": 3.896493434906006,
      "learning_rate": 3.4617113273027254e-05,
      "loss": 1.2151,
      "step": 54100
    },
    {
      "epoch": 4.625362689878819,
      "grad_norm": 3.107149600982666,
      "learning_rate": 3.458866700802185e-05,
      "loss": 1.2211,
      "step": 54200
    },
    {
      "epoch": 4.633896569380441,
      "grad_norm": 3.4960384368896484,
      "learning_rate": 3.4560220743016444e-05,
      "loss": 1.2178,
      "step": 54300
    },
    {
      "epoch": 4.642430448882061,
      "grad_norm": 3.296459913253784,
      "learning_rate": 3.453177447801104e-05,
      "loss": 1.229,
      "step": 54400
    },
    {
      "epoch": 4.650964328383683,
      "grad_norm": 3.239849328994751,
      "learning_rate": 3.4503328213005634e-05,
      "loss": 1.2077,
      "step": 54500
    },
    {
      "epoch": 4.659498207885305,
      "grad_norm": 3.6565356254577637,
      "learning_rate": 3.447488194800023e-05,
      "loss": 1.2165,
      "step": 54600
    },
    {
      "epoch": 4.668032087386926,
      "grad_norm": 3.5132510662078857,
      "learning_rate": 3.4446435682994824e-05,
      "loss": 1.2235,
      "step": 54700
    },
    {
      "epoch": 4.676565966888548,
      "grad_norm": 2.7538840770721436,
      "learning_rate": 3.441798941798942e-05,
      "loss": 1.2117,
      "step": 54800
    },
    {
      "epoch": 4.685099846390169,
      "grad_norm": 3.8430678844451904,
      "learning_rate": 3.4389543152984014e-05,
      "loss": 1.2205,
      "step": 54900
    },
    {
      "epoch": 4.69363372589179,
      "grad_norm": 3.8609180450439453,
      "learning_rate": 3.436109688797861e-05,
      "loss": 1.2187,
      "step": 55000
    },
    {
      "epoch": 4.69363372589179,
      "eval_loss": 1.0119959115982056,
      "eval_runtime": 64.6231,
      "eval_samples_per_second": 610.773,
      "eval_steps_per_second": 76.35,
      "step": 55000
    },
    {
      "epoch": 4.702167605393412,
      "grad_norm": 4.012221336364746,
      "learning_rate": 3.4332650622973204e-05,
      "loss": 1.2355,
      "step": 55100
    },
    {
      "epoch": 4.710701484895033,
      "grad_norm": 3.390822172164917,
      "learning_rate": 3.43042043579678e-05,
      "loss": 1.2266,
      "step": 55200
    },
    {
      "epoch": 4.7192353643966545,
      "grad_norm": 3.2752199172973633,
      "learning_rate": 3.4275758092962394e-05,
      "loss": 1.2215,
      "step": 55300
    },
    {
      "epoch": 4.727769243898276,
      "grad_norm": 3.086373805999756,
      "learning_rate": 3.424731182795699e-05,
      "loss": 1.2183,
      "step": 55400
    },
    {
      "epoch": 4.736303123399898,
      "grad_norm": 3.4042763710021973,
      "learning_rate": 3.4218865562951584e-05,
      "loss": 1.2146,
      "step": 55500
    },
    {
      "epoch": 4.744837002901519,
      "grad_norm": 3.3657076358795166,
      "learning_rate": 3.419041929794618e-05,
      "loss": 1.2148,
      "step": 55600
    },
    {
      "epoch": 4.75337088240314,
      "grad_norm": 3.758791923522949,
      "learning_rate": 3.4161973032940775e-05,
      "loss": 1.2164,
      "step": 55700
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 3.2885801792144775,
      "learning_rate": 3.413352676793537e-05,
      "loss": 1.2118,
      "step": 55800
    },
    {
      "epoch": 4.7704386414063835,
      "grad_norm": 3.2036755084991455,
      "learning_rate": 3.4105080502929965e-05,
      "loss": 1.2172,
      "step": 55900
    },
    {
      "epoch": 4.778972520908004,
      "grad_norm": 3.3440322875976562,
      "learning_rate": 3.407663423792456e-05,
      "loss": 1.2186,
      "step": 56000
    },
    {
      "epoch": 4.778972520908004,
      "eval_loss": 1.0081491470336914,
      "eval_runtime": 63.8906,
      "eval_samples_per_second": 617.775,
      "eval_steps_per_second": 77.226,
      "step": 56000
    },
    {
      "epoch": 4.787506400409626,
      "grad_norm": 3.4157674312591553,
      "learning_rate": 3.404818797291916e-05,
      "loss": 1.1988,
      "step": 56100
    },
    {
      "epoch": 4.796040279911248,
      "grad_norm": 3.3673388957977295,
      "learning_rate": 3.401974170791376e-05,
      "loss": 1.2232,
      "step": 56200
    },
    {
      "epoch": 4.804574159412869,
      "grad_norm": 3.494115114212036,
      "learning_rate": 3.399129544290835e-05,
      "loss": 1.2011,
      "step": 56300
    },
    {
      "epoch": 4.813108038914491,
      "grad_norm": 3.326279640197754,
      "learning_rate": 3.396284917790295e-05,
      "loss": 1.2114,
      "step": 56400
    },
    {
      "epoch": 4.821641918416112,
      "grad_norm": 3.6319427490234375,
      "learning_rate": 3.393440291289754e-05,
      "loss": 1.2087,
      "step": 56500
    },
    {
      "epoch": 4.830175797917733,
      "grad_norm": 3.7953097820281982,
      "learning_rate": 3.390595664789214e-05,
      "loss": 1.2116,
      "step": 56600
    },
    {
      "epoch": 4.838709677419355,
      "grad_norm": 3.4947166442871094,
      "learning_rate": 3.387751038288673e-05,
      "loss": 1.2141,
      "step": 56700
    },
    {
      "epoch": 4.847243556920977,
      "grad_norm": 3.568209409713745,
      "learning_rate": 3.384906411788133e-05,
      "loss": 1.2131,
      "step": 56800
    },
    {
      "epoch": 4.855777436422597,
      "grad_norm": 3.6430792808532715,
      "learning_rate": 3.382061785287592e-05,
      "loss": 1.216,
      "step": 56900
    },
    {
      "epoch": 4.864311315924219,
      "grad_norm": 3.711925745010376,
      "learning_rate": 3.379217158787051e-05,
      "loss": 1.1972,
      "step": 57000
    },
    {
      "epoch": 4.864311315924219,
      "eval_loss": 1.0093086957931519,
      "eval_runtime": 63.7171,
      "eval_samples_per_second": 619.457,
      "eval_steps_per_second": 77.436,
      "step": 57000
    },
    {
      "epoch": 4.872845195425841,
      "grad_norm": 3.664731025695801,
      "learning_rate": 3.3763725322865105e-05,
      "loss": 1.2086,
      "step": 57100
    },
    {
      "epoch": 4.881379074927462,
      "grad_norm": 3.5595836639404297,
      "learning_rate": 3.37352790578597e-05,
      "loss": 1.2146,
      "step": 57200
    },
    {
      "epoch": 4.889912954429083,
      "grad_norm": 3.6040942668914795,
      "learning_rate": 3.3706832792854296e-05,
      "loss": 1.2037,
      "step": 57300
    },
    {
      "epoch": 4.898446833930705,
      "grad_norm": 3.3486039638519287,
      "learning_rate": 3.367838652784889e-05,
      "loss": 1.1993,
      "step": 57400
    },
    {
      "epoch": 4.9069807134323264,
      "grad_norm": 3.3644344806671143,
      "learning_rate": 3.3649940262843486e-05,
      "loss": 1.1956,
      "step": 57500
    },
    {
      "epoch": 4.915514592933948,
      "grad_norm": 3.133335828781128,
      "learning_rate": 3.362149399783808e-05,
      "loss": 1.2172,
      "step": 57600
    },
    {
      "epoch": 4.924048472435569,
      "grad_norm": 3.353348731994629,
      "learning_rate": 3.359304773283268e-05,
      "loss": 1.2138,
      "step": 57700
    },
    {
      "epoch": 4.9325823519371905,
      "grad_norm": 3.417337417602539,
      "learning_rate": 3.356460146782728e-05,
      "loss": 1.2006,
      "step": 57800
    },
    {
      "epoch": 4.941116231438812,
      "grad_norm": 3.647233486175537,
      "learning_rate": 3.353643966547192e-05,
      "loss": 1.2122,
      "step": 57900
    },
    {
      "epoch": 4.949650110940434,
      "grad_norm": 3.4377198219299316,
      "learning_rate": 3.350799340046652e-05,
      "loss": 1.2082,
      "step": 58000
    },
    {
      "epoch": 4.949650110940434,
      "eval_loss": 1.0017173290252686,
      "eval_runtime": 64.1344,
      "eval_samples_per_second": 615.426,
      "eval_steps_per_second": 76.932,
      "step": 58000
    },
    {
      "epoch": 4.958183990442055,
      "grad_norm": 3.1458001136779785,
      "learning_rate": 3.347954713546111e-05,
      "loss": 1.2059,
      "step": 58100
    },
    {
      "epoch": 4.966717869943676,
      "grad_norm": 3.450125217437744,
      "learning_rate": 3.345110087045571e-05,
      "loss": 1.2014,
      "step": 58200
    },
    {
      "epoch": 4.975251749445298,
      "grad_norm": 3.2878756523132324,
      "learning_rate": 3.34226546054503e-05,
      "loss": 1.2115,
      "step": 58300
    },
    {
      "epoch": 4.98378562894692,
      "grad_norm": 3.2547709941864014,
      "learning_rate": 3.33942083404449e-05,
      "loss": 1.2202,
      "step": 58400
    },
    {
      "epoch": 4.99231950844854,
      "grad_norm": 3.183800458908081,
      "learning_rate": 3.336576207543949e-05,
      "loss": 1.1997,
      "step": 58500
    },
    {
      "epoch": 5.000853387950162,
      "grad_norm": 3.2523059844970703,
      "learning_rate": 3.3337315810434095e-05,
      "loss": 1.2136,
      "step": 58600
    },
    {
      "epoch": 5.009387267451784,
      "grad_norm": 3.6686887741088867,
      "learning_rate": 3.330886954542869e-05,
      "loss": 1.1928,
      "step": 58700
    },
    {
      "epoch": 5.017921146953405,
      "grad_norm": 3.4784207344055176,
      "learning_rate": 3.3280423280423285e-05,
      "loss": 1.2085,
      "step": 58800
    },
    {
      "epoch": 5.026455026455026,
      "grad_norm": 3.3933773040771484,
      "learning_rate": 3.325197701541788e-05,
      "loss": 1.198,
      "step": 58900
    },
    {
      "epoch": 5.034988905956648,
      "grad_norm": 3.4516594409942627,
      "learning_rate": 3.3223530750412475e-05,
      "loss": 1.2037,
      "step": 59000
    },
    {
      "epoch": 5.034988905956648,
      "eval_loss": 1.0017335414886475,
      "eval_runtime": 63.9854,
      "eval_samples_per_second": 616.86,
      "eval_steps_per_second": 77.111,
      "step": 59000
    },
    {
      "epoch": 5.043522785458269,
      "grad_norm": 3.273247003555298,
      "learning_rate": 3.319508448540707e-05,
      "loss": 1.1975,
      "step": 59100
    },
    {
      "epoch": 5.052056664959891,
      "grad_norm": 3.587566614151001,
      "learning_rate": 3.3166638220401665e-05,
      "loss": 1.198,
      "step": 59200
    },
    {
      "epoch": 5.060590544461512,
      "grad_norm": 3.848876953125,
      "learning_rate": 3.313819195539626e-05,
      "loss": 1.1988,
      "step": 59300
    },
    {
      "epoch": 5.0691244239631335,
      "grad_norm": 3.2438409328460693,
      "learning_rate": 3.3109745690390855e-05,
      "loss": 1.1949,
      "step": 59400
    },
    {
      "epoch": 5.077658303464755,
      "grad_norm": 3.285132884979248,
      "learning_rate": 3.308129942538545e-05,
      "loss": 1.1915,
      "step": 59500
    },
    {
      "epoch": 5.086192182966377,
      "grad_norm": 3.7005467414855957,
      "learning_rate": 3.3052853160380045e-05,
      "loss": 1.2014,
      "step": 59600
    },
    {
      "epoch": 5.0947260624679975,
      "grad_norm": 3.445190191268921,
      "learning_rate": 3.302440689537464e-05,
      "loss": 1.2155,
      "step": 59700
    },
    {
      "epoch": 5.103259941969619,
      "grad_norm": 3.2869679927825928,
      "learning_rate": 3.2995960630369235e-05,
      "loss": 1.204,
      "step": 59800
    },
    {
      "epoch": 5.111793821471241,
      "grad_norm": 3.1870973110198975,
      "learning_rate": 3.296779882801389e-05,
      "loss": 1.2124,
      "step": 59900
    },
    {
      "epoch": 5.1203277009728625,
      "grad_norm": 3.3844797611236572,
      "learning_rate": 3.293935256300848e-05,
      "loss": 1.199,
      "step": 60000
    },
    {
      "epoch": 5.1203277009728625,
      "eval_loss": 0.9957778453826904,
      "eval_runtime": 63.0536,
      "eval_samples_per_second": 625.976,
      "eval_steps_per_second": 78.251,
      "step": 60000
    },
    {
      "epoch": 5.128861580474483,
      "grad_norm": 3.491363525390625,
      "learning_rate": 3.291090629800308e-05,
      "loss": 1.1896,
      "step": 60100
    },
    {
      "epoch": 5.137395459976105,
      "grad_norm": 3.76497220993042,
      "learning_rate": 3.288246003299767e-05,
      "loss": 1.1887,
      "step": 60200
    },
    {
      "epoch": 5.145929339477727,
      "grad_norm": 3.667365789413452,
      "learning_rate": 3.285401376799227e-05,
      "loss": 1.1997,
      "step": 60300
    },
    {
      "epoch": 5.154463218979348,
      "grad_norm": 3.9669487476348877,
      "learning_rate": 3.282556750298686e-05,
      "loss": 1.199,
      "step": 60400
    },
    {
      "epoch": 5.16299709848097,
      "grad_norm": 3.510868787765503,
      "learning_rate": 3.279712123798145e-05,
      "loss": 1.2183,
      "step": 60500
    },
    {
      "epoch": 5.171530977982591,
      "grad_norm": 3.184826135635376,
      "learning_rate": 3.2768674972976046e-05,
      "loss": 1.1983,
      "step": 60600
    },
    {
      "epoch": 5.180064857484212,
      "grad_norm": 3.4774441719055176,
      "learning_rate": 3.274022870797064e-05,
      "loss": 1.2012,
      "step": 60700
    },
    {
      "epoch": 5.188598736985834,
      "grad_norm": 3.841663122177124,
      "learning_rate": 3.2711782442965236e-05,
      "loss": 1.1915,
      "step": 60800
    },
    {
      "epoch": 5.197132616487456,
      "grad_norm": 3.6375083923339844,
      "learning_rate": 3.268333617795983e-05,
      "loss": 1.2109,
      "step": 60900
    },
    {
      "epoch": 5.205666495989076,
      "grad_norm": 3.3556859493255615,
      "learning_rate": 3.2654889912954426e-05,
      "loss": 1.1842,
      "step": 61000
    },
    {
      "epoch": 5.205666495989076,
      "eval_loss": 0.9915396571159363,
      "eval_runtime": 63.8306,
      "eval_samples_per_second": 618.356,
      "eval_steps_per_second": 77.298,
      "step": 61000
    },
    {
      "epoch": 5.214200375490698,
      "grad_norm": 3.496572732925415,
      "learning_rate": 3.262644364794902e-05,
      "loss": 1.197,
      "step": 61100
    },
    {
      "epoch": 5.22273425499232,
      "grad_norm": 3.552064895629883,
      "learning_rate": 3.259799738294362e-05,
      "loss": 1.1952,
      "step": 61200
    },
    {
      "epoch": 5.231268134493941,
      "grad_norm": 3.2729849815368652,
      "learning_rate": 3.256955111793822e-05,
      "loss": 1.1886,
      "step": 61300
    },
    {
      "epoch": 5.239802013995562,
      "grad_norm": 4.062591552734375,
      "learning_rate": 3.254110485293281e-05,
      "loss": 1.198,
      "step": 61400
    },
    {
      "epoch": 5.248335893497184,
      "grad_norm": 3.4771368503570557,
      "learning_rate": 3.251265858792741e-05,
      "loss": 1.2091,
      "step": 61500
    },
    {
      "epoch": 5.256869772998805,
      "grad_norm": 3.317338228225708,
      "learning_rate": 3.2484212322922e-05,
      "loss": 1.1951,
      "step": 61600
    },
    {
      "epoch": 5.265403652500427,
      "grad_norm": 3.4230356216430664,
      "learning_rate": 3.24557660579166e-05,
      "loss": 1.1818,
      "step": 61700
    },
    {
      "epoch": 5.273937532002048,
      "grad_norm": 3.313976287841797,
      "learning_rate": 3.242731979291119e-05,
      "loss": 1.197,
      "step": 61800
    },
    {
      "epoch": 5.2824714115036695,
      "grad_norm": 3.8192977905273438,
      "learning_rate": 3.239915799055584e-05,
      "loss": 1.1947,
      "step": 61900
    },
    {
      "epoch": 5.291005291005291,
      "grad_norm": 4.078474521636963,
      "learning_rate": 3.237071172555043e-05,
      "loss": 1.1884,
      "step": 62000
    },
    {
      "epoch": 5.291005291005291,
      "eval_loss": 0.9924935102462769,
      "eval_runtime": 63.8606,
      "eval_samples_per_second": 618.065,
      "eval_steps_per_second": 77.262,
      "step": 62000
    },
    {
      "epoch": 5.299539170506913,
      "grad_norm": 3.3724915981292725,
      "learning_rate": 3.234226546054503e-05,
      "loss": 1.1877,
      "step": 62100
    },
    {
      "epoch": 5.308073050008534,
      "grad_norm": 3.243084192276001,
      "learning_rate": 3.231381919553963e-05,
      "loss": 1.2016,
      "step": 62200
    },
    {
      "epoch": 5.316606929510155,
      "grad_norm": 3.2875635623931885,
      "learning_rate": 3.2285372930534225e-05,
      "loss": 1.1808,
      "step": 62300
    },
    {
      "epoch": 5.325140809011777,
      "grad_norm": 3.756495475769043,
      "learning_rate": 3.225692666552882e-05,
      "loss": 1.1935,
      "step": 62400
    },
    {
      "epoch": 5.3336746885133985,
      "grad_norm": 3.0690178871154785,
      "learning_rate": 3.2228480400523415e-05,
      "loss": 1.1992,
      "step": 62500
    },
    {
      "epoch": 5.342208568015019,
      "grad_norm": 3.352822780609131,
      "learning_rate": 3.220003413551801e-05,
      "loss": 1.1949,
      "step": 62600
    },
    {
      "epoch": 5.350742447516641,
      "grad_norm": 3.413693428039551,
      "learning_rate": 3.2171587870512606e-05,
      "loss": 1.1856,
      "step": 62700
    },
    {
      "epoch": 5.359276327018263,
      "grad_norm": 3.4281790256500244,
      "learning_rate": 3.21431416055072e-05,
      "loss": 1.184,
      "step": 62800
    },
    {
      "epoch": 5.367810206519884,
      "grad_norm": 3.550370454788208,
      "learning_rate": 3.2114695340501796e-05,
      "loss": 1.1851,
      "step": 62900
    },
    {
      "epoch": 5.376344086021505,
      "grad_norm": 3.5169565677642822,
      "learning_rate": 3.208624907549639e-05,
      "loss": 1.1842,
      "step": 63000
    },
    {
      "epoch": 5.376344086021505,
      "eval_loss": 0.9881500005722046,
      "eval_runtime": 63.9677,
      "eval_samples_per_second": 617.03,
      "eval_steps_per_second": 77.133,
      "step": 63000
    },
    {
      "epoch": 5.384877965523127,
      "grad_norm": 3.604403257369995,
      "learning_rate": 3.2057802810490986e-05,
      "loss": 1.2031,
      "step": 63100
    },
    {
      "epoch": 5.393411845024748,
      "grad_norm": 3.5951778888702393,
      "learning_rate": 3.202935654548558e-05,
      "loss": 1.1883,
      "step": 63200
    },
    {
      "epoch": 5.40194572452637,
      "grad_norm": 3.559638500213623,
      "learning_rate": 3.2000910280480176e-05,
      "loss": 1.1854,
      "step": 63300
    },
    {
      "epoch": 5.410479604027991,
      "grad_norm": 3.4052534103393555,
      "learning_rate": 3.197246401547477e-05,
      "loss": 1.2036,
      "step": 63400
    },
    {
      "epoch": 5.419013483529612,
      "grad_norm": 3.377141237258911,
      "learning_rate": 3.1944017750469366e-05,
      "loss": 1.1847,
      "step": 63500
    },
    {
      "epoch": 5.427547363031234,
      "grad_norm": 3.4502265453338623,
      "learning_rate": 3.1915571485463954e-05,
      "loss": 1.1781,
      "step": 63600
    },
    {
      "epoch": 5.436081242532856,
      "grad_norm": 3.733018636703491,
      "learning_rate": 3.1887125220458556e-05,
      "loss": 1.1938,
      "step": 63700
    },
    {
      "epoch": 5.4446151220344765,
      "grad_norm": 3.2883548736572266,
      "learning_rate": 3.185867895545315e-05,
      "loss": 1.1807,
      "step": 63800
    },
    {
      "epoch": 5.453149001536098,
      "grad_norm": 3.563809633255005,
      "learning_rate": 3.18305171530978e-05,
      "loss": 1.1854,
      "step": 63900
    },
    {
      "epoch": 5.46168288103772,
      "grad_norm": 3.5701277256011963,
      "learning_rate": 3.180207088809239e-05,
      "loss": 1.1863,
      "step": 64000
    },
    {
      "epoch": 5.46168288103772,
      "eval_loss": 0.980884313583374,
      "eval_runtime": 63.5761,
      "eval_samples_per_second": 620.831,
      "eval_steps_per_second": 77.608,
      "step": 64000
    },
    {
      "epoch": 5.4702167605393415,
      "grad_norm": 3.6901299953460693,
      "learning_rate": 3.1773624623086986e-05,
      "loss": 1.1885,
      "step": 64100
    },
    {
      "epoch": 5.478750640040962,
      "grad_norm": 3.848520517349243,
      "learning_rate": 3.174517835808158e-05,
      "loss": 1.1967,
      "step": 64200
    },
    {
      "epoch": 5.487284519542584,
      "grad_norm": 3.6690642833709717,
      "learning_rate": 3.1716732093076176e-05,
      "loss": 1.1807,
      "step": 64300
    },
    {
      "epoch": 5.4958183990442055,
      "grad_norm": 3.5981853008270264,
      "learning_rate": 3.168828582807077e-05,
      "loss": 1.1882,
      "step": 64400
    },
    {
      "epoch": 5.504352278545827,
      "grad_norm": 3.4453532695770264,
      "learning_rate": 3.1659839563065367e-05,
      "loss": 1.1937,
      "step": 64500
    },
    {
      "epoch": 5.512886158047449,
      "grad_norm": 3.4242358207702637,
      "learning_rate": 3.163139329805996e-05,
      "loss": 1.1855,
      "step": 64600
    },
    {
      "epoch": 5.52142003754907,
      "grad_norm": 3.3031792640686035,
      "learning_rate": 3.1602947033054563e-05,
      "loss": 1.189,
      "step": 64700
    },
    {
      "epoch": 5.529953917050691,
      "grad_norm": 3.782339334487915,
      "learning_rate": 3.157450076804916e-05,
      "loss": 1.1717,
      "step": 64800
    },
    {
      "epoch": 5.538487796552313,
      "grad_norm": 3.448438882827759,
      "learning_rate": 3.1546054503043754e-05,
      "loss": 1.1793,
      "step": 64900
    },
    {
      "epoch": 5.547021676053934,
      "grad_norm": 3.370455503463745,
      "learning_rate": 3.151760823803835e-05,
      "loss": 1.1953,
      "step": 65000
    },
    {
      "epoch": 5.547021676053934,
      "eval_loss": 0.9757853150367737,
      "eval_runtime": 64.1166,
      "eval_samples_per_second": 615.597,
      "eval_steps_per_second": 76.954,
      "step": 65000
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 3.201064348220825,
      "learning_rate": 3.1489161973032944e-05,
      "loss": 1.1842,
      "step": 65100
    },
    {
      "epoch": 5.564089435057177,
      "grad_norm": 3.529386520385742,
      "learning_rate": 3.146071570802754e-05,
      "loss": 1.1858,
      "step": 65200
    },
    {
      "epoch": 5.572623314558799,
      "grad_norm": 3.119697332382202,
      "learning_rate": 3.1432269443022134e-05,
      "loss": 1.1811,
      "step": 65300
    },
    {
      "epoch": 5.58115719406042,
      "grad_norm": 3.5603184700012207,
      "learning_rate": 3.140382317801673e-05,
      "loss": 1.1699,
      "step": 65400
    },
    {
      "epoch": 5.589691073562041,
      "grad_norm": 3.403177499771118,
      "learning_rate": 3.1375376913011324e-05,
      "loss": 1.1831,
      "step": 65500
    },
    {
      "epoch": 5.598224953063663,
      "grad_norm": 3.2767140865325928,
      "learning_rate": 3.134693064800592e-05,
      "loss": 1.1842,
      "step": 65600
    },
    {
      "epoch": 5.606758832565284,
      "grad_norm": 3.5886762142181396,
      "learning_rate": 3.1318484383000514e-05,
      "loss": 1.1804,
      "step": 65700
    },
    {
      "epoch": 5.615292712066905,
      "grad_norm": 3.0140554904937744,
      "learning_rate": 3.129003811799511e-05,
      "loss": 1.167,
      "step": 65800
    },
    {
      "epoch": 5.623826591568527,
      "grad_norm": 3.6392264366149902,
      "learning_rate": 3.126187631563976e-05,
      "loss": 1.1874,
      "step": 65900
    },
    {
      "epoch": 5.6323604710701485,
      "grad_norm": 3.2621450424194336,
      "learning_rate": 3.1233430050634356e-05,
      "loss": 1.1826,
      "step": 66000
    },
    {
      "epoch": 5.6323604710701485,
      "eval_loss": 0.9740868210792542,
      "eval_runtime": 63.7123,
      "eval_samples_per_second": 619.504,
      "eval_steps_per_second": 77.442,
      "step": 66000
    },
    {
      "epoch": 5.64089435057177,
      "grad_norm": 3.360302209854126,
      "learning_rate": 3.120498378562895e-05,
      "loss": 1.1992,
      "step": 66100
    },
    {
      "epoch": 5.649428230073392,
      "grad_norm": 3.443101167678833,
      "learning_rate": 3.1176537520623546e-05,
      "loss": 1.1779,
      "step": 66200
    },
    {
      "epoch": 5.6579621095750126,
      "grad_norm": 3.6133832931518555,
      "learning_rate": 3.114809125561814e-05,
      "loss": 1.1838,
      "step": 66300
    },
    {
      "epoch": 5.666495989076634,
      "grad_norm": 3.382192611694336,
      "learning_rate": 3.1119644990612736e-05,
      "loss": 1.1794,
      "step": 66400
    },
    {
      "epoch": 5.675029868578256,
      "grad_norm": 3.318331718444824,
      "learning_rate": 3.109119872560733e-05,
      "loss": 1.1774,
      "step": 66500
    },
    {
      "epoch": 5.683563748079877,
      "grad_norm": 3.673910140991211,
      "learning_rate": 3.1062752460601926e-05,
      "loss": 1.1778,
      "step": 66600
    },
    {
      "epoch": 5.692097627581498,
      "grad_norm": 3.4243338108062744,
      "learning_rate": 3.103430619559652e-05,
      "loss": 1.1707,
      "step": 66700
    },
    {
      "epoch": 5.70063150708312,
      "grad_norm": 3.7032699584960938,
      "learning_rate": 3.1005859930591116e-05,
      "loss": 1.187,
      "step": 66800
    },
    {
      "epoch": 5.709165386584742,
      "grad_norm": 3.1653902530670166,
      "learning_rate": 3.097741366558571e-05,
      "loss": 1.1794,
      "step": 66900
    },
    {
      "epoch": 5.717699266086363,
      "grad_norm": 3.2299633026123047,
      "learning_rate": 3.0948967400580306e-05,
      "loss": 1.1918,
      "step": 67000
    },
    {
      "epoch": 5.717699266086363,
      "eval_loss": 0.976830780506134,
      "eval_runtime": 63.4633,
      "eval_samples_per_second": 621.934,
      "eval_steps_per_second": 77.746,
      "step": 67000
    },
    {
      "epoch": 5.726233145587984,
      "grad_norm": 3.6745049953460693,
      "learning_rate": 3.0920521135574895e-05,
      "loss": 1.189,
      "step": 67100
    },
    {
      "epoch": 5.734767025089606,
      "grad_norm": 4.002594947814941,
      "learning_rate": 3.0892074870569497e-05,
      "loss": 1.1694,
      "step": 67200
    },
    {
      "epoch": 5.743300904591227,
      "grad_norm": 3.252641439437866,
      "learning_rate": 3.086362860556409e-05,
      "loss": 1.1778,
      "step": 67300
    },
    {
      "epoch": 5.751834784092849,
      "grad_norm": 3.5795366764068604,
      "learning_rate": 3.083518234055869e-05,
      "loss": 1.1713,
      "step": 67400
    },
    {
      "epoch": 5.76036866359447,
      "grad_norm": 3.7468831539154053,
      "learning_rate": 3.080673607555328e-05,
      "loss": 1.1886,
      "step": 67500
    },
    {
      "epoch": 5.768902543096091,
      "grad_norm": 3.0974652767181396,
      "learning_rate": 3.077828981054788e-05,
      "loss": 1.1671,
      "step": 67600
    },
    {
      "epoch": 5.777436422597713,
      "grad_norm": 3.2524547576904297,
      "learning_rate": 3.074984354554247e-05,
      "loss": 1.181,
      "step": 67700
    },
    {
      "epoch": 5.785970302099335,
      "grad_norm": 3.531467914581299,
      "learning_rate": 3.072139728053707e-05,
      "loss": 1.1835,
      "step": 67800
    },
    {
      "epoch": 5.7945041816009555,
      "grad_norm": 3.950143575668335,
      "learning_rate": 3.069323547818171e-05,
      "loss": 1.1878,
      "step": 67900
    },
    {
      "epoch": 5.803038061102577,
      "grad_norm": 3.585265874862671,
      "learning_rate": 3.066478921317631e-05,
      "loss": 1.18,
      "step": 68000
    },
    {
      "epoch": 5.803038061102577,
      "eval_loss": 0.9750033617019653,
      "eval_runtime": 63.8377,
      "eval_samples_per_second": 618.287,
      "eval_steps_per_second": 77.29,
      "step": 68000
    },
    {
      "epoch": 5.811571940604199,
      "grad_norm": 3.319046974182129,
      "learning_rate": 3.06363429481709e-05,
      "loss": 1.1777,
      "step": 68100
    },
    {
      "epoch": 5.8201058201058204,
      "grad_norm": 3.3022892475128174,
      "learning_rate": 3.0607896683165504e-05,
      "loss": 1.1802,
      "step": 68200
    },
    {
      "epoch": 5.828639699607441,
      "grad_norm": 3.365762948989868,
      "learning_rate": 3.05794504181601e-05,
      "loss": 1.1763,
      "step": 68300
    },
    {
      "epoch": 5.837173579109063,
      "grad_norm": 3.2595326900482178,
      "learning_rate": 3.0551004153154694e-05,
      "loss": 1.1696,
      "step": 68400
    },
    {
      "epoch": 5.8457074586106845,
      "grad_norm": 3.4994399547576904,
      "learning_rate": 3.052255788814929e-05,
      "loss": 1.1749,
      "step": 68500
    },
    {
      "epoch": 5.854241338112306,
      "grad_norm": 3.642656087875366,
      "learning_rate": 3.0494111623143884e-05,
      "loss": 1.1839,
      "step": 68600
    },
    {
      "epoch": 5.862775217613927,
      "grad_norm": 2.9601941108703613,
      "learning_rate": 3.046566535813848e-05,
      "loss": 1.1851,
      "step": 68700
    },
    {
      "epoch": 5.871309097115549,
      "grad_norm": 3.2120554447174072,
      "learning_rate": 3.0437219093133074e-05,
      "loss": 1.1688,
      "step": 68800
    },
    {
      "epoch": 5.87984297661717,
      "grad_norm": 3.297140598297119,
      "learning_rate": 3.040877282812767e-05,
      "loss": 1.1585,
      "step": 68900
    },
    {
      "epoch": 5.888376856118792,
      "grad_norm": 3.7937891483306885,
      "learning_rate": 3.0380326563122264e-05,
      "loss": 1.1597,
      "step": 69000
    },
    {
      "epoch": 5.888376856118792,
      "eval_loss": 0.9720855951309204,
      "eval_runtime": 63.8153,
      "eval_samples_per_second": 618.503,
      "eval_steps_per_second": 77.317,
      "step": 69000
    },
    {
      "epoch": 5.896910735620413,
      "grad_norm": 3.3062002658843994,
      "learning_rate": 3.035188029811686e-05,
      "loss": 1.1696,
      "step": 69100
    },
    {
      "epoch": 5.905444615122034,
      "grad_norm": 3.4680137634277344,
      "learning_rate": 3.0323434033111454e-05,
      "loss": 1.1746,
      "step": 69200
    },
    {
      "epoch": 5.913978494623656,
      "grad_norm": 3.0741610527038574,
      "learning_rate": 3.029498776810605e-05,
      "loss": 1.1598,
      "step": 69300
    },
    {
      "epoch": 5.922512374125278,
      "grad_norm": 3.534212112426758,
      "learning_rate": 3.026654150310064e-05,
      "loss": 1.1843,
      "step": 69400
    },
    {
      "epoch": 5.931046253626898,
      "grad_norm": 3.408858299255371,
      "learning_rate": 3.0238095238095236e-05,
      "loss": 1.1658,
      "step": 69500
    },
    {
      "epoch": 5.93958013312852,
      "grad_norm": 3.1228368282318115,
      "learning_rate": 3.020964897308983e-05,
      "loss": 1.1767,
      "step": 69600
    },
    {
      "epoch": 5.948114012630142,
      "grad_norm": 3.5817298889160156,
      "learning_rate": 3.0181202708084426e-05,
      "loss": 1.1687,
      "step": 69700
    },
    {
      "epoch": 5.956647892131763,
      "grad_norm": 3.46116304397583,
      "learning_rate": 3.0152756443079028e-05,
      "loss": 1.1795,
      "step": 69800
    },
    {
      "epoch": 5.965181771633384,
      "grad_norm": 3.296515941619873,
      "learning_rate": 3.0124594640723673e-05,
      "loss": 1.1758,
      "step": 69900
    },
    {
      "epoch": 5.973715651135006,
      "grad_norm": 3.601720094680786,
      "learning_rate": 3.0096148375718268e-05,
      "loss": 1.1801,
      "step": 70000
    },
    {
      "epoch": 5.973715651135006,
      "eval_loss": 0.9669371247291565,
      "eval_runtime": 63.9262,
      "eval_samples_per_second": 617.43,
      "eval_steps_per_second": 77.183,
      "step": 70000
    },
    {
      "epoch": 5.9822495306366275,
      "grad_norm": 3.726987838745117,
      "learning_rate": 3.0067702110712863e-05,
      "loss": 1.1653,
      "step": 70100
    },
    {
      "epoch": 5.990783410138249,
      "grad_norm": 3.552234649658203,
      "learning_rate": 3.003925584570746e-05,
      "loss": 1.1675,
      "step": 70200
    },
    {
      "epoch": 5.999317289639871,
      "grad_norm": 3.282937526702881,
      "learning_rate": 3.0010809580702053e-05,
      "loss": 1.1654,
      "step": 70300
    },
    {
      "epoch": 6.0078511691414915,
      "grad_norm": 3.2972116470336914,
      "learning_rate": 2.998236331569665e-05,
      "loss": 1.1706,
      "step": 70400
    },
    {
      "epoch": 6.016385048643113,
      "grad_norm": 3.3546576499938965,
      "learning_rate": 2.9953917050691244e-05,
      "loss": 1.161,
      "step": 70500
    },
    {
      "epoch": 6.024918928144735,
      "grad_norm": 3.338700532913208,
      "learning_rate": 2.992547078568584e-05,
      "loss": 1.1727,
      "step": 70600
    },
    {
      "epoch": 6.033452807646356,
      "grad_norm": 3.439039468765259,
      "learning_rate": 2.9897024520680434e-05,
      "loss": 1.1815,
      "step": 70700
    },
    {
      "epoch": 6.041986687147977,
      "grad_norm": 4.011170387268066,
      "learning_rate": 2.9868578255675032e-05,
      "loss": 1.1618,
      "step": 70800
    },
    {
      "epoch": 6.050520566649599,
      "grad_norm": 3.231187105178833,
      "learning_rate": 2.9840131990669627e-05,
      "loss": 1.1791,
      "step": 70900
    },
    {
      "epoch": 6.059054446151221,
      "grad_norm": 3.142967462539673,
      "learning_rate": 2.9811685725664222e-05,
      "loss": 1.1696,
      "step": 71000
    },
    {
      "epoch": 6.059054446151221,
      "eval_loss": 0.9634074568748474,
      "eval_runtime": 63.4804,
      "eval_samples_per_second": 621.766,
      "eval_steps_per_second": 77.725,
      "step": 71000
    },
    {
      "epoch": 6.067588325652842,
      "grad_norm": 2.9875543117523193,
      "learning_rate": 2.9783239460658817e-05,
      "loss": 1.1653,
      "step": 71100
    },
    {
      "epoch": 6.076122205154463,
      "grad_norm": 3.500324010848999,
      "learning_rate": 2.9754793195653412e-05,
      "loss": 1.1613,
      "step": 71200
    },
    {
      "epoch": 6.084656084656085,
      "grad_norm": 3.452937364578247,
      "learning_rate": 2.9726346930648007e-05,
      "loss": 1.1749,
      "step": 71300
    },
    {
      "epoch": 6.093189964157706,
      "grad_norm": 3.384916305541992,
      "learning_rate": 2.9697900665642602e-05,
      "loss": 1.1643,
      "step": 71400
    },
    {
      "epoch": 6.101723843659328,
      "grad_norm": 3.5020406246185303,
      "learning_rate": 2.966973886328725e-05,
      "loss": 1.1722,
      "step": 71500
    },
    {
      "epoch": 6.110257723160949,
      "grad_norm": 3.509303331375122,
      "learning_rate": 2.9641292598281846e-05,
      "loss": 1.1752,
      "step": 71600
    },
    {
      "epoch": 6.11879160266257,
      "grad_norm": 3.648178815841675,
      "learning_rate": 2.9612846333276444e-05,
      "loss": 1.1757,
      "step": 71700
    },
    {
      "epoch": 6.127325482164192,
      "grad_norm": 3.261261463165283,
      "learning_rate": 2.958440006827104e-05,
      "loss": 1.1755,
      "step": 71800
    },
    {
      "epoch": 6.135859361665814,
      "grad_norm": 2.9364798069000244,
      "learning_rate": 2.9555953803265634e-05,
      "loss": 1.1573,
      "step": 71900
    },
    {
      "epoch": 6.1443932411674345,
      "grad_norm": 3.0258004665374756,
      "learning_rate": 2.952750753826023e-05,
      "loss": 1.1682,
      "step": 72000
    },
    {
      "epoch": 6.1443932411674345,
      "eval_loss": 0.9597973227500916,
      "eval_runtime": 64.1006,
      "eval_samples_per_second": 615.751,
      "eval_steps_per_second": 76.973,
      "step": 72000
    },
    {
      "epoch": 6.152927120669056,
      "grad_norm": 3.3185415267944336,
      "learning_rate": 2.9499061273254825e-05,
      "loss": 1.1643,
      "step": 72100
    },
    {
      "epoch": 6.161461000170678,
      "grad_norm": 3.383753538131714,
      "learning_rate": 2.947061500824942e-05,
      "loss": 1.1671,
      "step": 72200
    },
    {
      "epoch": 6.169994879672299,
      "grad_norm": 3.5559139251708984,
      "learning_rate": 2.9442168743244015e-05,
      "loss": 1.1716,
      "step": 72300
    },
    {
      "epoch": 6.17852875917392,
      "grad_norm": 3.467536449432373,
      "learning_rate": 2.941372247823861e-05,
      "loss": 1.1687,
      "step": 72400
    },
    {
      "epoch": 6.187062638675542,
      "grad_norm": 3.5232081413269043,
      "learning_rate": 2.9385276213233205e-05,
      "loss": 1.1779,
      "step": 72500
    },
    {
      "epoch": 6.1955965181771635,
      "grad_norm": 4.021553039550781,
      "learning_rate": 2.93568299482278e-05,
      "loss": 1.1668,
      "step": 72600
    },
    {
      "epoch": 6.204130397678785,
      "grad_norm": 3.455552339553833,
      "learning_rate": 2.9328383683222395e-05,
      "loss": 1.1669,
      "step": 72700
    },
    {
      "epoch": 6.212664277180406,
      "grad_norm": 3.4155519008636475,
      "learning_rate": 2.929993741821699e-05,
      "loss": 1.164,
      "step": 72800
    },
    {
      "epoch": 6.221198156682028,
      "grad_norm": 3.3071680068969727,
      "learning_rate": 2.927149115321158e-05,
      "loss": 1.1576,
      "step": 72900
    },
    {
      "epoch": 6.229732036183649,
      "grad_norm": 3.5123908519744873,
      "learning_rate": 2.9243044888206177e-05,
      "loss": 1.1658,
      "step": 73000
    },
    {
      "epoch": 6.229732036183649,
      "eval_loss": 0.9563544392585754,
      "eval_runtime": 63.5946,
      "eval_samples_per_second": 620.65,
      "eval_steps_per_second": 77.585,
      "step": 73000
    },
    {
      "epoch": 6.238265915685271,
      "grad_norm": 3.520714044570923,
      "learning_rate": 2.9214598623200772e-05,
      "loss": 1.1696,
      "step": 73100
    },
    {
      "epoch": 6.246799795186892,
      "grad_norm": 3.14424991607666,
      "learning_rate": 2.9186152358195367e-05,
      "loss": 1.1613,
      "step": 73200
    },
    {
      "epoch": 6.255333674688513,
      "grad_norm": 3.4593746662139893,
      "learning_rate": 2.915770609318997e-05,
      "loss": 1.1632,
      "step": 73300
    },
    {
      "epoch": 6.263867554190135,
      "grad_norm": 3.314448595046997,
      "learning_rate": 2.9129259828184564e-05,
      "loss": 1.1626,
      "step": 73400
    },
    {
      "epoch": 6.272401433691757,
      "grad_norm": 3.438063144683838,
      "learning_rate": 2.910081356317916e-05,
      "loss": 1.1715,
      "step": 73500
    },
    {
      "epoch": 6.280935313193377,
      "grad_norm": 3.37542462348938,
      "learning_rate": 2.9072367298173754e-05,
      "loss": 1.159,
      "step": 73600
    },
    {
      "epoch": 6.289469192694999,
      "grad_norm": 3.4880125522613525,
      "learning_rate": 2.904392103316835e-05,
      "loss": 1.156,
      "step": 73700
    },
    {
      "epoch": 6.298003072196621,
      "grad_norm": 2.9050867557525635,
      "learning_rate": 2.9015474768162944e-05,
      "loss": 1.1575,
      "step": 73800
    },
    {
      "epoch": 6.306536951698242,
      "grad_norm": 3.432363510131836,
      "learning_rate": 2.8987028503157536e-05,
      "loss": 1.154,
      "step": 73900
    },
    {
      "epoch": 6.315070831199863,
      "grad_norm": 3.7323100566864014,
      "learning_rate": 2.895858223815213e-05,
      "loss": 1.165,
      "step": 74000
    },
    {
      "epoch": 6.315070831199863,
      "eval_loss": 0.958354651927948,
      "eval_runtime": 63.3261,
      "eval_samples_per_second": 623.282,
      "eval_steps_per_second": 77.914,
      "step": 74000
    },
    {
      "epoch": 6.323604710701485,
      "grad_norm": 3.9303479194641113,
      "learning_rate": 2.8930135973146726e-05,
      "loss": 1.1704,
      "step": 74100
    },
    {
      "epoch": 6.332138590203106,
      "grad_norm": 3.453800916671753,
      "learning_rate": 2.890168970814132e-05,
      "loss": 1.1702,
      "step": 74200
    },
    {
      "epoch": 6.340672469704728,
      "grad_norm": 3.770343065261841,
      "learning_rate": 2.8873243443135916e-05,
      "loss": 1.1525,
      "step": 74300
    },
    {
      "epoch": 6.349206349206349,
      "grad_norm": 3.392428398132324,
      "learning_rate": 2.884479717813051e-05,
      "loss": 1.1596,
      "step": 74400
    },
    {
      "epoch": 6.3577402287079705,
      "grad_norm": 3.714341402053833,
      "learning_rate": 2.8816350913125106e-05,
      "loss": 1.1627,
      "step": 74500
    },
    {
      "epoch": 6.366274108209592,
      "grad_norm": 3.5537912845611572,
      "learning_rate": 2.87879046481197e-05,
      "loss": 1.1636,
      "step": 74600
    },
    {
      "epoch": 6.374807987711214,
      "grad_norm": 3.264845848083496,
      "learning_rate": 2.8759458383114296e-05,
      "loss": 1.1658,
      "step": 74700
    },
    {
      "epoch": 6.383341867212835,
      "grad_norm": 3.524232864379883,
      "learning_rate": 2.873101211810889e-05,
      "loss": 1.1743,
      "step": 74800
    },
    {
      "epoch": 6.391875746714456,
      "grad_norm": 3.0715019702911377,
      "learning_rate": 2.8702565853103493e-05,
      "loss": 1.1652,
      "step": 74900
    },
    {
      "epoch": 6.400409626216078,
      "grad_norm": 3.4228274822235107,
      "learning_rate": 2.8674119588098085e-05,
      "loss": 1.1513,
      "step": 75000
    },
    {
      "epoch": 6.400409626216078,
      "eval_loss": 0.9557257890701294,
      "eval_runtime": 63.5677,
      "eval_samples_per_second": 620.912,
      "eval_steps_per_second": 77.618,
      "step": 75000
    },
    {
      "epoch": 6.4089435057176996,
      "grad_norm": 3.524259090423584,
      "learning_rate": 2.8645957785742733e-05,
      "loss": 1.1582,
      "step": 75100
    },
    {
      "epoch": 6.41747738521932,
      "grad_norm": 3.5992038249969482,
      "learning_rate": 2.8617511520737328e-05,
      "loss": 1.1457,
      "step": 75200
    },
    {
      "epoch": 6.426011264720942,
      "grad_norm": 3.0210750102996826,
      "learning_rate": 2.8589065255731923e-05,
      "loss": 1.1698,
      "step": 75300
    },
    {
      "epoch": 6.434545144222564,
      "grad_norm": 3.832918167114258,
      "learning_rate": 2.8560618990726518e-05,
      "loss": 1.1566,
      "step": 75400
    },
    {
      "epoch": 6.443079023724185,
      "grad_norm": 3.4130923748016357,
      "learning_rate": 2.8532172725721113e-05,
      "loss": 1.1647,
      "step": 75500
    },
    {
      "epoch": 6.451612903225806,
      "grad_norm": 3.2262558937072754,
      "learning_rate": 2.850372646071571e-05,
      "loss": 1.1598,
      "step": 75600
    },
    {
      "epoch": 6.460146782727428,
      "grad_norm": 3.730638027191162,
      "learning_rate": 2.8475280195710303e-05,
      "loss": 1.158,
      "step": 75700
    },
    {
      "epoch": 6.468680662229049,
      "grad_norm": 3.5626423358917236,
      "learning_rate": 2.8446833930704902e-05,
      "loss": 1.1576,
      "step": 75800
    },
    {
      "epoch": 6.477214541730671,
      "grad_norm": 3.323000192642212,
      "learning_rate": 2.8418387665699497e-05,
      "loss": 1.1456,
      "step": 75900
    },
    {
      "epoch": 6.485748421232293,
      "grad_norm": 3.56013560295105,
      "learning_rate": 2.8389941400694092e-05,
      "loss": 1.1671,
      "step": 76000
    },
    {
      "epoch": 6.485748421232293,
      "eval_loss": 0.9574443697929382,
      "eval_runtime": 64.015,
      "eval_samples_per_second": 616.574,
      "eval_steps_per_second": 77.076,
      "step": 76000
    },
    {
      "epoch": 6.494282300733913,
      "grad_norm": 3.4524717330932617,
      "learning_rate": 2.8361495135688687e-05,
      "loss": 1.1641,
      "step": 76100
    },
    {
      "epoch": 6.502816180235535,
      "grad_norm": 3.3705074787139893,
      "learning_rate": 2.8333048870683282e-05,
      "loss": 1.1707,
      "step": 76200
    },
    {
      "epoch": 6.511350059737157,
      "grad_norm": 3.2887566089630127,
      "learning_rate": 2.8304602605677877e-05,
      "loss": 1.1652,
      "step": 76300
    },
    {
      "epoch": 6.5198839392387775,
      "grad_norm": 3.7609941959381104,
      "learning_rate": 2.8276156340672472e-05,
      "loss": 1.1466,
      "step": 76400
    },
    {
      "epoch": 6.528417818740399,
      "grad_norm": 3.4347569942474365,
      "learning_rate": 2.8247710075667067e-05,
      "loss": 1.1605,
      "step": 76500
    },
    {
      "epoch": 6.536951698242021,
      "grad_norm": 3.587682008743286,
      "learning_rate": 2.8219263810661662e-05,
      "loss": 1.1535,
      "step": 76600
    },
    {
      "epoch": 6.5454855777436425,
      "grad_norm": 3.6132352352142334,
      "learning_rate": 2.8190817545656257e-05,
      "loss": 1.1628,
      "step": 76700
    },
    {
      "epoch": 6.554019457245264,
      "grad_norm": 3.3457655906677246,
      "learning_rate": 2.8162371280650852e-05,
      "loss": 1.1602,
      "step": 76800
    },
    {
      "epoch": 6.562553336746885,
      "grad_norm": 3.74383807182312,
      "learning_rate": 2.8133925015645447e-05,
      "loss": 1.1426,
      "step": 76900
    },
    {
      "epoch": 6.571087216248507,
      "grad_norm": 3.4499497413635254,
      "learning_rate": 2.810547875064004e-05,
      "loss": 1.161,
      "step": 77000
    },
    {
      "epoch": 6.571087216248507,
      "eval_loss": 0.947964608669281,
      "eval_runtime": 63.6866,
      "eval_samples_per_second": 619.754,
      "eval_steps_per_second": 77.473,
      "step": 77000
    },
    {
      "epoch": 6.579621095750128,
      "grad_norm": 3.442106008529663,
      "learning_rate": 2.8077032485634634e-05,
      "loss": 1.146,
      "step": 77100
    },
    {
      "epoch": 6.588154975251749,
      "grad_norm": 3.3028647899627686,
      "learning_rate": 2.804858622062923e-05,
      "loss": 1.1441,
      "step": 77200
    },
    {
      "epoch": 6.596688854753371,
      "grad_norm": 3.888138771057129,
      "learning_rate": 2.8020139955623824e-05,
      "loss": 1.1503,
      "step": 77300
    },
    {
      "epoch": 6.605222734254992,
      "grad_norm": 3.104217767715454,
      "learning_rate": 2.7991693690618426e-05,
      "loss": 1.1506,
      "step": 77400
    },
    {
      "epoch": 6.613756613756614,
      "grad_norm": 3.294893741607666,
      "learning_rate": 2.796324742561302e-05,
      "loss": 1.1556,
      "step": 77500
    },
    {
      "epoch": 6.622290493258236,
      "grad_norm": 3.716261863708496,
      "learning_rate": 2.7934801160607616e-05,
      "loss": 1.1548,
      "step": 77600
    },
    {
      "epoch": 6.630824372759856,
      "grad_norm": 3.4230151176452637,
      "learning_rate": 2.790635489560221e-05,
      "loss": 1.1587,
      "step": 77700
    },
    {
      "epoch": 6.639358252261478,
      "grad_norm": 3.3560094833374023,
      "learning_rate": 2.7877908630596806e-05,
      "loss": 1.1516,
      "step": 77800
    },
    {
      "epoch": 6.6478921317631,
      "grad_norm": 3.5635228157043457,
      "learning_rate": 2.78494623655914e-05,
      "loss": 1.1641,
      "step": 77900
    },
    {
      "epoch": 6.65642601126472,
      "grad_norm": 3.7592966556549072,
      "learning_rate": 2.7821016100585997e-05,
      "loss": 1.1635,
      "step": 78000
    },
    {
      "epoch": 6.65642601126472,
      "eval_loss": 0.9467499256134033,
      "eval_runtime": 63.3618,
      "eval_samples_per_second": 622.931,
      "eval_steps_per_second": 77.87,
      "step": 78000
    },
    {
      "epoch": 6.664959890766342,
      "grad_norm": 3.2838501930236816,
      "learning_rate": 2.7792569835580588e-05,
      "loss": 1.159,
      "step": 78100
    },
    {
      "epoch": 6.673493770267964,
      "grad_norm": 3.6091513633728027,
      "learning_rate": 2.7764123570575183e-05,
      "loss": 1.1611,
      "step": 78200
    },
    {
      "epoch": 6.682027649769585,
      "grad_norm": 3.439047336578369,
      "learning_rate": 2.7735677305569778e-05,
      "loss": 1.1497,
      "step": 78300
    },
    {
      "epoch": 6.690561529271207,
      "grad_norm": 3.5684995651245117,
      "learning_rate": 2.7707231040564373e-05,
      "loss": 1.1588,
      "step": 78400
    },
    {
      "epoch": 6.699095408772828,
      "grad_norm": 3.1924378871917725,
      "learning_rate": 2.767878477555897e-05,
      "loss": 1.1506,
      "step": 78500
    },
    {
      "epoch": 6.7076292882744495,
      "grad_norm": 3.343324661254883,
      "learning_rate": 2.7650338510553563e-05,
      "loss": 1.1509,
      "step": 78600
    },
    {
      "epoch": 6.716163167776071,
      "grad_norm": 3.462595224380493,
      "learning_rate": 2.762189224554816e-05,
      "loss": 1.161,
      "step": 78700
    },
    {
      "epoch": 6.724697047277693,
      "grad_norm": 3.917379856109619,
      "learning_rate": 2.7593445980542754e-05,
      "loss": 1.1547,
      "step": 78800
    },
    {
      "epoch": 6.733230926779314,
      "grad_norm": 3.8708913326263428,
      "learning_rate": 2.756499971553735e-05,
      "loss": 1.1533,
      "step": 78900
    },
    {
      "epoch": 6.741764806280935,
      "grad_norm": 3.320420742034912,
      "learning_rate": 2.753655345053195e-05,
      "loss": 1.1484,
      "step": 79000
    },
    {
      "epoch": 6.741764806280935,
      "eval_loss": 0.9457192420959473,
      "eval_runtime": 63.8703,
      "eval_samples_per_second": 617.971,
      "eval_steps_per_second": 77.25,
      "step": 79000
    },
    {
      "epoch": 6.750298685782557,
      "grad_norm": 3.3710315227508545,
      "learning_rate": 2.7508391648176595e-05,
      "loss": 1.161,
      "step": 79100
    },
    {
      "epoch": 6.7588325652841785,
      "grad_norm": 3.000235080718994,
      "learning_rate": 2.747994538317119e-05,
      "loss": 1.1698,
      "step": 79200
    },
    {
      "epoch": 6.767366444785799,
      "grad_norm": 3.455379009246826,
      "learning_rate": 2.7451499118165786e-05,
      "loss": 1.1369,
      "step": 79300
    },
    {
      "epoch": 6.775900324287421,
      "grad_norm": 3.5766608715057373,
      "learning_rate": 2.742305285316038e-05,
      "loss": 1.1637,
      "step": 79400
    },
    {
      "epoch": 6.784434203789043,
      "grad_norm": 3.73014497756958,
      "learning_rate": 2.7394891050805032e-05,
      "loss": 1.1587,
      "step": 79500
    },
    {
      "epoch": 6.792968083290664,
      "grad_norm": 3.3069231510162354,
      "learning_rate": 2.7366444785799627e-05,
      "loss": 1.1574,
      "step": 79600
    },
    {
      "epoch": 6.801501962792285,
      "grad_norm": 3.061701536178589,
      "learning_rate": 2.7337998520794223e-05,
      "loss": 1.143,
      "step": 79700
    },
    {
      "epoch": 6.810035842293907,
      "grad_norm": 3.166928291320801,
      "learning_rate": 2.7309552255788818e-05,
      "loss": 1.1459,
      "step": 79800
    },
    {
      "epoch": 6.818569721795528,
      "grad_norm": 3.7064971923828125,
      "learning_rate": 2.7281105990783413e-05,
      "loss": 1.1464,
      "step": 79900
    },
    {
      "epoch": 6.82710360129715,
      "grad_norm": 3.149966239929199,
      "learning_rate": 2.7252659725778008e-05,
      "loss": 1.1427,
      "step": 80000
    },
    {
      "epoch": 6.82710360129715,
      "eval_loss": 0.9427413940429688,
      "eval_runtime": 63.9569,
      "eval_samples_per_second": 617.134,
      "eval_steps_per_second": 77.146,
      "step": 80000
    },
    {
      "epoch": 6.835637480798771,
      "grad_norm": 3.330843448638916,
      "learning_rate": 2.7224213460772603e-05,
      "loss": 1.1463,
      "step": 80100
    },
    {
      "epoch": 6.844171360300392,
      "grad_norm": 4.348784923553467,
      "learning_rate": 2.7195767195767198e-05,
      "loss": 1.1442,
      "step": 80200
    },
    {
      "epoch": 6.852705239802014,
      "grad_norm": 3.515491008758545,
      "learning_rate": 2.7167320930761793e-05,
      "loss": 1.1392,
      "step": 80300
    },
    {
      "epoch": 6.861239119303636,
      "grad_norm": 3.4179418087005615,
      "learning_rate": 2.7138874665756388e-05,
      "loss": 1.1385,
      "step": 80400
    },
    {
      "epoch": 6.8697729988052565,
      "grad_norm": 3.7067415714263916,
      "learning_rate": 2.711042840075098e-05,
      "loss": 1.1548,
      "step": 80500
    },
    {
      "epoch": 6.878306878306878,
      "grad_norm": 3.3674826622009277,
      "learning_rate": 2.7081982135745575e-05,
      "loss": 1.1579,
      "step": 80600
    },
    {
      "epoch": 6.8868407578085,
      "grad_norm": 3.42048978805542,
      "learning_rate": 2.705353587074017e-05,
      "loss": 1.147,
      "step": 80700
    },
    {
      "epoch": 6.8953746373101215,
      "grad_norm": 3.4196929931640625,
      "learning_rate": 2.7025089605734765e-05,
      "loss": 1.1428,
      "step": 80800
    },
    {
      "epoch": 6.903908516811743,
      "grad_norm": 3.3227150440216064,
      "learning_rate": 2.6996643340729367e-05,
      "loss": 1.1514,
      "step": 80900
    },
    {
      "epoch": 6.912442396313364,
      "grad_norm": 4.277144908905029,
      "learning_rate": 2.696819707572396e-05,
      "loss": 1.1561,
      "step": 81000
    },
    {
      "epoch": 6.912442396313364,
      "eval_loss": 0.940028727054596,
      "eval_runtime": 63.5471,
      "eval_samples_per_second": 621.114,
      "eval_steps_per_second": 77.643,
      "step": 81000
    },
    {
      "epoch": 6.9209762758149855,
      "grad_norm": 3.20634388923645,
      "learning_rate": 2.6939750810718557e-05,
      "loss": 1.1529,
      "step": 81100
    },
    {
      "epoch": 6.929510155316607,
      "grad_norm": 3.3856780529022217,
      "learning_rate": 2.6911304545713152e-05,
      "loss": 1.1588,
      "step": 81200
    },
    {
      "epoch": 6.938044034818228,
      "grad_norm": 3.2515852451324463,
      "learning_rate": 2.6882858280707747e-05,
      "loss": 1.1519,
      "step": 81300
    },
    {
      "epoch": 6.94657791431985,
      "grad_norm": 3.8286080360412598,
      "learning_rate": 2.6854412015702342e-05,
      "loss": 1.1404,
      "step": 81400
    },
    {
      "epoch": 6.955111793821471,
      "grad_norm": 3.175532102584839,
      "learning_rate": 2.6825965750696937e-05,
      "loss": 1.1623,
      "step": 81500
    },
    {
      "epoch": 6.963645673323093,
      "grad_norm": 3.405508041381836,
      "learning_rate": 2.679751948569153e-05,
      "loss": 1.1414,
      "step": 81600
    },
    {
      "epoch": 6.972179552824715,
      "grad_norm": 3.4095776081085205,
      "learning_rate": 2.6769073220686124e-05,
      "loss": 1.1495,
      "step": 81700
    },
    {
      "epoch": 6.980713432326335,
      "grad_norm": 3.2131004333496094,
      "learning_rate": 2.674062695568072e-05,
      "loss": 1.1554,
      "step": 81800
    },
    {
      "epoch": 6.989247311827957,
      "grad_norm": 3.2767326831817627,
      "learning_rate": 2.6712180690675314e-05,
      "loss": 1.1505,
      "step": 81900
    },
    {
      "epoch": 6.997781191329579,
      "grad_norm": 3.761136293411255,
      "learning_rate": 2.668373442566991e-05,
      "loss": 1.1436,
      "step": 82000
    },
    {
      "epoch": 6.997781191329579,
      "eval_loss": 0.9448239803314209,
      "eval_runtime": 63.6651,
      "eval_samples_per_second": 619.962,
      "eval_steps_per_second": 77.499,
      "step": 82000
    },
    {
      "epoch": 7.006315070831199,
      "grad_norm": 3.6257455348968506,
      "learning_rate": 2.6655288160664504e-05,
      "loss": 1.1386,
      "step": 82100
    },
    {
      "epoch": 7.014848950332821,
      "grad_norm": 3.534731864929199,
      "learning_rate": 2.66268418956591e-05,
      "loss": 1.1444,
      "step": 82200
    },
    {
      "epoch": 7.023382829834443,
      "grad_norm": 4.095148086547852,
      "learning_rate": 2.6598395630653694e-05,
      "loss": 1.1459,
      "step": 82300
    },
    {
      "epoch": 7.031916709336064,
      "grad_norm": 3.246398448944092,
      "learning_rate": 2.656994936564829e-05,
      "loss": 1.1544,
      "step": 82400
    },
    {
      "epoch": 7.040450588837686,
      "grad_norm": 3.296549081802368,
      "learning_rate": 2.654150310064289e-05,
      "loss": 1.1384,
      "step": 82500
    },
    {
      "epoch": 7.048984468339307,
      "grad_norm": 3.2867188453674316,
      "learning_rate": 2.6513056835637483e-05,
      "loss": 1.1493,
      "step": 82600
    },
    {
      "epoch": 7.0575183478409285,
      "grad_norm": 3.5921831130981445,
      "learning_rate": 2.6484610570632078e-05,
      "loss": 1.134,
      "step": 82700
    },
    {
      "epoch": 7.06605222734255,
      "grad_norm": 4.0031633377075195,
      "learning_rate": 2.6456164305626673e-05,
      "loss": 1.1413,
      "step": 82800
    },
    {
      "epoch": 7.074586106844172,
      "grad_norm": 3.7016489505767822,
      "learning_rate": 2.6427718040621268e-05,
      "loss": 1.1309,
      "step": 82900
    },
    {
      "epoch": 7.0831199863457925,
      "grad_norm": 3.8164002895355225,
      "learning_rate": 2.6399271775615863e-05,
      "loss": 1.1429,
      "step": 83000
    },
    {
      "epoch": 7.0831199863457925,
      "eval_loss": 0.9369388818740845,
      "eval_runtime": 64.0312,
      "eval_samples_per_second": 616.418,
      "eval_steps_per_second": 77.056,
      "step": 83000
    },
    {
      "epoch": 7.091653865847414,
      "grad_norm": 3.3491711616516113,
      "learning_rate": 2.6370825510610458e-05,
      "loss": 1.1367,
      "step": 83100
    },
    {
      "epoch": 7.100187745349036,
      "grad_norm": 3.7284538745880127,
      "learning_rate": 2.6342379245605053e-05,
      "loss": 1.1499,
      "step": 83200
    },
    {
      "epoch": 7.1087216248506575,
      "grad_norm": 3.808624267578125,
      "learning_rate": 2.6313932980599648e-05,
      "loss": 1.15,
      "step": 83300
    },
    {
      "epoch": 7.117255504352278,
      "grad_norm": 3.7053775787353516,
      "learning_rate": 2.6285486715594243e-05,
      "loss": 1.1505,
      "step": 83400
    },
    {
      "epoch": 7.1257893838539,
      "grad_norm": 3.3493809700012207,
      "learning_rate": 2.6257324913238895e-05,
      "loss": 1.1455,
      "step": 83500
    },
    {
      "epoch": 7.134323263355522,
      "grad_norm": 3.108367919921875,
      "learning_rate": 2.622887864823349e-05,
      "loss": 1.1347,
      "step": 83600
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 3.9833803176879883,
      "learning_rate": 2.6200432383228085e-05,
      "loss": 1.1545,
      "step": 83700
    },
    {
      "epoch": 7.151391022358764,
      "grad_norm": 3.741774797439575,
      "learning_rate": 2.617198611822268e-05,
      "loss": 1.1415,
      "step": 83800
    },
    {
      "epoch": 7.159924901860386,
      "grad_norm": 3.622617721557617,
      "learning_rate": 2.6143539853217275e-05,
      "loss": 1.1391,
      "step": 83900
    },
    {
      "epoch": 7.168458781362007,
      "grad_norm": 3.6689555644989014,
      "learning_rate": 2.611509358821187e-05,
      "loss": 1.1375,
      "step": 84000
    },
    {
      "epoch": 7.168458781362007,
      "eval_loss": 0.9357222318649292,
      "eval_runtime": 63.5982,
      "eval_samples_per_second": 620.615,
      "eval_steps_per_second": 77.581,
      "step": 84000
    },
    {
      "epoch": 7.176992660863629,
      "grad_norm": 3.5975468158721924,
      "learning_rate": 2.6086647323206465e-05,
      "loss": 1.141,
      "step": 84100
    },
    {
      "epoch": 7.18552654036525,
      "grad_norm": 3.4835400581359863,
      "learning_rate": 2.605820105820106e-05,
      "loss": 1.1385,
      "step": 84200
    },
    {
      "epoch": 7.194060419866871,
      "grad_norm": 3.865511178970337,
      "learning_rate": 2.6029754793195655e-05,
      "loss": 1.1456,
      "step": 84300
    },
    {
      "epoch": 7.202594299368493,
      "grad_norm": 3.7484323978424072,
      "learning_rate": 2.600130852819025e-05,
      "loss": 1.1433,
      "step": 84400
    },
    {
      "epoch": 7.211128178870115,
      "grad_norm": 3.5389389991760254,
      "learning_rate": 2.5972862263184845e-05,
      "loss": 1.1417,
      "step": 84500
    },
    {
      "epoch": 7.2196620583717355,
      "grad_norm": 3.88057017326355,
      "learning_rate": 2.5944700460829497e-05,
      "loss": 1.1533,
      "step": 84600
    },
    {
      "epoch": 7.228195937873357,
      "grad_norm": 3.4721388816833496,
      "learning_rate": 2.5916254195824092e-05,
      "loss": 1.1358,
      "step": 84700
    },
    {
      "epoch": 7.236729817374979,
      "grad_norm": 4.161671161651611,
      "learning_rate": 2.5887807930818687e-05,
      "loss": 1.135,
      "step": 84800
    },
    {
      "epoch": 7.2452636968766,
      "grad_norm": 3.7056689262390137,
      "learning_rate": 2.5859361665813282e-05,
      "loss": 1.1304,
      "step": 84900
    },
    {
      "epoch": 7.253797576378221,
      "grad_norm": 3.2962424755096436,
      "learning_rate": 2.5830915400807877e-05,
      "loss": 1.151,
      "step": 85000
    },
    {
      "epoch": 7.253797576378221,
      "eval_loss": 0.9296704530715942,
      "eval_runtime": 63.4021,
      "eval_samples_per_second": 622.535,
      "eval_steps_per_second": 77.821,
      "step": 85000
    },
    {
      "epoch": 7.262331455879843,
      "grad_norm": 3.554563283920288,
      "learning_rate": 2.580246913580247e-05,
      "loss": 1.1254,
      "step": 85100
    },
    {
      "epoch": 7.2708653353814645,
      "grad_norm": 3.495232582092285,
      "learning_rate": 2.5774022870797064e-05,
      "loss": 1.129,
      "step": 85200
    },
    {
      "epoch": 7.279399214883086,
      "grad_norm": 3.554131269454956,
      "learning_rate": 2.574557660579166e-05,
      "loss": 1.1405,
      "step": 85300
    },
    {
      "epoch": 7.287933094384707,
      "grad_norm": 3.7194368839263916,
      "learning_rate": 2.5717130340786254e-05,
      "loss": 1.1358,
      "step": 85400
    },
    {
      "epoch": 7.296466973886329,
      "grad_norm": 3.7417335510253906,
      "learning_rate": 2.568868407578085e-05,
      "loss": 1.1442,
      "step": 85500
    },
    {
      "epoch": 7.30500085338795,
      "grad_norm": 3.5473098754882812,
      "learning_rate": 2.5660237810775444e-05,
      "loss": 1.1302,
      "step": 85600
    },
    {
      "epoch": 7.313534732889572,
      "grad_norm": 3.237391710281372,
      "learning_rate": 2.563179154577004e-05,
      "loss": 1.1357,
      "step": 85700
    },
    {
      "epoch": 7.322068612391193,
      "grad_norm": 3.3230154514312744,
      "learning_rate": 2.5603345280764635e-05,
      "loss": 1.1442,
      "step": 85800
    },
    {
      "epoch": 7.330602491892814,
      "grad_norm": 3.2222750186920166,
      "learning_rate": 2.557489901575923e-05,
      "loss": 1.1346,
      "step": 85900
    },
    {
      "epoch": 7.339136371394436,
      "grad_norm": 3.692025661468506,
      "learning_rate": 2.554645275075383e-05,
      "loss": 1.1482,
      "step": 86000
    },
    {
      "epoch": 7.339136371394436,
      "eval_loss": 0.9363229870796204,
      "eval_runtime": 62.7963,
      "eval_samples_per_second": 628.54,
      "eval_steps_per_second": 78.572,
      "step": 86000
    },
    {
      "epoch": 7.347670250896058,
      "grad_norm": 3.706817388534546,
      "learning_rate": 2.5518006485748423e-05,
      "loss": 1.1299,
      "step": 86100
    },
    {
      "epoch": 7.356204130397678,
      "grad_norm": 3.2652993202209473,
      "learning_rate": 2.5489560220743018e-05,
      "loss": 1.1405,
      "step": 86200
    },
    {
      "epoch": 7.3647380098993,
      "grad_norm": 3.237851858139038,
      "learning_rate": 2.5461113955737613e-05,
      "loss": 1.1438,
      "step": 86300
    },
    {
      "epoch": 7.373271889400922,
      "grad_norm": 3.4706027507781982,
      "learning_rate": 2.5432667690732208e-05,
      "loss": 1.1288,
      "step": 86400
    },
    {
      "epoch": 7.381805768902543,
      "grad_norm": 3.4112186431884766,
      "learning_rate": 2.5404221425726803e-05,
      "loss": 1.1219,
      "step": 86500
    },
    {
      "epoch": 7.390339648404164,
      "grad_norm": 3.454545021057129,
      "learning_rate": 2.53757751607214e-05,
      "loss": 1.135,
      "step": 86600
    },
    {
      "epoch": 7.398873527905786,
      "grad_norm": 3.9515271186828613,
      "learning_rate": 2.5347328895715993e-05,
      "loss": 1.136,
      "step": 86700
    },
    {
      "epoch": 7.407407407407407,
      "grad_norm": 3.3837223052978516,
      "learning_rate": 2.531888263071059e-05,
      "loss": 1.1316,
      "step": 86800
    },
    {
      "epoch": 7.415941286909029,
      "grad_norm": 3.3942909240722656,
      "learning_rate": 2.5290720828355237e-05,
      "loss": 1.1449,
      "step": 86900
    },
    {
      "epoch": 7.42447516641065,
      "grad_norm": 3.5665817260742188,
      "learning_rate": 2.5262274563349835e-05,
      "loss": 1.1391,
      "step": 87000
    },
    {
      "epoch": 7.42447516641065,
      "eval_loss": 0.9303489923477173,
      "eval_runtime": 62.6483,
      "eval_samples_per_second": 630.025,
      "eval_steps_per_second": 78.757,
      "step": 87000
    },
    {
      "epoch": 7.4330090459122715,
      "grad_norm": 3.243198871612549,
      "learning_rate": 2.523382829834443e-05,
      "loss": 1.1514,
      "step": 87100
    },
    {
      "epoch": 7.441542925413893,
      "grad_norm": 3.6918869018554688,
      "learning_rate": 2.5205382033339025e-05,
      "loss": 1.1357,
      "step": 87200
    },
    {
      "epoch": 7.450076804915515,
      "grad_norm": 3.5958216190338135,
      "learning_rate": 2.517693576833362e-05,
      "loss": 1.1251,
      "step": 87300
    },
    {
      "epoch": 7.4586106844171365,
      "grad_norm": 3.6463773250579834,
      "learning_rate": 2.5148489503328216e-05,
      "loss": 1.1413,
      "step": 87400
    },
    {
      "epoch": 7.467144563918757,
      "grad_norm": 3.453746795654297,
      "learning_rate": 2.512004323832281e-05,
      "loss": 1.1341,
      "step": 87500
    },
    {
      "epoch": 7.475678443420379,
      "grad_norm": 3.2942492961883545,
      "learning_rate": 2.5091596973317406e-05,
      "loss": 1.1479,
      "step": 87600
    },
    {
      "epoch": 7.484212322922001,
      "grad_norm": 3.483816146850586,
      "learning_rate": 2.5063150708312e-05,
      "loss": 1.14,
      "step": 87700
    },
    {
      "epoch": 7.492746202423621,
      "grad_norm": 3.6883938312530518,
      "learning_rate": 2.5034704443306596e-05,
      "loss": 1.1464,
      "step": 87800
    },
    {
      "epoch": 7.501280081925243,
      "grad_norm": 3.2011446952819824,
      "learning_rate": 2.500625817830119e-05,
      "loss": 1.1344,
      "step": 87900
    },
    {
      "epoch": 7.509813961426865,
      "grad_norm": 3.586799144744873,
      "learning_rate": 2.4977811913295786e-05,
      "loss": 1.1366,
      "step": 88000
    },
    {
      "epoch": 7.509813961426865,
      "eval_loss": 0.9223225116729736,
      "eval_runtime": 62.3048,
      "eval_samples_per_second": 633.499,
      "eval_steps_per_second": 79.191,
      "step": 88000
    },
    {
      "epoch": 7.518347840928486,
      "grad_norm": 3.9515342712402344,
      "learning_rate": 2.494936564829038e-05,
      "loss": 1.1257,
      "step": 88100
    },
    {
      "epoch": 7.526881720430108,
      "grad_norm": 3.808896064758301,
      "learning_rate": 2.4920919383284976e-05,
      "loss": 1.1199,
      "step": 88200
    },
    {
      "epoch": 7.535415599931729,
      "grad_norm": 3.960888385772705,
      "learning_rate": 2.489247311827957e-05,
      "loss": 1.1357,
      "step": 88300
    },
    {
      "epoch": 7.54394947943335,
      "grad_norm": 3.405561923980713,
      "learning_rate": 2.4864026853274166e-05,
      "loss": 1.1348,
      "step": 88400
    },
    {
      "epoch": 7.552483358934972,
      "grad_norm": 3.4069583415985107,
      "learning_rate": 2.483558058826876e-05,
      "loss": 1.1306,
      "step": 88500
    },
    {
      "epoch": 7.561017238436593,
      "grad_norm": 3.908707857131958,
      "learning_rate": 2.4807134323263356e-05,
      "loss": 1.1344,
      "step": 88600
    },
    {
      "epoch": 7.5695511179382144,
      "grad_norm": 3.3801567554473877,
      "learning_rate": 2.477868805825795e-05,
      "loss": 1.1235,
      "step": 88700
    },
    {
      "epoch": 7.578084997439836,
      "grad_norm": 3.416548490524292,
      "learning_rate": 2.4750241793252546e-05,
      "loss": 1.1265,
      "step": 88800
    },
    {
      "epoch": 7.586618876941458,
      "grad_norm": 3.0704686641693115,
      "learning_rate": 2.4721795528247145e-05,
      "loss": 1.1265,
      "step": 88900
    },
    {
      "epoch": 7.595152756443079,
      "grad_norm": 3.4964210987091064,
      "learning_rate": 2.469334926324174e-05,
      "loss": 1.1183,
      "step": 89000
    },
    {
      "epoch": 7.595152756443079,
      "eval_loss": 0.9261144995689392,
      "eval_runtime": 62.5672,
      "eval_samples_per_second": 630.841,
      "eval_steps_per_second": 78.859,
      "step": 89000
    },
    {
      "epoch": 7.6036866359447,
      "grad_norm": 3.487128257751465,
      "learning_rate": 2.4664902998236335e-05,
      "loss": 1.1128,
      "step": 89100
    },
    {
      "epoch": 7.612220515446322,
      "grad_norm": 3.4812138080596924,
      "learning_rate": 2.4636456733230927e-05,
      "loss": 1.1204,
      "step": 89200
    },
    {
      "epoch": 7.6207543949479435,
      "grad_norm": 3.1270015239715576,
      "learning_rate": 2.460801046822552e-05,
      "loss": 1.1249,
      "step": 89300
    },
    {
      "epoch": 7.629288274449565,
      "grad_norm": 3.083493947982788,
      "learning_rate": 2.4579564203220117e-05,
      "loss": 1.1307,
      "step": 89400
    },
    {
      "epoch": 7.637822153951186,
      "grad_norm": 3.466610908508301,
      "learning_rate": 2.4551117938214712e-05,
      "loss": 1.1337,
      "step": 89500
    },
    {
      "epoch": 7.646356033452808,
      "grad_norm": 3.5903804302215576,
      "learning_rate": 2.4522671673209307e-05,
      "loss": 1.1369,
      "step": 89600
    },
    {
      "epoch": 7.654889912954429,
      "grad_norm": 3.1332011222839355,
      "learning_rate": 2.4494225408203905e-05,
      "loss": 1.1332,
      "step": 89700
    },
    {
      "epoch": 7.663423792456051,
      "grad_norm": 3.91452693939209,
      "learning_rate": 2.44657791431985e-05,
      "loss": 1.1334,
      "step": 89800
    },
    {
      "epoch": 7.671957671957672,
      "grad_norm": 3.3308560848236084,
      "learning_rate": 2.4437332878193095e-05,
      "loss": 1.1396,
      "step": 89900
    },
    {
      "epoch": 7.680491551459293,
      "grad_norm": 3.475480079650879,
      "learning_rate": 2.440888661318769e-05,
      "loss": 1.1266,
      "step": 90000
    },
    {
      "epoch": 7.680491551459293,
      "eval_loss": 0.9233965277671814,
      "eval_runtime": 63.1464,
      "eval_samples_per_second": 625.055,
      "eval_steps_per_second": 78.136,
      "step": 90000
    },
    {
      "epoch": 7.689025430960915,
      "grad_norm": 3.7955288887023926,
      "learning_rate": 2.4380440348182286e-05,
      "loss": 1.1368,
      "step": 90100
    },
    {
      "epoch": 7.697559310462537,
      "grad_norm": 3.4536077976226807,
      "learning_rate": 2.435199408317688e-05,
      "loss": 1.1288,
      "step": 90200
    },
    {
      "epoch": 7.706093189964157,
      "grad_norm": 3.7873871326446533,
      "learning_rate": 2.4323547818171476e-05,
      "loss": 1.123,
      "step": 90300
    },
    {
      "epoch": 7.714627069465779,
      "grad_norm": 3.2989957332611084,
      "learning_rate": 2.429510155316607e-05,
      "loss": 1.1274,
      "step": 90400
    },
    {
      "epoch": 7.723160948967401,
      "grad_norm": 3.2251152992248535,
      "learning_rate": 2.4266655288160666e-05,
      "loss": 1.1396,
      "step": 90500
    },
    {
      "epoch": 7.731694828469022,
      "grad_norm": 3.654341220855713,
      "learning_rate": 2.423820902315526e-05,
      "loss": 1.1319,
      "step": 90600
    },
    {
      "epoch": 7.740228707970643,
      "grad_norm": 3.399998903274536,
      "learning_rate": 2.4209762758149856e-05,
      "loss": 1.1362,
      "step": 90700
    },
    {
      "epoch": 7.748762587472265,
      "grad_norm": 2.964440107345581,
      "learning_rate": 2.418131649314445e-05,
      "loss": 1.1261,
      "step": 90800
    },
    {
      "epoch": 7.757296466973886,
      "grad_norm": 3.1899070739746094,
      "learning_rate": 2.41531546907891e-05,
      "loss": 1.1316,
      "step": 90900
    },
    {
      "epoch": 7.765830346475508,
      "grad_norm": 4.023904323577881,
      "learning_rate": 2.4124708425783694e-05,
      "loss": 1.1196,
      "step": 91000
    },
    {
      "epoch": 7.765830346475508,
      "eval_loss": 0.9189020991325378,
      "eval_runtime": 63.272,
      "eval_samples_per_second": 623.815,
      "eval_steps_per_second": 77.981,
      "step": 91000
    },
    {
      "epoch": 7.774364225977129,
      "grad_norm": 3.402981758117676,
      "learning_rate": 2.409626216077829e-05,
      "loss": 1.1407,
      "step": 91100
    },
    {
      "epoch": 7.7828981054787505,
      "grad_norm": 3.5426113605499268,
      "learning_rate": 2.4067815895772884e-05,
      "loss": 1.1354,
      "step": 91200
    },
    {
      "epoch": 7.791431984980372,
      "grad_norm": 3.440096139907837,
      "learning_rate": 2.403936963076748e-05,
      "loss": 1.1348,
      "step": 91300
    },
    {
      "epoch": 7.799965864481994,
      "grad_norm": 3.3720576763153076,
      "learning_rate": 2.4010923365762075e-05,
      "loss": 1.1169,
      "step": 91400
    },
    {
      "epoch": 7.808499743983615,
      "grad_norm": 3.9048361778259277,
      "learning_rate": 2.3982477100756673e-05,
      "loss": 1.1239,
      "step": 91500
    },
    {
      "epoch": 7.817033623485236,
      "grad_norm": 3.944150924682617,
      "learning_rate": 2.3954030835751268e-05,
      "loss": 1.1281,
      "step": 91600
    },
    {
      "epoch": 7.825567502986858,
      "grad_norm": 3.940171241760254,
      "learning_rate": 2.3925584570745863e-05,
      "loss": 1.1352,
      "step": 91700
    },
    {
      "epoch": 7.8341013824884795,
      "grad_norm": 3.624924659729004,
      "learning_rate": 2.3897138305740458e-05,
      "loss": 1.1266,
      "step": 91800
    },
    {
      "epoch": 7.8426352619901,
      "grad_norm": 3.6367287635803223,
      "learning_rate": 2.3868692040735053e-05,
      "loss": 1.1262,
      "step": 91900
    },
    {
      "epoch": 7.851169141491722,
      "grad_norm": 3.157590866088867,
      "learning_rate": 2.384024577572965e-05,
      "loss": 1.1139,
      "step": 92000
    },
    {
      "epoch": 7.851169141491722,
      "eval_loss": 0.9236568212509155,
      "eval_runtime": 63.1576,
      "eval_samples_per_second": 624.945,
      "eval_steps_per_second": 78.122,
      "step": 92000
    },
    {
      "epoch": 7.859703020993344,
      "grad_norm": 3.9439663887023926,
      "learning_rate": 2.3811799510724243e-05,
      "loss": 1.1228,
      "step": 92100
    },
    {
      "epoch": 7.868236900494965,
      "grad_norm": 3.2269227504730225,
      "learning_rate": 2.378335324571884e-05,
      "loss": 1.116,
      "step": 92200
    },
    {
      "epoch": 7.876770779996587,
      "grad_norm": 3.215413808822632,
      "learning_rate": 2.3754906980713434e-05,
      "loss": 1.1265,
      "step": 92300
    },
    {
      "epoch": 7.885304659498208,
      "grad_norm": 3.3385519981384277,
      "learning_rate": 2.372646071570803e-05,
      "loss": 1.1299,
      "step": 92400
    },
    {
      "epoch": 7.893838538999829,
      "grad_norm": 3.8813538551330566,
      "learning_rate": 2.3698014450702624e-05,
      "loss": 1.1058,
      "step": 92500
    },
    {
      "epoch": 7.902372418501451,
      "grad_norm": 3.3454360961914062,
      "learning_rate": 2.366956818569722e-05,
      "loss": 1.1159,
      "step": 92600
    },
    {
      "epoch": 7.910906298003072,
      "grad_norm": 3.475085496902466,
      "learning_rate": 2.3641121920691814e-05,
      "loss": 1.1181,
      "step": 92700
    },
    {
      "epoch": 7.919440177504693,
      "grad_norm": 3.9273788928985596,
      "learning_rate": 2.361267565568641e-05,
      "loss": 1.1291,
      "step": 92800
    },
    {
      "epoch": 7.927974057006315,
      "grad_norm": 3.6474080085754395,
      "learning_rate": 2.3584513853331057e-05,
      "loss": 1.1284,
      "step": 92900
    },
    {
      "epoch": 7.936507936507937,
      "grad_norm": 3.4360995292663574,
      "learning_rate": 2.3556067588325652e-05,
      "loss": 1.129,
      "step": 93000
    },
    {
      "epoch": 7.936507936507937,
      "eval_loss": 0.9203459620475769,
      "eval_runtime": 63.4196,
      "eval_samples_per_second": 622.363,
      "eval_steps_per_second": 77.799,
      "step": 93000
    },
    {
      "epoch": 7.945041816009558,
      "grad_norm": 3.3887295722961426,
      "learning_rate": 2.3527621323320247e-05,
      "loss": 1.1105,
      "step": 93100
    },
    {
      "epoch": 7.953575695511179,
      "grad_norm": 3.418175458908081,
      "learning_rate": 2.3499175058314846e-05,
      "loss": 1.1228,
      "step": 93200
    },
    {
      "epoch": 7.962109575012801,
      "grad_norm": 3.871537446975708,
      "learning_rate": 2.347072879330944e-05,
      "loss": 1.1207,
      "step": 93300
    },
    {
      "epoch": 7.9706434545144225,
      "grad_norm": 3.6909027099609375,
      "learning_rate": 2.3442282528304036e-05,
      "loss": 1.1307,
      "step": 93400
    },
    {
      "epoch": 7.979177334016043,
      "grad_norm": 3.8371548652648926,
      "learning_rate": 2.341383626329863e-05,
      "loss": 1.1241,
      "step": 93500
    },
    {
      "epoch": 7.987711213517665,
      "grad_norm": 3.7448668479919434,
      "learning_rate": 2.3385389998293226e-05,
      "loss": 1.1148,
      "step": 93600
    },
    {
      "epoch": 7.9962450930192865,
      "grad_norm": 3.6784698963165283,
      "learning_rate": 2.335694373328782e-05,
      "loss": 1.1144,
      "step": 93700
    },
    {
      "epoch": 8.004778972520908,
      "grad_norm": 3.3005762100219727,
      "learning_rate": 2.3328497468282416e-05,
      "loss": 1.122,
      "step": 93800
    },
    {
      "epoch": 8.01331285202253,
      "grad_norm": 3.2351255416870117,
      "learning_rate": 2.330005120327701e-05,
      "loss": 1.1168,
      "step": 93900
    },
    {
      "epoch": 8.021846731524152,
      "grad_norm": 3.275621175765991,
      "learning_rate": 2.3271604938271606e-05,
      "loss": 1.1224,
      "step": 94000
    },
    {
      "epoch": 8.021846731524152,
      "eval_loss": 0.9172611236572266,
      "eval_runtime": 66.0217,
      "eval_samples_per_second": 597.834,
      "eval_steps_per_second": 74.733,
      "step": 94000
    },
    {
      "epoch": 8.030380611025773,
      "grad_norm": 3.5177319049835205,
      "learning_rate": 2.32431586732662e-05,
      "loss": 1.1278,
      "step": 94100
    },
    {
      "epoch": 8.038914490527393,
      "grad_norm": 3.4692330360412598,
      "learning_rate": 2.3214712408260796e-05,
      "loss": 1.1208,
      "step": 94200
    },
    {
      "epoch": 8.047448370029015,
      "grad_norm": 3.4856715202331543,
      "learning_rate": 2.318626614325539e-05,
      "loss": 1.1142,
      "step": 94300
    },
    {
      "epoch": 8.055982249530636,
      "grad_norm": 3.319122791290283,
      "learning_rate": 2.3157819878249986e-05,
      "loss": 1.1332,
      "step": 94400
    },
    {
      "epoch": 8.064516129032258,
      "grad_norm": 3.845027208328247,
      "learning_rate": 2.312937361324458e-05,
      "loss": 1.1171,
      "step": 94500
    },
    {
      "epoch": 8.07305000853388,
      "grad_norm": 3.8737621307373047,
      "learning_rate": 2.3100927348239177e-05,
      "loss": 1.1198,
      "step": 94600
    },
    {
      "epoch": 8.081583888035501,
      "grad_norm": 3.327113389968872,
      "learning_rate": 2.307248108323377e-05,
      "loss": 1.1212,
      "step": 94700
    },
    {
      "epoch": 8.090117767537123,
      "grad_norm": 3.4768388271331787,
      "learning_rate": 2.304403481822837e-05,
      "loss": 1.1185,
      "step": 94800
    },
    {
      "epoch": 8.098651647038745,
      "grad_norm": 3.516261100769043,
      "learning_rate": 2.3015873015873015e-05,
      "loss": 1.1196,
      "step": 94900
    },
    {
      "epoch": 8.107185526540365,
      "grad_norm": 3.6818630695343018,
      "learning_rate": 2.2987426750867613e-05,
      "loss": 1.1305,
      "step": 95000
    },
    {
      "epoch": 8.107185526540365,
      "eval_loss": 0.9145363569259644,
      "eval_runtime": 63.4393,
      "eval_samples_per_second": 622.17,
      "eval_steps_per_second": 77.775,
      "step": 95000
    },
    {
      "epoch": 8.115719406041986,
      "grad_norm": 3.7266924381256104,
      "learning_rate": 2.295898048586221e-05,
      "loss": 1.1199,
      "step": 95100
    },
    {
      "epoch": 8.124253285543608,
      "grad_norm": 3.662700891494751,
      "learning_rate": 2.2930534220856804e-05,
      "loss": 1.1192,
      "step": 95200
    },
    {
      "epoch": 8.13278716504523,
      "grad_norm": 3.3991706371307373,
      "learning_rate": 2.29020879558514e-05,
      "loss": 1.1189,
      "step": 95300
    },
    {
      "epoch": 8.141321044546851,
      "grad_norm": 3.672433853149414,
      "learning_rate": 2.2873641690845994e-05,
      "loss": 1.1208,
      "step": 95400
    },
    {
      "epoch": 8.149854924048473,
      "grad_norm": 3.644141912460327,
      "learning_rate": 2.284519542584059e-05,
      "loss": 1.1212,
      "step": 95500
    },
    {
      "epoch": 8.158388803550094,
      "grad_norm": 3.3611767292022705,
      "learning_rate": 2.2816749160835184e-05,
      "loss": 1.1248,
      "step": 95600
    },
    {
      "epoch": 8.166922683051716,
      "grad_norm": 3.597179889678955,
      "learning_rate": 2.278830289582978e-05,
      "loss": 1.1157,
      "step": 95700
    },
    {
      "epoch": 8.175456562553336,
      "grad_norm": 3.308095932006836,
      "learning_rate": 2.2759856630824374e-05,
      "loss": 1.1196,
      "step": 95800
    },
    {
      "epoch": 8.183990442054958,
      "grad_norm": 3.674456834793091,
      "learning_rate": 2.273141036581897e-05,
      "loss": 1.1162,
      "step": 95900
    },
    {
      "epoch": 8.19252432155658,
      "grad_norm": 3.4690260887145996,
      "learning_rate": 2.2702964100813564e-05,
      "loss": 1.1159,
      "step": 96000
    },
    {
      "epoch": 8.19252432155658,
      "eval_loss": 0.9181001782417297,
      "eval_runtime": 65.8249,
      "eval_samples_per_second": 599.621,
      "eval_steps_per_second": 74.956,
      "step": 96000
    },
    {
      "epoch": 8.201058201058201,
      "grad_norm": 3.8644707202911377,
      "learning_rate": 2.267451783580816e-05,
      "loss": 1.1348,
      "step": 96100
    },
    {
      "epoch": 8.209592080559823,
      "grad_norm": 3.509918451309204,
      "learning_rate": 2.2646071570802754e-05,
      "loss": 1.1198,
      "step": 96200
    },
    {
      "epoch": 8.218125960061444,
      "grad_norm": 3.1815974712371826,
      "learning_rate": 2.261762530579735e-05,
      "loss": 1.1154,
      "step": 96300
    },
    {
      "epoch": 8.226659839563066,
      "grad_norm": 3.3486924171447754,
      "learning_rate": 2.2589179040791944e-05,
      "loss": 1.1089,
      "step": 96400
    },
    {
      "epoch": 8.235193719064688,
      "grad_norm": 3.8630576133728027,
      "learning_rate": 2.2560732775786543e-05,
      "loss": 1.103,
      "step": 96500
    },
    {
      "epoch": 8.243727598566307,
      "grad_norm": 3.394481897354126,
      "learning_rate": 2.2532286510781138e-05,
      "loss": 1.1297,
      "step": 96600
    },
    {
      "epoch": 8.252261478067929,
      "grad_norm": 3.2211337089538574,
      "learning_rate": 2.2503840245775733e-05,
      "loss": 1.1186,
      "step": 96700
    },
    {
      "epoch": 8.26079535756955,
      "grad_norm": 3.5480518341064453,
      "learning_rate": 2.2475393980770325e-05,
      "loss": 1.129,
      "step": 96800
    },
    {
      "epoch": 8.269329237071172,
      "grad_norm": 3.983830690383911,
      "learning_rate": 2.2447232178414976e-05,
      "loss": 1.1237,
      "step": 96900
    },
    {
      "epoch": 8.277863116572794,
      "grad_norm": 3.1986937522888184,
      "learning_rate": 2.241878591340957e-05,
      "loss": 1.1069,
      "step": 97000
    },
    {
      "epoch": 8.277863116572794,
      "eval_loss": 0.9162917733192444,
      "eval_runtime": 66.4238,
      "eval_samples_per_second": 594.215,
      "eval_steps_per_second": 74.281,
      "step": 97000
    },
    {
      "epoch": 8.286396996074416,
      "grad_norm": 3.4016754627227783,
      "learning_rate": 2.2390339648404166e-05,
      "loss": 1.1198,
      "step": 97100
    },
    {
      "epoch": 8.294930875576037,
      "grad_norm": 3.3362159729003906,
      "learning_rate": 2.236189338339876e-05,
      "loss": 1.1164,
      "step": 97200
    },
    {
      "epoch": 8.303464755077659,
      "grad_norm": 3.6241750717163086,
      "learning_rate": 2.2333447118393357e-05,
      "loss": 1.1177,
      "step": 97300
    },
    {
      "epoch": 8.311998634579279,
      "grad_norm": 3.176670789718628,
      "learning_rate": 2.230500085338795e-05,
      "loss": 1.1108,
      "step": 97400
    },
    {
      "epoch": 8.3205325140809,
      "grad_norm": 3.8950228691101074,
      "learning_rate": 2.2276554588382547e-05,
      "loss": 1.1107,
      "step": 97500
    },
    {
      "epoch": 8.329066393582522,
      "grad_norm": 3.2322587966918945,
      "learning_rate": 2.2248108323377142e-05,
      "loss": 1.1151,
      "step": 97600
    },
    {
      "epoch": 8.337600273084144,
      "grad_norm": 3.5442137718200684,
      "learning_rate": 2.2219662058371737e-05,
      "loss": 1.0972,
      "step": 97700
    },
    {
      "epoch": 8.346134152585766,
      "grad_norm": 3.9666311740875244,
      "learning_rate": 2.2191215793366332e-05,
      "loss": 1.1202,
      "step": 97800
    },
    {
      "epoch": 8.354668032087387,
      "grad_norm": 3.9876763820648193,
      "learning_rate": 2.2162769528360927e-05,
      "loss": 1.1158,
      "step": 97900
    },
    {
      "epoch": 8.363201911589009,
      "grad_norm": 3.2726314067840576,
      "learning_rate": 2.2134323263355522e-05,
      "loss": 1.1116,
      "step": 98000
    },
    {
      "epoch": 8.363201911589009,
      "eval_loss": 0.9133909940719604,
      "eval_runtime": 63.7619,
      "eval_samples_per_second": 619.022,
      "eval_steps_per_second": 77.382,
      "step": 98000
    },
    {
      "epoch": 8.37173579109063,
      "grad_norm": 3.298701286315918,
      "learning_rate": 2.2105876998350117e-05,
      "loss": 1.1259,
      "step": 98100
    },
    {
      "epoch": 8.380269670592252,
      "grad_norm": 3.5715980529785156,
      "learning_rate": 2.2077430733344712e-05,
      "loss": 1.1077,
      "step": 98200
    },
    {
      "epoch": 8.388803550093872,
      "grad_norm": 3.659207582473755,
      "learning_rate": 2.204898446833931e-05,
      "loss": 1.109,
      "step": 98300
    },
    {
      "epoch": 8.397337429595494,
      "grad_norm": 3.696479320526123,
      "learning_rate": 2.2020538203333906e-05,
      "loss": 1.1269,
      "step": 98400
    },
    {
      "epoch": 8.405871309097115,
      "grad_norm": 3.5465810298919678,
      "learning_rate": 2.19920919383285e-05,
      "loss": 1.1154,
      "step": 98500
    },
    {
      "epoch": 8.414405188598737,
      "grad_norm": 3.2840569019317627,
      "learning_rate": 2.1963645673323092e-05,
      "loss": 1.1203,
      "step": 98600
    },
    {
      "epoch": 8.422939068100359,
      "grad_norm": 3.316547393798828,
      "learning_rate": 2.1935199408317687e-05,
      "loss": 1.0999,
      "step": 98700
    },
    {
      "epoch": 8.43147294760198,
      "grad_norm": 3.215733051300049,
      "learning_rate": 2.1906753143312282e-05,
      "loss": 1.1018,
      "step": 98800
    },
    {
      "epoch": 8.440006827103602,
      "grad_norm": 3.4464335441589355,
      "learning_rate": 2.1878591340956934e-05,
      "loss": 1.1065,
      "step": 98900
    },
    {
      "epoch": 8.448540706605222,
      "grad_norm": 3.529155731201172,
      "learning_rate": 2.185014507595153e-05,
      "loss": 1.1105,
      "step": 99000
    },
    {
      "epoch": 8.448540706605222,
      "eval_loss": 0.9050413370132446,
      "eval_runtime": 66.2836,
      "eval_samples_per_second": 595.471,
      "eval_steps_per_second": 74.438,
      "step": 99000
    },
    {
      "epoch": 8.457074586106843,
      "grad_norm": 3.0841050148010254,
      "learning_rate": 2.1821698810946124e-05,
      "loss": 1.1148,
      "step": 99100
    },
    {
      "epoch": 8.465608465608465,
      "grad_norm": 3.4372012615203857,
      "learning_rate": 2.179325254594072e-05,
      "loss": 1.1176,
      "step": 99200
    },
    {
      "epoch": 8.474142345110087,
      "grad_norm": 3.5351128578186035,
      "learning_rate": 2.1764806280935314e-05,
      "loss": 1.1156,
      "step": 99300
    },
    {
      "epoch": 8.482676224611708,
      "grad_norm": 3.4273464679718018,
      "learning_rate": 2.173636001592991e-05,
      "loss": 1.1137,
      "step": 99400
    },
    {
      "epoch": 8.49121010411333,
      "grad_norm": 3.212116003036499,
      "learning_rate": 2.1707913750924505e-05,
      "loss": 1.1089,
      "step": 99500
    },
    {
      "epoch": 8.499743983614952,
      "grad_norm": 3.4486703872680664,
      "learning_rate": 2.16794674859191e-05,
      "loss": 1.1128,
      "step": 99600
    },
    {
      "epoch": 8.508277863116573,
      "grad_norm": 3.4064509868621826,
      "learning_rate": 2.1651021220913695e-05,
      "loss": 1.1187,
      "step": 99700
    },
    {
      "epoch": 8.516811742618195,
      "grad_norm": 3.644655704498291,
      "learning_rate": 2.162257495590829e-05,
      "loss": 1.1134,
      "step": 99800
    },
    {
      "epoch": 8.525345622119815,
      "grad_norm": 3.856855630874634,
      "learning_rate": 2.1594128690902885e-05,
      "loss": 1.1259,
      "step": 99900
    },
    {
      "epoch": 8.533879501621437,
      "grad_norm": 4.134647846221924,
      "learning_rate": 2.156568242589748e-05,
      "loss": 1.1038,
      "step": 100000
    },
    {
      "epoch": 8.533879501621437,
      "eval_loss": 0.9101511836051941,
      "eval_runtime": 63.4758,
      "eval_samples_per_second": 621.812,
      "eval_steps_per_second": 77.73,
      "step": 100000
    },
    {
      "epoch": 8.542413381123058,
      "grad_norm": 3.653515338897705,
      "learning_rate": 2.1537236160892078e-05,
      "loss": 1.1156,
      "step": 100100
    },
    {
      "epoch": 8.55094726062468,
      "grad_norm": 3.8385372161865234,
      "learning_rate": 2.1508789895886673e-05,
      "loss": 1.1261,
      "step": 100200
    },
    {
      "epoch": 8.559481140126302,
      "grad_norm": 3.322734832763672,
      "learning_rate": 2.1480343630881265e-05,
      "loss": 1.1041,
      "step": 100300
    },
    {
      "epoch": 8.568015019627923,
      "grad_norm": 3.7428689002990723,
      "learning_rate": 2.145189736587586e-05,
      "loss": 1.1147,
      "step": 100400
    },
    {
      "epoch": 8.576548899129545,
      "grad_norm": 3.5957984924316406,
      "learning_rate": 2.1423451100870455e-05,
      "loss": 1.097,
      "step": 100500
    },
    {
      "epoch": 8.585082778631167,
      "grad_norm": 3.382004737854004,
      "learning_rate": 2.139500483586505e-05,
      "loss": 1.1259,
      "step": 100600
    },
    {
      "epoch": 8.593616658132786,
      "grad_norm": 3.2164037227630615,
      "learning_rate": 2.1366558570859645e-05,
      "loss": 1.1238,
      "step": 100700
    },
    {
      "epoch": 8.602150537634408,
      "grad_norm": 3.367550849914551,
      "learning_rate": 2.1338112305854244e-05,
      "loss": 1.1266,
      "step": 100800
    },
    {
      "epoch": 8.61068441713603,
      "grad_norm": 3.8076562881469727,
      "learning_rate": 2.1309950503498892e-05,
      "loss": 1.0988,
      "step": 100900
    },
    {
      "epoch": 8.619218296637651,
      "grad_norm": 3.906785726547241,
      "learning_rate": 2.1281504238493487e-05,
      "loss": 1.1174,
      "step": 101000
    },
    {
      "epoch": 8.619218296637651,
      "eval_loss": 0.9036284685134888,
      "eval_runtime": 64.8358,
      "eval_samples_per_second": 608.769,
      "eval_steps_per_second": 76.1,
      "step": 101000
    },
    {
      "epoch": 8.627752176139273,
      "grad_norm": 3.9307162761688232,
      "learning_rate": 2.1253057973488082e-05,
      "loss": 1.118,
      "step": 101100
    },
    {
      "epoch": 8.636286055640895,
      "grad_norm": 3.8319571018218994,
      "learning_rate": 2.1224611708482677e-05,
      "loss": 1.1062,
      "step": 101200
    },
    {
      "epoch": 8.644819935142516,
      "grad_norm": 3.3577897548675537,
      "learning_rate": 2.1196165443477272e-05,
      "loss": 1.1055,
      "step": 101300
    },
    {
      "epoch": 8.653353814644138,
      "grad_norm": 3.7019550800323486,
      "learning_rate": 2.1167719178471867e-05,
      "loss": 1.1264,
      "step": 101400
    },
    {
      "epoch": 8.661887694145758,
      "grad_norm": 3.6823315620422363,
      "learning_rate": 2.1139272913466462e-05,
      "loss": 1.1167,
      "step": 101500
    },
    {
      "epoch": 8.67042157364738,
      "grad_norm": 3.58853816986084,
      "learning_rate": 2.1110826648461057e-05,
      "loss": 1.0941,
      "step": 101600
    },
    {
      "epoch": 8.678955453149001,
      "grad_norm": 3.393497943878174,
      "learning_rate": 2.1082380383455653e-05,
      "loss": 1.1078,
      "step": 101700
    },
    {
      "epoch": 8.687489332650623,
      "grad_norm": 3.3490278720855713,
      "learning_rate": 2.105393411845025e-05,
      "loss": 1.1147,
      "step": 101800
    },
    {
      "epoch": 8.696023212152244,
      "grad_norm": 3.5051794052124023,
      "learning_rate": 2.1025487853444846e-05,
      "loss": 1.1021,
      "step": 101900
    },
    {
      "epoch": 8.704557091653866,
      "grad_norm": 3.7359793186187744,
      "learning_rate": 2.099704158843944e-05,
      "loss": 1.103,
      "step": 102000
    },
    {
      "epoch": 8.704557091653866,
      "eval_loss": 0.9069210290908813,
      "eval_runtime": 66.5831,
      "eval_samples_per_second": 592.793,
      "eval_steps_per_second": 74.103,
      "step": 102000
    },
    {
      "epoch": 8.713090971155488,
      "grad_norm": 3.7449631690979004,
      "learning_rate": 2.0968595323434033e-05,
      "loss": 1.1126,
      "step": 102100
    },
    {
      "epoch": 8.72162485065711,
      "grad_norm": 3.744904041290283,
      "learning_rate": 2.0940149058428628e-05,
      "loss": 1.1216,
      "step": 102200
    },
    {
      "epoch": 8.73015873015873,
      "grad_norm": 3.3138365745544434,
      "learning_rate": 2.0911702793423223e-05,
      "loss": 1.1118,
      "step": 102300
    },
    {
      "epoch": 8.738692609660351,
      "grad_norm": 3.369210720062256,
      "learning_rate": 2.0883256528417818e-05,
      "loss": 1.1055,
      "step": 102400
    },
    {
      "epoch": 8.747226489161973,
      "grad_norm": 3.59649395942688,
      "learning_rate": 2.0854810263412413e-05,
      "loss": 1.1159,
      "step": 102500
    },
    {
      "epoch": 8.755760368663594,
      "grad_norm": 3.5273189544677734,
      "learning_rate": 2.082636399840701e-05,
      "loss": 1.1079,
      "step": 102600
    },
    {
      "epoch": 8.764294248165216,
      "grad_norm": 3.3710994720458984,
      "learning_rate": 2.0797917733401607e-05,
      "loss": 1.1135,
      "step": 102700
    },
    {
      "epoch": 8.772828127666838,
      "grad_norm": 3.7643582820892334,
      "learning_rate": 2.07694714683962e-05,
      "loss": 1.1036,
      "step": 102800
    },
    {
      "epoch": 8.78136200716846,
      "grad_norm": 3.9942567348480225,
      "learning_rate": 2.074130966604085e-05,
      "loss": 1.1027,
      "step": 102900
    },
    {
      "epoch": 8.789895886670081,
      "grad_norm": 4.111598968505859,
      "learning_rate": 2.0712863401035445e-05,
      "loss": 1.1076,
      "step": 103000
    },
    {
      "epoch": 8.789895886670081,
      "eval_loss": 0.8970772624015808,
      "eval_runtime": 66.9032,
      "eval_samples_per_second": 589.957,
      "eval_steps_per_second": 73.748,
      "step": 103000
    },
    {
      "epoch": 8.7984297661717,
      "grad_norm": 3.4529175758361816,
      "learning_rate": 2.068441713603004e-05,
      "loss": 1.1033,
      "step": 103100
    },
    {
      "epoch": 8.806963645673322,
      "grad_norm": 3.3306384086608887,
      "learning_rate": 2.0655970871024635e-05,
      "loss": 1.1035,
      "step": 103200
    },
    {
      "epoch": 8.815497525174944,
      "grad_norm": 3.7265496253967285,
      "learning_rate": 2.062752460601923e-05,
      "loss": 1.1094,
      "step": 103300
    },
    {
      "epoch": 8.824031404676566,
      "grad_norm": 3.5221364498138428,
      "learning_rate": 2.0599078341013825e-05,
      "loss": 1.1073,
      "step": 103400
    },
    {
      "epoch": 8.832565284178187,
      "grad_norm": 3.2800240516662598,
      "learning_rate": 2.057063207600842e-05,
      "loss": 1.1123,
      "step": 103500
    },
    {
      "epoch": 8.841099163679809,
      "grad_norm": 3.7288005352020264,
      "learning_rate": 2.054218581100302e-05,
      "loss": 1.1096,
      "step": 103600
    },
    {
      "epoch": 8.84963304318143,
      "grad_norm": 4.049788475036621,
      "learning_rate": 2.0513739545997614e-05,
      "loss": 1.0935,
      "step": 103700
    },
    {
      "epoch": 8.858166922683052,
      "grad_norm": 3.7209112644195557,
      "learning_rate": 2.0485293280992205e-05,
      "loss": 1.1052,
      "step": 103800
    },
    {
      "epoch": 8.866700802184674,
      "grad_norm": 4.114773273468018,
      "learning_rate": 2.04568470159868e-05,
      "loss": 1.1215,
      "step": 103900
    },
    {
      "epoch": 8.875234681686294,
      "grad_norm": 3.3884525299072266,
      "learning_rate": 2.0428400750981396e-05,
      "loss": 1.1153,
      "step": 104000
    },
    {
      "epoch": 8.875234681686294,
      "eval_loss": 0.9084514379501343,
      "eval_runtime": 64.1832,
      "eval_samples_per_second": 614.958,
      "eval_steps_per_second": 76.874,
      "step": 104000
    },
    {
      "epoch": 8.883768561187916,
      "grad_norm": 3.7912774085998535,
      "learning_rate": 2.039995448597599e-05,
      "loss": 1.0987,
      "step": 104100
    },
    {
      "epoch": 8.892302440689537,
      "grad_norm": 3.3235886096954346,
      "learning_rate": 2.0371508220970586e-05,
      "loss": 1.1068,
      "step": 104200
    },
    {
      "epoch": 8.900836320191159,
      "grad_norm": 3.403388023376465,
      "learning_rate": 2.034306195596518e-05,
      "loss": 1.1031,
      "step": 104300
    },
    {
      "epoch": 8.90937019969278,
      "grad_norm": 3.434617757797241,
      "learning_rate": 2.031461569095978e-05,
      "loss": 1.1199,
      "step": 104400
    },
    {
      "epoch": 8.917904079194402,
      "grad_norm": 3.640507698059082,
      "learning_rate": 2.0286169425954374e-05,
      "loss": 1.0967,
      "step": 104500
    },
    {
      "epoch": 8.926437958696024,
      "grad_norm": 4.094884872436523,
      "learning_rate": 2.025772316094897e-05,
      "loss": 1.1082,
      "step": 104600
    },
    {
      "epoch": 8.934971838197644,
      "grad_norm": 3.418980360031128,
      "learning_rate": 2.0229276895943564e-05,
      "loss": 1.0926,
      "step": 104700
    },
    {
      "epoch": 8.943505717699265,
      "grad_norm": 3.579408645629883,
      "learning_rate": 2.020083063093816e-05,
      "loss": 1.1033,
      "step": 104800
    },
    {
      "epoch": 8.952039597200887,
      "grad_norm": 3.5585105419158936,
      "learning_rate": 2.0172668828582808e-05,
      "loss": 1.0998,
      "step": 104900
    },
    {
      "epoch": 8.960573476702509,
      "grad_norm": 3.505952835083008,
      "learning_rate": 2.0144222563577403e-05,
      "loss": 1.1116,
      "step": 105000
    },
    {
      "epoch": 8.960573476702509,
      "eval_loss": 0.898962140083313,
      "eval_runtime": 65.3304,
      "eval_samples_per_second": 604.16,
      "eval_steps_per_second": 75.524,
      "step": 105000
    },
    {
      "epoch": 8.96910735620413,
      "grad_norm": 3.68992280960083,
      "learning_rate": 2.0115776298571998e-05,
      "loss": 1.108,
      "step": 105100
    },
    {
      "epoch": 8.977641235705752,
      "grad_norm": 3.4474666118621826,
      "learning_rate": 2.0087330033566593e-05,
      "loss": 1.1085,
      "step": 105200
    },
    {
      "epoch": 8.986175115207374,
      "grad_norm": 3.4819958209991455,
      "learning_rate": 2.005888376856119e-05,
      "loss": 1.108,
      "step": 105300
    },
    {
      "epoch": 8.994708994708995,
      "grad_norm": 3.4373810291290283,
      "learning_rate": 2.0030437503555786e-05,
      "loss": 1.1066,
      "step": 105400
    },
    {
      "epoch": 9.003242874210617,
      "grad_norm": 3.5726401805877686,
      "learning_rate": 2.000199123855038e-05,
      "loss": 1.1004,
      "step": 105500
    },
    {
      "epoch": 9.011776753712237,
      "grad_norm": 3.3587749004364014,
      "learning_rate": 1.9973544973544973e-05,
      "loss": 1.0957,
      "step": 105600
    },
    {
      "epoch": 9.020310633213859,
      "grad_norm": 3.440786361694336,
      "learning_rate": 1.9945383171189625e-05,
      "loss": 1.1108,
      "step": 105700
    },
    {
      "epoch": 9.02884451271548,
      "grad_norm": 3.5561447143554688,
      "learning_rate": 1.991693690618422e-05,
      "loss": 1.1007,
      "step": 105800
    },
    {
      "epoch": 9.037378392217102,
      "grad_norm": 3.3445122241973877,
      "learning_rate": 1.9888490641178815e-05,
      "loss": 1.1144,
      "step": 105900
    },
    {
      "epoch": 9.045912271718723,
      "grad_norm": 3.0594921112060547,
      "learning_rate": 1.986004437617341e-05,
      "loss": 1.0976,
      "step": 106000
    },
    {
      "epoch": 9.045912271718723,
      "eval_loss": 0.8986230492591858,
      "eval_runtime": 64.5635,
      "eval_samples_per_second": 611.336,
      "eval_steps_per_second": 76.421,
      "step": 106000
    },
    {
      "epoch": 9.054446151220345,
      "grad_norm": 3.3135507106781006,
      "learning_rate": 1.9831598111168005e-05,
      "loss": 1.0962,
      "step": 106100
    },
    {
      "epoch": 9.062980030721967,
      "grad_norm": 3.6480281352996826,
      "learning_rate": 1.98031518461626e-05,
      "loss": 1.1079,
      "step": 106200
    },
    {
      "epoch": 9.071513910223588,
      "grad_norm": 3.4048938751220703,
      "learning_rate": 1.9774705581157195e-05,
      "loss": 1.1015,
      "step": 106300
    },
    {
      "epoch": 9.080047789725208,
      "grad_norm": 3.6965630054473877,
      "learning_rate": 1.974625931615179e-05,
      "loss": 1.0989,
      "step": 106400
    },
    {
      "epoch": 9.08858166922683,
      "grad_norm": 3.396019220352173,
      "learning_rate": 1.9717813051146385e-05,
      "loss": 1.101,
      "step": 106500
    },
    {
      "epoch": 9.097115548728452,
      "grad_norm": 3.7406797409057617,
      "learning_rate": 1.968936678614098e-05,
      "loss": 1.0885,
      "step": 106600
    },
    {
      "epoch": 9.105649428230073,
      "grad_norm": 3.59902286529541,
      "learning_rate": 1.9660920521135576e-05,
      "loss": 1.0971,
      "step": 106700
    },
    {
      "epoch": 9.114183307731695,
      "grad_norm": 3.6565239429473877,
      "learning_rate": 1.963247425613017e-05,
      "loss": 1.1075,
      "step": 106800
    },
    {
      "epoch": 9.122717187233317,
      "grad_norm": 3.0460500717163086,
      "learning_rate": 1.9604027991124766e-05,
      "loss": 1.1119,
      "step": 106900
    },
    {
      "epoch": 9.131251066734938,
      "grad_norm": 3.1419179439544678,
      "learning_rate": 1.957558172611936e-05,
      "loss": 1.1076,
      "step": 107000
    },
    {
      "epoch": 9.131251066734938,
      "eval_loss": 0.8952913284301758,
      "eval_runtime": 65.2357,
      "eval_samples_per_second": 605.037,
      "eval_steps_per_second": 75.633,
      "step": 107000
    },
    {
      "epoch": 9.13978494623656,
      "grad_norm": 3.247995376586914,
      "learning_rate": 1.954713546111396e-05,
      "loss": 1.0952,
      "step": 107100
    },
    {
      "epoch": 9.14831882573818,
      "grad_norm": 3.3736257553100586,
      "learning_rate": 1.9518689196108554e-05,
      "loss": 1.1035,
      "step": 107200
    },
    {
      "epoch": 9.156852705239801,
      "grad_norm": 3.347438097000122,
      "learning_rate": 1.9490242931103146e-05,
      "loss": 1.096,
      "step": 107300
    },
    {
      "epoch": 9.165386584741423,
      "grad_norm": 3.6263082027435303,
      "learning_rate": 1.946179666609774e-05,
      "loss": 1.0964,
      "step": 107400
    },
    {
      "epoch": 9.173920464243045,
      "grad_norm": 3.473003387451172,
      "learning_rate": 1.9433350401092336e-05,
      "loss": 1.0995,
      "step": 107500
    },
    {
      "epoch": 9.182454343744666,
      "grad_norm": 3.3410117626190186,
      "learning_rate": 1.940490413608693e-05,
      "loss": 1.0996,
      "step": 107600
    },
    {
      "epoch": 9.190988223246288,
      "grad_norm": 3.762380838394165,
      "learning_rate": 1.9376457871081526e-05,
      "loss": 1.1042,
      "step": 107700
    },
    {
      "epoch": 9.19952210274791,
      "grad_norm": 3.3324341773986816,
      "learning_rate": 1.934801160607612e-05,
      "loss": 1.1058,
      "step": 107800
    },
    {
      "epoch": 9.208055982249531,
      "grad_norm": 3.9079504013061523,
      "learning_rate": 1.931956534107072e-05,
      "loss": 1.1001,
      "step": 107900
    },
    {
      "epoch": 9.216589861751151,
      "grad_norm": 3.76845645904541,
      "learning_rate": 1.9291119076065315e-05,
      "loss": 1.1073,
      "step": 108000
    },
    {
      "epoch": 9.216589861751151,
      "eval_loss": 0.8940559029579163,
      "eval_runtime": 64.9829,
      "eval_samples_per_second": 607.39,
      "eval_steps_per_second": 75.928,
      "step": 108000
    },
    {
      "epoch": 9.225123741252773,
      "grad_norm": 3.6449520587921143,
      "learning_rate": 1.926267281105991e-05,
      "loss": 1.1052,
      "step": 108100
    },
    {
      "epoch": 9.233657620754395,
      "grad_norm": 3.3062589168548584,
      "learning_rate": 1.9234226546054505e-05,
      "loss": 1.095,
      "step": 108200
    },
    {
      "epoch": 9.242191500256016,
      "grad_norm": 3.5189144611358643,
      "learning_rate": 1.92057802810491e-05,
      "loss": 1.1032,
      "step": 108300
    },
    {
      "epoch": 9.250725379757638,
      "grad_norm": 3.498610496520996,
      "learning_rate": 1.9177334016043695e-05,
      "loss": 1.1032,
      "step": 108400
    },
    {
      "epoch": 9.25925925925926,
      "grad_norm": 3.436903476715088,
      "learning_rate": 1.914888775103829e-05,
      "loss": 1.0952,
      "step": 108500
    },
    {
      "epoch": 9.267793138760881,
      "grad_norm": 3.2576704025268555,
      "learning_rate": 1.9120441486032885e-05,
      "loss": 1.0883,
      "step": 108600
    },
    {
      "epoch": 9.276327018262503,
      "grad_norm": 3.5320611000061035,
      "learning_rate": 1.909199522102748e-05,
      "loss": 1.1014,
      "step": 108700
    },
    {
      "epoch": 9.284860897764123,
      "grad_norm": 3.5368387699127197,
      "learning_rate": 1.9063548956022075e-05,
      "loss": 1.092,
      "step": 108800
    },
    {
      "epoch": 9.293394777265744,
      "grad_norm": 3.178285598754883,
      "learning_rate": 1.903510269101667e-05,
      "loss": 1.0959,
      "step": 108900
    },
    {
      "epoch": 9.301928656767366,
      "grad_norm": 3.7307794094085693,
      "learning_rate": 1.9006656426011265e-05,
      "loss": 1.0953,
      "step": 109000
    },
    {
      "epoch": 9.301928656767366,
      "eval_loss": 0.8952474594116211,
      "eval_runtime": 65.1378,
      "eval_samples_per_second": 605.946,
      "eval_steps_per_second": 75.747,
      "step": 109000
    },
    {
      "epoch": 9.310462536268988,
      "grad_norm": 3.2186059951782227,
      "learning_rate": 1.897821016100586e-05,
      "loss": 1.0943,
      "step": 109100
    },
    {
      "epoch": 9.31899641577061,
      "grad_norm": 3.9649064540863037,
      "learning_rate": 1.8949763896000455e-05,
      "loss": 1.1133,
      "step": 109200
    },
    {
      "epoch": 9.327530295272231,
      "grad_norm": 3.6365532875061035,
      "learning_rate": 1.892131763099505e-05,
      "loss": 1.0987,
      "step": 109300
    },
    {
      "epoch": 9.336064174773853,
      "grad_norm": 3.4051570892333984,
      "learning_rate": 1.889287136598965e-05,
      "loss": 1.093,
      "step": 109400
    },
    {
      "epoch": 9.344598054275474,
      "grad_norm": 3.640988826751709,
      "learning_rate": 1.8864425100984244e-05,
      "loss": 1.0828,
      "step": 109500
    },
    {
      "epoch": 9.353131933777096,
      "grad_norm": 3.4961531162261963,
      "learning_rate": 1.883597883597884e-05,
      "loss": 1.1065,
      "step": 109600
    },
    {
      "epoch": 9.361665813278716,
      "grad_norm": 3.6998484134674072,
      "learning_rate": 1.8807817033623487e-05,
      "loss": 1.091,
      "step": 109700
    },
    {
      "epoch": 9.370199692780337,
      "grad_norm": 3.4848382472991943,
      "learning_rate": 1.8779370768618082e-05,
      "loss": 1.1012,
      "step": 109800
    },
    {
      "epoch": 9.37873357228196,
      "grad_norm": 3.8552558422088623,
      "learning_rate": 1.8750924503612678e-05,
      "loss": 1.097,
      "step": 109900
    },
    {
      "epoch": 9.38726745178358,
      "grad_norm": 3.7999584674835205,
      "learning_rate": 1.8722478238607273e-05,
      "loss": 1.111,
      "step": 110000
    },
    {
      "epoch": 9.38726745178358,
      "eval_loss": 0.8948847651481628,
      "eval_runtime": 64.8114,
      "eval_samples_per_second": 608.998,
      "eval_steps_per_second": 76.129,
      "step": 110000
    },
    {
      "epoch": 9.395801331285202,
      "grad_norm": 3.73335862159729,
      "learning_rate": 1.8694031973601868e-05,
      "loss": 1.085,
      "step": 110100
    },
    {
      "epoch": 9.404335210786824,
      "grad_norm": 3.6200385093688965,
      "learning_rate": 1.8665585708596463e-05,
      "loss": 1.1026,
      "step": 110200
    },
    {
      "epoch": 9.412869090288446,
      "grad_norm": 3.377516984939575,
      "learning_rate": 1.8637139443591058e-05,
      "loss": 1.0846,
      "step": 110300
    },
    {
      "epoch": 9.421402969790067,
      "grad_norm": 3.607876777648926,
      "learning_rate": 1.8608693178585653e-05,
      "loss": 1.0999,
      "step": 110400
    },
    {
      "epoch": 9.429936849291687,
      "grad_norm": 3.8329999446868896,
      "learning_rate": 1.8580246913580248e-05,
      "loss": 1.0967,
      "step": 110500
    },
    {
      "epoch": 9.438470728793309,
      "grad_norm": 3.4416630268096924,
      "learning_rate": 1.8551800648574843e-05,
      "loss": 1.1013,
      "step": 110600
    },
    {
      "epoch": 9.44700460829493,
      "grad_norm": 3.9437613487243652,
      "learning_rate": 1.8523354383569438e-05,
      "loss": 1.0968,
      "step": 110700
    },
    {
      "epoch": 9.455538487796552,
      "grad_norm": 3.3167123794555664,
      "learning_rate": 1.8494908118564033e-05,
      "loss": 1.0968,
      "step": 110800
    },
    {
      "epoch": 9.464072367298174,
      "grad_norm": 3.7338743209838867,
      "learning_rate": 1.8466461853558628e-05,
      "loss": 1.0981,
      "step": 110900
    },
    {
      "epoch": 9.472606246799796,
      "grad_norm": 3.63552188873291,
      "learning_rate": 1.8438015588553223e-05,
      "loss": 1.0896,
      "step": 111000
    },
    {
      "epoch": 9.472606246799796,
      "eval_loss": 0.8860325217247009,
      "eval_runtime": 64.3309,
      "eval_samples_per_second": 613.546,
      "eval_steps_per_second": 76.697,
      "step": 111000
    },
    {
      "epoch": 9.481140126301417,
      "grad_norm": 3.8264193534851074,
      "learning_rate": 1.8409569323547818e-05,
      "loss": 1.0987,
      "step": 111100
    },
    {
      "epoch": 9.489674005803039,
      "grad_norm": 3.323981523513794,
      "learning_rate": 1.8381123058542417e-05,
      "loss": 1.1009,
      "step": 111200
    },
    {
      "epoch": 9.498207885304659,
      "grad_norm": 3.695324659347534,
      "learning_rate": 1.8352676793537012e-05,
      "loss": 1.0897,
      "step": 111300
    },
    {
      "epoch": 9.50674176480628,
      "grad_norm": 3.370992660522461,
      "learning_rate": 1.8324230528531607e-05,
      "loss": 1.0982,
      "step": 111400
    },
    {
      "epoch": 9.515275644307902,
      "grad_norm": 3.3550798892974854,
      "learning_rate": 1.82957842635262e-05,
      "loss": 1.0956,
      "step": 111500
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 3.4784467220306396,
      "learning_rate": 1.8267337998520794e-05,
      "loss": 1.0888,
      "step": 111600
    },
    {
      "epoch": 9.532343403311145,
      "grad_norm": 3.577665090560913,
      "learning_rate": 1.823889173351539e-05,
      "loss": 1.1035,
      "step": 111700
    },
    {
      "epoch": 9.540877282812767,
      "grad_norm": 3.316112995147705,
      "learning_rate": 1.821072993116004e-05,
      "loss": 1.0958,
      "step": 111800
    },
    {
      "epoch": 9.549411162314389,
      "grad_norm": 3.3398094177246094,
      "learning_rate": 1.8182283666154635e-05,
      "loss": 1.0953,
      "step": 111900
    },
    {
      "epoch": 9.55794504181601,
      "grad_norm": 3.79012131690979,
      "learning_rate": 1.815383740114923e-05,
      "loss": 1.1096,
      "step": 112000
    },
    {
      "epoch": 9.55794504181601,
      "eval_loss": 0.8867492079734802,
      "eval_runtime": 64.9401,
      "eval_samples_per_second": 607.791,
      "eval_steps_per_second": 75.978,
      "step": 112000
    },
    {
      "epoch": 9.56647892131763,
      "grad_norm": 3.1866884231567383,
      "learning_rate": 1.8125391136143826e-05,
      "loss": 1.0982,
      "step": 112100
    },
    {
      "epoch": 9.575012800819252,
      "grad_norm": 3.641355037689209,
      "learning_rate": 1.809694487113842e-05,
      "loss": 1.0953,
      "step": 112200
    },
    {
      "epoch": 9.583546680320874,
      "grad_norm": 3.5088746547698975,
      "learning_rate": 1.8068498606133016e-05,
      "loss": 1.0865,
      "step": 112300
    },
    {
      "epoch": 9.592080559822495,
      "grad_norm": 3.9294052124023438,
      "learning_rate": 1.804005234112761e-05,
      "loss": 1.0941,
      "step": 112400
    },
    {
      "epoch": 9.600614439324117,
      "grad_norm": 3.753202199935913,
      "learning_rate": 1.8011606076122206e-05,
      "loss": 1.0837,
      "step": 112500
    },
    {
      "epoch": 9.609148318825738,
      "grad_norm": 3.258836030960083,
      "learning_rate": 1.79831598111168e-05,
      "loss": 1.0981,
      "step": 112600
    },
    {
      "epoch": 9.61768219832736,
      "grad_norm": 3.7152719497680664,
      "learning_rate": 1.7954713546111396e-05,
      "loss": 1.0927,
      "step": 112700
    },
    {
      "epoch": 9.626216077828982,
      "grad_norm": 3.4235599040985107,
      "learning_rate": 1.792626728110599e-05,
      "loss": 1.0949,
      "step": 112800
    },
    {
      "epoch": 9.634749957330602,
      "grad_norm": 3.068549633026123,
      "learning_rate": 1.7897821016100586e-05,
      "loss": 1.0918,
      "step": 112900
    },
    {
      "epoch": 9.643283836832223,
      "grad_norm": 3.5534863471984863,
      "learning_rate": 1.7869374751095184e-05,
      "loss": 1.0912,
      "step": 113000
    },
    {
      "epoch": 9.643283836832223,
      "eval_loss": 0.8877887725830078,
      "eval_runtime": 66.7554,
      "eval_samples_per_second": 591.263,
      "eval_steps_per_second": 73.912,
      "step": 113000
    },
    {
      "epoch": 9.651817716333845,
      "grad_norm": 4.034995079040527,
      "learning_rate": 1.784092848608978e-05,
      "loss": 1.0949,
      "step": 113100
    },
    {
      "epoch": 9.660351595835467,
      "grad_norm": 3.49526047706604,
      "learning_rate": 1.781248222108437e-05,
      "loss": 1.0873,
      "step": 113200
    },
    {
      "epoch": 9.668885475337088,
      "grad_norm": 3.2227847576141357,
      "learning_rate": 1.7784035956078966e-05,
      "loss": 1.0823,
      "step": 113300
    },
    {
      "epoch": 9.67741935483871,
      "grad_norm": 3.5015323162078857,
      "learning_rate": 1.775558969107356e-05,
      "loss": 1.1059,
      "step": 113400
    },
    {
      "epoch": 9.685953234340332,
      "grad_norm": 3.569777488708496,
      "learning_rate": 1.7727143426068156e-05,
      "loss": 1.0954,
      "step": 113500
    },
    {
      "epoch": 9.694487113841953,
      "grad_norm": 3.1885299682617188,
      "learning_rate": 1.769869716106275e-05,
      "loss": 1.0892,
      "step": 113600
    },
    {
      "epoch": 9.703020993343575,
      "grad_norm": 3.386185884475708,
      "learning_rate": 1.767025089605735e-05,
      "loss": 1.0894,
      "step": 113700
    },
    {
      "epoch": 9.711554872845195,
      "grad_norm": 3.8538472652435303,
      "learning_rate": 1.7642089093701998e-05,
      "loss": 1.0863,
      "step": 113800
    },
    {
      "epoch": 9.720088752346816,
      "grad_norm": 3.7735490798950195,
      "learning_rate": 1.7613642828696593e-05,
      "loss": 1.097,
      "step": 113900
    },
    {
      "epoch": 9.728622631848438,
      "grad_norm": 3.591777801513672,
      "learning_rate": 1.758519656369119e-05,
      "loss": 1.0807,
      "step": 114000
    },
    {
      "epoch": 9.728622631848438,
      "eval_loss": 0.8841206431388855,
      "eval_runtime": 62.8962,
      "eval_samples_per_second": 627.542,
      "eval_steps_per_second": 78.447,
      "step": 114000
    },
    {
      "epoch": 9.73715651135006,
      "grad_norm": 4.044203281402588,
      "learning_rate": 1.7556750298685783e-05,
      "loss": 1.0997,
      "step": 114100
    },
    {
      "epoch": 9.745690390851681,
      "grad_norm": 3.3992018699645996,
      "learning_rate": 1.752830403368038e-05,
      "loss": 1.083,
      "step": 114200
    },
    {
      "epoch": 9.754224270353303,
      "grad_norm": 3.756216049194336,
      "learning_rate": 1.7499857768674974e-05,
      "loss": 1.0771,
      "step": 114300
    },
    {
      "epoch": 9.762758149854925,
      "grad_norm": 3.7251060009002686,
      "learning_rate": 1.747141150366957e-05,
      "loss": 1.0966,
      "step": 114400
    },
    {
      "epoch": 9.771292029356545,
      "grad_norm": 3.538442850112915,
      "learning_rate": 1.7442965238664164e-05,
      "loss": 1.0869,
      "step": 114500
    },
    {
      "epoch": 9.779825908858166,
      "grad_norm": 3.566516399383545,
      "learning_rate": 1.741451897365876e-05,
      "loss": 1.086,
      "step": 114600
    },
    {
      "epoch": 9.788359788359788,
      "grad_norm": 3.4653894901275635,
      "learning_rate": 1.7386072708653357e-05,
      "loss": 1.0743,
      "step": 114700
    },
    {
      "epoch": 9.79689366786141,
      "grad_norm": 3.2068252563476562,
      "learning_rate": 1.7357626443647952e-05,
      "loss": 1.0898,
      "step": 114800
    },
    {
      "epoch": 9.805427547363031,
      "grad_norm": 3.8769121170043945,
      "learning_rate": 1.7329180178642547e-05,
      "loss": 1.0763,
      "step": 114900
    },
    {
      "epoch": 9.813961426864653,
      "grad_norm": 3.7228028774261475,
      "learning_rate": 1.730073391363714e-05,
      "loss": 1.0858,
      "step": 115000
    },
    {
      "epoch": 9.813961426864653,
      "eval_loss": 0.8840302228927612,
      "eval_runtime": 64.8187,
      "eval_samples_per_second": 608.929,
      "eval_steps_per_second": 76.12,
      "step": 115000
    },
    {
      "epoch": 9.822495306366275,
      "grad_norm": 3.4203081130981445,
      "learning_rate": 1.7272287648631734e-05,
      "loss": 1.0898,
      "step": 115100
    },
    {
      "epoch": 9.831029185867896,
      "grad_norm": 3.6249747276306152,
      "learning_rate": 1.724384138362633e-05,
      "loss": 1.0939,
      "step": 115200
    },
    {
      "epoch": 9.839563065369518,
      "grad_norm": 3.753450393676758,
      "learning_rate": 1.7215395118620924e-05,
      "loss": 1.0991,
      "step": 115300
    },
    {
      "epoch": 9.848096944871138,
      "grad_norm": 3.251760482788086,
      "learning_rate": 1.718694885361552e-05,
      "loss": 1.0744,
      "step": 115400
    },
    {
      "epoch": 9.85663082437276,
      "grad_norm": 3.8180923461914062,
      "learning_rate": 1.7158502588610118e-05,
      "loss": 1.1041,
      "step": 115500
    },
    {
      "epoch": 9.865164703874381,
      "grad_norm": 3.6627230644226074,
      "learning_rate": 1.7130056323604713e-05,
      "loss": 1.0901,
      "step": 115600
    },
    {
      "epoch": 9.873698583376003,
      "grad_norm": 3.8564443588256836,
      "learning_rate": 1.7101610058599308e-05,
      "loss": 1.0943,
      "step": 115700
    },
    {
      "epoch": 9.882232462877624,
      "grad_norm": 3.086364507675171,
      "learning_rate": 1.7073448256243956e-05,
      "loss": 1.0992,
      "step": 115800
    },
    {
      "epoch": 9.890766342379246,
      "grad_norm": 3.6318137645721436,
      "learning_rate": 1.704500199123855e-05,
      "loss": 1.0945,
      "step": 115900
    },
    {
      "epoch": 9.899300221880868,
      "grad_norm": 3.38574481010437,
      "learning_rate": 1.7016555726233146e-05,
      "loss": 1.0883,
      "step": 116000
    },
    {
      "epoch": 9.899300221880868,
      "eval_loss": 0.8822036385536194,
      "eval_runtime": 66.0998,
      "eval_samples_per_second": 597.127,
      "eval_steps_per_second": 74.645,
      "step": 116000
    },
    {
      "epoch": 9.907834101382488,
      "grad_norm": 3.5153326988220215,
      "learning_rate": 1.698810946122774e-05,
      "loss": 1.0833,
      "step": 116100
    },
    {
      "epoch": 9.91636798088411,
      "grad_norm": 3.640556812286377,
      "learning_rate": 1.6959663196222336e-05,
      "loss": 1.1034,
      "step": 116200
    },
    {
      "epoch": 9.92490186038573,
      "grad_norm": 3.5282328128814697,
      "learning_rate": 1.693121693121693e-05,
      "loss": 1.1055,
      "step": 116300
    },
    {
      "epoch": 9.933435739887353,
      "grad_norm": 3.95158052444458,
      "learning_rate": 1.6902770666211526e-05,
      "loss": 1.096,
      "step": 116400
    },
    {
      "epoch": 9.941969619388974,
      "grad_norm": 3.054635524749756,
      "learning_rate": 1.6874324401206125e-05,
      "loss": 1.0694,
      "step": 116500
    },
    {
      "epoch": 9.950503498890596,
      "grad_norm": 3.7057385444641113,
      "learning_rate": 1.684587813620072e-05,
      "loss": 1.0817,
      "step": 116600
    },
    {
      "epoch": 9.959037378392217,
      "grad_norm": 3.3638508319854736,
      "learning_rate": 1.681743187119531e-05,
      "loss": 1.0956,
      "step": 116700
    },
    {
      "epoch": 9.96757125789384,
      "grad_norm": 3.688567876815796,
      "learning_rate": 1.6788985606189907e-05,
      "loss": 1.0869,
      "step": 116800
    },
    {
      "epoch": 9.97610513739546,
      "grad_norm": 3.7335941791534424,
      "learning_rate": 1.6760539341184502e-05,
      "loss": 1.0901,
      "step": 116900
    },
    {
      "epoch": 9.98463901689708,
      "grad_norm": 4.265102386474609,
      "learning_rate": 1.6732093076179097e-05,
      "loss": 1.0788,
      "step": 117000
    },
    {
      "epoch": 9.98463901689708,
      "eval_loss": 0.8861629366874695,
      "eval_runtime": 66.2435,
      "eval_samples_per_second": 595.832,
      "eval_steps_per_second": 74.483,
      "step": 117000
    },
    {
      "epoch": 9.993172896398702,
      "grad_norm": 3.660125255584717,
      "learning_rate": 1.6703646811173692e-05,
      "loss": 1.0977,
      "step": 117100
    },
    {
      "epoch": 10.001706775900324,
      "grad_norm": 3.619915723800659,
      "learning_rate": 1.6675200546168287e-05,
      "loss": 1.0912,
      "step": 117200
    },
    {
      "epoch": 10.010240655401946,
      "grad_norm": 3.4919981956481934,
      "learning_rate": 1.6646754281162885e-05,
      "loss": 1.0876,
      "step": 117300
    },
    {
      "epoch": 10.018774534903567,
      "grad_norm": 3.6070144176483154,
      "learning_rate": 1.661830801615748e-05,
      "loss": 1.0953,
      "step": 117400
    },
    {
      "epoch": 10.027308414405189,
      "grad_norm": 3.752042055130005,
      "learning_rate": 1.6589861751152075e-05,
      "loss": 1.0844,
      "step": 117500
    },
    {
      "epoch": 10.03584229390681,
      "grad_norm": 3.8161518573760986,
      "learning_rate": 1.656141548614667e-05,
      "loss": 1.0767,
      "step": 117600
    },
    {
      "epoch": 10.044376173408432,
      "grad_norm": 3.4310736656188965,
      "learning_rate": 1.6532969221141266e-05,
      "loss": 1.0896,
      "step": 117700
    },
    {
      "epoch": 10.052910052910052,
      "grad_norm": 3.5619914531707764,
      "learning_rate": 1.6504807418785914e-05,
      "loss": 1.0687,
      "step": 117800
    },
    {
      "epoch": 10.061443932411674,
      "grad_norm": 3.722576379776001,
      "learning_rate": 1.647636115378051e-05,
      "loss": 1.0805,
      "step": 117900
    },
    {
      "epoch": 10.069977811913295,
      "grad_norm": 3.296687364578247,
      "learning_rate": 1.6447914888775104e-05,
      "loss": 1.0829,
      "step": 118000
    },
    {
      "epoch": 10.069977811913295,
      "eval_loss": 0.8817278146743774,
      "eval_runtime": 64.9057,
      "eval_samples_per_second": 608.113,
      "eval_steps_per_second": 76.018,
      "step": 118000
    },
    {
      "epoch": 10.078511691414917,
      "grad_norm": 3.371011972427368,
      "learning_rate": 1.64194686237697e-05,
      "loss": 1.0824,
      "step": 118100
    },
    {
      "epoch": 10.087045570916539,
      "grad_norm": 3.4824776649475098,
      "learning_rate": 1.6391022358764298e-05,
      "loss": 1.0895,
      "step": 118200
    },
    {
      "epoch": 10.09557945041816,
      "grad_norm": 3.408923625946045,
      "learning_rate": 1.6362576093758893e-05,
      "loss": 1.0999,
      "step": 118300
    },
    {
      "epoch": 10.104113329919782,
      "grad_norm": 3.5112030506134033,
      "learning_rate": 1.6334129828753488e-05,
      "loss": 1.0948,
      "step": 118400
    },
    {
      "epoch": 10.112647209421404,
      "grad_norm": 3.366642713546753,
      "learning_rate": 1.630568356374808e-05,
      "loss": 1.0831,
      "step": 118500
    },
    {
      "epoch": 10.121181088923024,
      "grad_norm": 3.7529385089874268,
      "learning_rate": 1.6277237298742674e-05,
      "loss": 1.0859,
      "step": 118600
    },
    {
      "epoch": 10.129714968424645,
      "grad_norm": 3.9311201572418213,
      "learning_rate": 1.624879103373727e-05,
      "loss": 1.0864,
      "step": 118700
    },
    {
      "epoch": 10.138248847926267,
      "grad_norm": 3.10505747795105,
      "learning_rate": 1.6220344768731865e-05,
      "loss": 1.0931,
      "step": 118800
    },
    {
      "epoch": 10.146782727427889,
      "grad_norm": 3.153470993041992,
      "learning_rate": 1.619189850372646e-05,
      "loss": 1.0928,
      "step": 118900
    },
    {
      "epoch": 10.15531660692951,
      "grad_norm": 3.82195782661438,
      "learning_rate": 1.6163452238721058e-05,
      "loss": 1.0895,
      "step": 119000
    },
    {
      "epoch": 10.15531660692951,
      "eval_loss": 0.8838801383972168,
      "eval_runtime": 65.6979,
      "eval_samples_per_second": 600.781,
      "eval_steps_per_second": 75.101,
      "step": 119000
    },
    {
      "epoch": 10.163850486431132,
      "grad_norm": 3.424555540084839,
      "learning_rate": 1.6135005973715653e-05,
      "loss": 1.0762,
      "step": 119100
    },
    {
      "epoch": 10.172384365932754,
      "grad_norm": 3.538400888442993,
      "learning_rate": 1.6106559708710248e-05,
      "loss": 1.0961,
      "step": 119200
    },
    {
      "epoch": 10.180918245434375,
      "grad_norm": 3.0982367992401123,
      "learning_rate": 1.6078113443704843e-05,
      "loss": 1.082,
      "step": 119300
    },
    {
      "epoch": 10.189452124935995,
      "grad_norm": 3.7905311584472656,
      "learning_rate": 1.6049667178699438e-05,
      "loss": 1.0932,
      "step": 119400
    },
    {
      "epoch": 10.197986004437617,
      "grad_norm": 3.5934574604034424,
      "learning_rate": 1.6021220913694033e-05,
      "loss": 1.0788,
      "step": 119500
    },
    {
      "epoch": 10.206519883939238,
      "grad_norm": 3.5517547130584717,
      "learning_rate": 1.599277464868863e-05,
      "loss": 1.092,
      "step": 119600
    },
    {
      "epoch": 10.21505376344086,
      "grad_norm": 3.811263084411621,
      "learning_rate": 1.5964328383683223e-05,
      "loss": 1.0935,
      "step": 119700
    },
    {
      "epoch": 10.223587642942482,
      "grad_norm": 3.566589593887329,
      "learning_rate": 1.5936166581327872e-05,
      "loss": 1.0925,
      "step": 119800
    },
    {
      "epoch": 10.232121522444103,
      "grad_norm": 3.5659894943237305,
      "learning_rate": 1.5907720316322467e-05,
      "loss": 1.096,
      "step": 119900
    },
    {
      "epoch": 10.240655401945725,
      "grad_norm": 3.585129737854004,
      "learning_rate": 1.5879274051317065e-05,
      "loss": 1.0856,
      "step": 120000
    },
    {
      "epoch": 10.240655401945725,
      "eval_loss": 0.882739782333374,
      "eval_runtime": 65.2997,
      "eval_samples_per_second": 604.444,
      "eval_steps_per_second": 75.559,
      "step": 120000
    },
    {
      "epoch": 10.249189281447347,
      "grad_norm": 3.6134085655212402,
      "learning_rate": 1.585082778631166e-05,
      "loss": 1.0889,
      "step": 120100
    },
    {
      "epoch": 10.257723160948967,
      "grad_norm": 3.6021878719329834,
      "learning_rate": 1.5822381521306252e-05,
      "loss": 1.0886,
      "step": 120200
    },
    {
      "epoch": 10.266257040450588,
      "grad_norm": 3.2383954524993896,
      "learning_rate": 1.5793935256300847e-05,
      "loss": 1.0886,
      "step": 120300
    },
    {
      "epoch": 10.27479091995221,
      "grad_norm": 3.276719331741333,
      "learning_rate": 1.5765488991295442e-05,
      "loss": 1.0905,
      "step": 120400
    },
    {
      "epoch": 10.283324799453831,
      "grad_norm": 3.285889148712158,
      "learning_rate": 1.5737042726290037e-05,
      "loss": 1.0873,
      "step": 120500
    },
    {
      "epoch": 10.291858678955453,
      "grad_norm": 3.7033708095550537,
      "learning_rate": 1.5708596461284632e-05,
      "loss": 1.0798,
      "step": 120600
    },
    {
      "epoch": 10.300392558457075,
      "grad_norm": 3.862762928009033,
      "learning_rate": 1.5680150196279227e-05,
      "loss": 1.1005,
      "step": 120700
    },
    {
      "epoch": 10.308926437958696,
      "grad_norm": 3.6443049907684326,
      "learning_rate": 1.5651703931273826e-05,
      "loss": 1.0837,
      "step": 120800
    },
    {
      "epoch": 10.317460317460318,
      "grad_norm": 3.6710045337677,
      "learning_rate": 1.562325766626842e-05,
      "loss": 1.0983,
      "step": 120900
    },
    {
      "epoch": 10.32599419696194,
      "grad_norm": 3.853344440460205,
      "learning_rate": 1.5594811401263016e-05,
      "loss": 1.1029,
      "step": 121000
    },
    {
      "epoch": 10.32599419696194,
      "eval_loss": 0.8818438053131104,
      "eval_runtime": 65.0849,
      "eval_samples_per_second": 606.439,
      "eval_steps_per_second": 75.809,
      "step": 121000
    },
    {
      "epoch": 10.33452807646356,
      "grad_norm": 3.8559529781341553,
      "learning_rate": 1.556636513625761e-05,
      "loss": 1.085,
      "step": 121100
    },
    {
      "epoch": 10.343061955965181,
      "grad_norm": 3.358565330505371,
      "learning_rate": 1.5537918871252206e-05,
      "loss": 1.0836,
      "step": 121200
    },
    {
      "epoch": 10.351595835466803,
      "grad_norm": 3.997887372970581,
      "learning_rate": 1.55094726062468e-05,
      "loss": 1.0733,
      "step": 121300
    },
    {
      "epoch": 10.360129714968425,
      "grad_norm": 3.8295888900756836,
      "learning_rate": 1.5481026341241396e-05,
      "loss": 1.0851,
      "step": 121400
    },
    {
      "epoch": 10.368663594470046,
      "grad_norm": 3.5390963554382324,
      "learning_rate": 1.545258007623599e-05,
      "loss": 1.0909,
      "step": 121500
    },
    {
      "epoch": 10.377197473971668,
      "grad_norm": 4.633728981018066,
      "learning_rate": 1.5424133811230586e-05,
      "loss": 1.0913,
      "step": 121600
    },
    {
      "epoch": 10.38573135347329,
      "grad_norm": 3.824427604675293,
      "learning_rate": 1.539568754622518e-05,
      "loss": 1.0691,
      "step": 121700
    },
    {
      "epoch": 10.394265232974911,
      "grad_norm": 3.7398948669433594,
      "learning_rate": 1.5367525743869833e-05,
      "loss": 1.0775,
      "step": 121800
    },
    {
      "epoch": 10.402799112476531,
      "grad_norm": 3.5672037601470947,
      "learning_rate": 1.5339079478864428e-05,
      "loss": 1.0867,
      "step": 121900
    },
    {
      "epoch": 10.411332991978153,
      "grad_norm": 3.2026102542877197,
      "learning_rate": 1.531063321385902e-05,
      "loss": 1.071,
      "step": 122000
    },
    {
      "epoch": 10.411332991978153,
      "eval_loss": 0.8818615078926086,
      "eval_runtime": 65.0521,
      "eval_samples_per_second": 606.744,
      "eval_steps_per_second": 75.847,
      "step": 122000
    },
    {
      "epoch": 10.419866871479774,
      "grad_norm": 3.4043023586273193,
      "learning_rate": 1.5282186948853615e-05,
      "loss": 1.0746,
      "step": 122100
    },
    {
      "epoch": 10.428400750981396,
      "grad_norm": 3.568560838699341,
      "learning_rate": 1.5253740683848212e-05,
      "loss": 1.0782,
      "step": 122200
    },
    {
      "epoch": 10.436934630483018,
      "grad_norm": 3.289768695831299,
      "learning_rate": 1.5225294418842807e-05,
      "loss": 1.0929,
      "step": 122300
    },
    {
      "epoch": 10.44546850998464,
      "grad_norm": 3.676786422729492,
      "learning_rate": 1.51968481538374e-05,
      "loss": 1.0751,
      "step": 122400
    },
    {
      "epoch": 10.454002389486261,
      "grad_norm": 3.5198662281036377,
      "learning_rate": 1.5168401888831999e-05,
      "loss": 1.0848,
      "step": 122500
    },
    {
      "epoch": 10.462536268987883,
      "grad_norm": 3.938913106918335,
      "learning_rate": 1.5139955623826594e-05,
      "loss": 1.0906,
      "step": 122600
    },
    {
      "epoch": 10.471070148489503,
      "grad_norm": 3.617802143096924,
      "learning_rate": 1.5111509358821189e-05,
      "loss": 1.0753,
      "step": 122700
    },
    {
      "epoch": 10.479604027991124,
      "grad_norm": 3.581655263900757,
      "learning_rate": 1.5083063093815784e-05,
      "loss": 1.0799,
      "step": 122800
    },
    {
      "epoch": 10.488137907492746,
      "grad_norm": 4.12092399597168,
      "learning_rate": 1.5054616828810377e-05,
      "loss": 1.0902,
      "step": 122900
    },
    {
      "epoch": 10.496671786994368,
      "grad_norm": 4.229060173034668,
      "learning_rate": 1.5026170563804972e-05,
      "loss": 1.0807,
      "step": 123000
    },
    {
      "epoch": 10.496671786994368,
      "eval_loss": 0.8837265372276306,
      "eval_runtime": 65.6457,
      "eval_samples_per_second": 601.258,
      "eval_steps_per_second": 75.161,
      "step": 123000
    },
    {
      "epoch": 10.50520566649599,
      "grad_norm": 3.085632562637329,
      "learning_rate": 1.4997724298799567e-05,
      "loss": 1.0749,
      "step": 123100
    },
    {
      "epoch": 10.51373954599761,
      "grad_norm": 3.386660099029541,
      "learning_rate": 1.4969278033794162e-05,
      "loss": 1.0777,
      "step": 123200
    },
    {
      "epoch": 10.522273425499233,
      "grad_norm": 3.7377612590789795,
      "learning_rate": 1.494083176878876e-05,
      "loss": 1.0831,
      "step": 123300
    },
    {
      "epoch": 10.530807305000854,
      "grad_norm": 3.378129243850708,
      "learning_rate": 1.4912385503783354e-05,
      "loss": 1.0853,
      "step": 123400
    },
    {
      "epoch": 10.539341184502474,
      "grad_norm": 3.757077932357788,
      "learning_rate": 1.4883939238777949e-05,
      "loss": 1.0846,
      "step": 123500
    },
    {
      "epoch": 10.547875064004096,
      "grad_norm": 3.5088770389556885,
      "learning_rate": 1.4855492973772544e-05,
      "loss": 1.0743,
      "step": 123600
    },
    {
      "epoch": 10.556408943505717,
      "grad_norm": 3.9199581146240234,
      "learning_rate": 1.482704670876714e-05,
      "loss": 1.0721,
      "step": 123700
    },
    {
      "epoch": 10.564942823007339,
      "grad_norm": 3.478426933288574,
      "learning_rate": 1.479888490641179e-05,
      "loss": 1.0793,
      "step": 123800
    },
    {
      "epoch": 10.57347670250896,
      "grad_norm": 3.4261019229888916,
      "learning_rate": 1.4770438641406384e-05,
      "loss": 1.0894,
      "step": 123900
    },
    {
      "epoch": 10.582010582010582,
      "grad_norm": 3.366255521774292,
      "learning_rate": 1.474199237640098e-05,
      "loss": 1.085,
      "step": 124000
    },
    {
      "epoch": 10.582010582010582,
      "eval_loss": 0.8757357001304626,
      "eval_runtime": 65.2519,
      "eval_samples_per_second": 604.887,
      "eval_steps_per_second": 75.615,
      "step": 124000
    },
    {
      "epoch": 10.590544461512204,
      "grad_norm": 4.0474853515625,
      "learning_rate": 1.4713546111395573e-05,
      "loss": 1.0739,
      "step": 124100
    },
    {
      "epoch": 10.599078341013826,
      "grad_norm": 3.5783450603485107,
      "learning_rate": 1.4685099846390168e-05,
      "loss": 1.0832,
      "step": 124200
    },
    {
      "epoch": 10.607612220515446,
      "grad_norm": 3.595076322555542,
      "learning_rate": 1.4656653581384766e-05,
      "loss": 1.0755,
      "step": 124300
    },
    {
      "epoch": 10.616146100017067,
      "grad_norm": 3.394686222076416,
      "learning_rate": 1.4628207316379361e-05,
      "loss": 1.0791,
      "step": 124400
    },
    {
      "epoch": 10.624679979518689,
      "grad_norm": 3.5917835235595703,
      "learning_rate": 1.4599761051373956e-05,
      "loss": 1.0891,
      "step": 124500
    },
    {
      "epoch": 10.63321385902031,
      "grad_norm": 3.274186372756958,
      "learning_rate": 1.4571314786368551e-05,
      "loss": 1.0961,
      "step": 124600
    },
    {
      "epoch": 10.641747738521932,
      "grad_norm": 3.866182804107666,
      "learning_rate": 1.4542868521363145e-05,
      "loss": 1.08,
      "step": 124700
    },
    {
      "epoch": 10.650281618023554,
      "grad_norm": 3.643622398376465,
      "learning_rate": 1.451442225635774e-05,
      "loss": 1.0724,
      "step": 124800
    },
    {
      "epoch": 10.658815497525175,
      "grad_norm": 3.74761700630188,
      "learning_rate": 1.4485975991352335e-05,
      "loss": 1.0776,
      "step": 124900
    },
    {
      "epoch": 10.667349377026797,
      "grad_norm": 3.481273889541626,
      "learning_rate": 1.445752972634693e-05,
      "loss": 1.0818,
      "step": 125000
    },
    {
      "epoch": 10.667349377026797,
      "eval_loss": 0.878314733505249,
      "eval_runtime": 65.9915,
      "eval_samples_per_second": 598.107,
      "eval_steps_per_second": 74.767,
      "step": 125000
    },
    {
      "epoch": 10.675883256528419,
      "grad_norm": 3.451335906982422,
      "learning_rate": 1.4429083461341528e-05,
      "loss": 1.0898,
      "step": 125100
    },
    {
      "epoch": 10.684417136030039,
      "grad_norm": 3.503373861312866,
      "learning_rate": 1.4400637196336122e-05,
      "loss": 1.0878,
      "step": 125200
    },
    {
      "epoch": 10.69295101553166,
      "grad_norm": 3.67707896232605,
      "learning_rate": 1.4372190931330717e-05,
      "loss": 1.0822,
      "step": 125300
    },
    {
      "epoch": 10.701484895033282,
      "grad_norm": 3.988072156906128,
      "learning_rate": 1.4343744666325312e-05,
      "loss": 1.0781,
      "step": 125400
    },
    {
      "epoch": 10.710018774534904,
      "grad_norm": 3.6836118698120117,
      "learning_rate": 1.4315298401319907e-05,
      "loss": 1.0573,
      "step": 125500
    },
    {
      "epoch": 10.718552654036525,
      "grad_norm": 3.945317268371582,
      "learning_rate": 1.4286852136314502e-05,
      "loss": 1.0889,
      "step": 125600
    },
    {
      "epoch": 10.727086533538147,
      "grad_norm": 4.577735424041748,
      "learning_rate": 1.4258405871309097e-05,
      "loss": 1.0936,
      "step": 125700
    },
    {
      "epoch": 10.735620413039769,
      "grad_norm": 4.055166721343994,
      "learning_rate": 1.4230244068953747e-05,
      "loss": 1.08,
      "step": 125800
    },
    {
      "epoch": 10.744154292541388,
      "grad_norm": 3.509368419647217,
      "learning_rate": 1.420179780394834e-05,
      "loss": 1.0835,
      "step": 125900
    },
    {
      "epoch": 10.75268817204301,
      "grad_norm": 3.8092997074127197,
      "learning_rate": 1.4173351538942936e-05,
      "loss": 1.0866,
      "step": 126000
    },
    {
      "epoch": 10.75268817204301,
      "eval_loss": 0.8790099620819092,
      "eval_runtime": 65.3554,
      "eval_samples_per_second": 603.929,
      "eval_steps_per_second": 75.495,
      "step": 126000
    },
    {
      "epoch": 10.761222051544632,
      "grad_norm": 3.913485527038574,
      "learning_rate": 1.4144905273937534e-05,
      "loss": 1.0802,
      "step": 126100
    },
    {
      "epoch": 10.769755931046253,
      "grad_norm": 3.933441400527954,
      "learning_rate": 1.4116459008932129e-05,
      "loss": 1.0689,
      "step": 126200
    },
    {
      "epoch": 10.778289810547875,
      "grad_norm": 3.221773862838745,
      "learning_rate": 1.4088012743926724e-05,
      "loss": 1.0742,
      "step": 126300
    },
    {
      "epoch": 10.786823690049497,
      "grad_norm": 3.3444089889526367,
      "learning_rate": 1.4059566478921318e-05,
      "loss": 1.0884,
      "step": 126400
    },
    {
      "epoch": 10.795357569551118,
      "grad_norm": 4.037327766418457,
      "learning_rate": 1.4031120213915913e-05,
      "loss": 1.0863,
      "step": 126500
    },
    {
      "epoch": 10.80389144905274,
      "grad_norm": 3.65579891204834,
      "learning_rate": 1.4002673948910508e-05,
      "loss": 1.0846,
      "step": 126600
    },
    {
      "epoch": 10.812425328554362,
      "grad_norm": 3.731783151626587,
      "learning_rate": 1.3974227683905103e-05,
      "loss": 1.081,
      "step": 126700
    },
    {
      "epoch": 10.820959208055982,
      "grad_norm": 3.612927198410034,
      "learning_rate": 1.3945781418899701e-05,
      "loss": 1.0793,
      "step": 126800
    },
    {
      "epoch": 10.829493087557603,
      "grad_norm": 3.562283992767334,
      "learning_rate": 1.3917335153894294e-05,
      "loss": 1.0629,
      "step": 126900
    },
    {
      "epoch": 10.838026967059225,
      "grad_norm": 3.1168010234832764,
      "learning_rate": 1.388888888888889e-05,
      "loss": 1.0774,
      "step": 127000
    },
    {
      "epoch": 10.838026967059225,
      "eval_loss": 0.8684071898460388,
      "eval_runtime": 64.0854,
      "eval_samples_per_second": 615.897,
      "eval_steps_per_second": 76.991,
      "step": 127000
    },
    {
      "epoch": 10.846560846560847,
      "grad_norm": 3.5781469345092773,
      "learning_rate": 1.3860442623883485e-05,
      "loss": 1.085,
      "step": 127100
    },
    {
      "epoch": 10.855094726062468,
      "grad_norm": 3.722046136856079,
      "learning_rate": 1.383199635887808e-05,
      "loss": 1.0751,
      "step": 127200
    },
    {
      "epoch": 10.86362860556409,
      "grad_norm": 3.466226577758789,
      "learning_rate": 1.3803550093872675e-05,
      "loss": 1.0837,
      "step": 127300
    },
    {
      "epoch": 10.872162485065711,
      "grad_norm": 3.558330774307251,
      "learning_rate": 1.377510382886727e-05,
      "loss": 1.0576,
      "step": 127400
    },
    {
      "epoch": 10.880696364567333,
      "grad_norm": 3.490818738937378,
      "learning_rate": 1.3746657563861865e-05,
      "loss": 1.0757,
      "step": 127500
    },
    {
      "epoch": 10.889230244068953,
      "grad_norm": 4.045575141906738,
      "learning_rate": 1.3718211298856462e-05,
      "loss": 1.0777,
      "step": 127600
    },
    {
      "epoch": 10.897764123570575,
      "grad_norm": 3.3839402198791504,
      "learning_rate": 1.3689765033851057e-05,
      "loss": 1.072,
      "step": 127700
    },
    {
      "epoch": 10.906298003072196,
      "grad_norm": 3.530306339263916,
      "learning_rate": 1.3661603231495707e-05,
      "loss": 1.078,
      "step": 127800
    },
    {
      "epoch": 10.914831882573818,
      "grad_norm": 3.722928524017334,
      "learning_rate": 1.3633156966490302e-05,
      "loss": 1.0678,
      "step": 127900
    },
    {
      "epoch": 10.92336576207544,
      "grad_norm": 4.151193141937256,
      "learning_rate": 1.3604710701484897e-05,
      "loss": 1.0726,
      "step": 128000
    },
    {
      "epoch": 10.92336576207544,
      "eval_loss": 0.867986261844635,
      "eval_runtime": 65.8792,
      "eval_samples_per_second": 599.127,
      "eval_steps_per_second": 74.895,
      "step": 128000
    },
    {
      "epoch": 10.931899641577061,
      "grad_norm": 3.7803213596343994,
      "learning_rate": 1.3576264436479492e-05,
      "loss": 1.0728,
      "step": 128100
    },
    {
      "epoch": 10.940433521078683,
      "grad_norm": 3.563490390777588,
      "learning_rate": 1.3547818171474085e-05,
      "loss": 1.0878,
      "step": 128200
    },
    {
      "epoch": 10.948967400580305,
      "grad_norm": 3.6566402912139893,
      "learning_rate": 1.351937190646868e-05,
      "loss": 1.0703,
      "step": 128300
    },
    {
      "epoch": 10.957501280081924,
      "grad_norm": 3.680929183959961,
      "learning_rate": 1.3490925641463275e-05,
      "loss": 1.0828,
      "step": 128400
    },
    {
      "epoch": 10.966035159583546,
      "grad_norm": 4.0344719886779785,
      "learning_rate": 1.346247937645787e-05,
      "loss": 1.0783,
      "step": 128500
    },
    {
      "epoch": 10.974569039085168,
      "grad_norm": 3.605314254760742,
      "learning_rate": 1.3434033111452469e-05,
      "loss": 1.0668,
      "step": 128600
    },
    {
      "epoch": 10.98310291858679,
      "grad_norm": 3.711576223373413,
      "learning_rate": 1.3405586846447062e-05,
      "loss": 1.0875,
      "step": 128700
    },
    {
      "epoch": 10.991636798088411,
      "grad_norm": 3.317910671234131,
      "learning_rate": 1.3377140581441657e-05,
      "loss": 1.081,
      "step": 128800
    },
    {
      "epoch": 11.000170677590033,
      "grad_norm": 3.7987918853759766,
      "learning_rate": 1.3348694316436252e-05,
      "loss": 1.0674,
      "step": 128900
    },
    {
      "epoch": 11.008704557091654,
      "grad_norm": 3.5385470390319824,
      "learning_rate": 1.3320248051430847e-05,
      "loss": 1.067,
      "step": 129000
    },
    {
      "epoch": 11.008704557091654,
      "eval_loss": 0.8708816766738892,
      "eval_runtime": 63.4609,
      "eval_samples_per_second": 621.958,
      "eval_steps_per_second": 77.749,
      "step": 129000
    },
    {
      "epoch": 11.017238436593276,
      "grad_norm": 3.7211523056030273,
      "learning_rate": 1.3291801786425442e-05,
      "loss": 1.0755,
      "step": 129100
    },
    {
      "epoch": 11.025772316094896,
      "grad_norm": 3.9236841201782227,
      "learning_rate": 1.3263355521420038e-05,
      "loss": 1.0777,
      "step": 129200
    },
    {
      "epoch": 11.034306195596518,
      "grad_norm": 3.923322916030884,
      "learning_rate": 1.3234909256414633e-05,
      "loss": 1.0773,
      "step": 129300
    },
    {
      "epoch": 11.04284007509814,
      "grad_norm": 3.4258389472961426,
      "learning_rate": 1.320646299140923e-05,
      "loss": 1.0843,
      "step": 129400
    },
    {
      "epoch": 11.051373954599761,
      "grad_norm": 3.645617723464966,
      "learning_rate": 1.3178016726403824e-05,
      "loss": 1.0824,
      "step": 129500
    },
    {
      "epoch": 11.059907834101383,
      "grad_norm": 3.7548904418945312,
      "learning_rate": 1.314957046139842e-05,
      "loss": 1.0709,
      "step": 129600
    },
    {
      "epoch": 11.068441713603004,
      "grad_norm": 3.6917967796325684,
      "learning_rate": 1.3121124196393015e-05,
      "loss": 1.0744,
      "step": 129700
    },
    {
      "epoch": 11.076975593104626,
      "grad_norm": 3.55682110786438,
      "learning_rate": 1.3092962394037665e-05,
      "loss": 1.0848,
      "step": 129800
    },
    {
      "epoch": 11.085509472606248,
      "grad_norm": 3.4947471618652344,
      "learning_rate": 1.3064516129032258e-05,
      "loss": 1.0662,
      "step": 129900
    },
    {
      "epoch": 11.094043352107867,
      "grad_norm": 3.343496322631836,
      "learning_rate": 1.3036069864026853e-05,
      "loss": 1.074,
      "step": 130000
    },
    {
      "epoch": 11.094043352107867,
      "eval_loss": 0.8715682029724121,
      "eval_runtime": 64.2053,
      "eval_samples_per_second": 614.747,
      "eval_steps_per_second": 76.847,
      "step": 130000
    },
    {
      "epoch": 11.102577231609489,
      "grad_norm": 3.4201619625091553,
      "learning_rate": 1.3007623599021448e-05,
      "loss": 1.0687,
      "step": 130100
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 4.0414862632751465,
      "learning_rate": 1.2979177334016043e-05,
      "loss": 1.0804,
      "step": 130200
    },
    {
      "epoch": 11.119644990612732,
      "grad_norm": 3.8097083568573,
      "learning_rate": 1.2950731069010638e-05,
      "loss": 1.0773,
      "step": 130300
    },
    {
      "epoch": 11.128178870114354,
      "grad_norm": 3.73236346244812,
      "learning_rate": 1.2922284804005235e-05,
      "loss": 1.0696,
      "step": 130400
    },
    {
      "epoch": 11.136712749615976,
      "grad_norm": 3.3772566318511963,
      "learning_rate": 1.289383853899983e-05,
      "loss": 1.072,
      "step": 130500
    },
    {
      "epoch": 11.145246629117597,
      "grad_norm": 3.1792123317718506,
      "learning_rate": 1.2865392273994425e-05,
      "loss": 1.0793,
      "step": 130600
    },
    {
      "epoch": 11.153780508619219,
      "grad_norm": 3.3580307960510254,
      "learning_rate": 1.283694600898902e-05,
      "loss": 1.0735,
      "step": 130700
    },
    {
      "epoch": 11.162314388120839,
      "grad_norm": 3.912321090698242,
      "learning_rate": 1.2808499743983615e-05,
      "loss": 1.0771,
      "step": 130800
    },
    {
      "epoch": 11.17084826762246,
      "grad_norm": 4.158100128173828,
      "learning_rate": 1.278005347897821e-05,
      "loss": 1.0639,
      "step": 130900
    },
    {
      "epoch": 11.179382147124082,
      "grad_norm": 3.7036166191101074,
      "learning_rate": 1.2751607213972805e-05,
      "loss": 1.0869,
      "step": 131000
    },
    {
      "epoch": 11.179382147124082,
      "eval_loss": 0.8735742568969727,
      "eval_runtime": 65.776,
      "eval_samples_per_second": 600.067,
      "eval_steps_per_second": 75.012,
      "step": 131000
    },
    {
      "epoch": 11.187916026625704,
      "grad_norm": 3.9632747173309326,
      "learning_rate": 1.2723160948967402e-05,
      "loss": 1.0824,
      "step": 131100
    },
    {
      "epoch": 11.196449906127325,
      "grad_norm": 3.618447780609131,
      "learning_rate": 1.2694714683961997e-05,
      "loss": 1.0673,
      "step": 131200
    },
    {
      "epoch": 11.204983785628947,
      "grad_norm": 3.599203586578369,
      "learning_rate": 1.2666268418956592e-05,
      "loss": 1.0797,
      "step": 131300
    },
    {
      "epoch": 11.213517665130569,
      "grad_norm": 3.275146722793579,
      "learning_rate": 1.2637822153951187e-05,
      "loss": 1.0735,
      "step": 131400
    },
    {
      "epoch": 11.22205154463219,
      "grad_norm": 3.8933751583099365,
      "learning_rate": 1.2609375888945782e-05,
      "loss": 1.076,
      "step": 131500
    },
    {
      "epoch": 11.23058542413381,
      "grad_norm": 3.6641299724578857,
      "learning_rate": 1.2580929623940377e-05,
      "loss": 1.0775,
      "step": 131600
    },
    {
      "epoch": 11.239119303635432,
      "grad_norm": 3.532184362411499,
      "learning_rate": 1.2552483358934972e-05,
      "loss": 1.0599,
      "step": 131700
    },
    {
      "epoch": 11.247653183137054,
      "grad_norm": 3.5904805660247803,
      "learning_rate": 1.252432155657962e-05,
      "loss": 1.0812,
      "step": 131800
    },
    {
      "epoch": 11.256187062638675,
      "grad_norm": 4.211766242980957,
      "learning_rate": 1.2495875291574218e-05,
      "loss": 1.084,
      "step": 131900
    },
    {
      "epoch": 11.264720942140297,
      "grad_norm": 3.7562475204467773,
      "learning_rate": 1.2467429026568813e-05,
      "loss": 1.0726,
      "step": 132000
    },
    {
      "epoch": 11.264720942140297,
      "eval_loss": 0.8686715960502625,
      "eval_runtime": 66.6181,
      "eval_samples_per_second": 592.482,
      "eval_steps_per_second": 74.064,
      "step": 132000
    },
    {
      "epoch": 11.273254821641919,
      "grad_norm": 3.5477471351623535,
      "learning_rate": 1.2438982761563408e-05,
      "loss": 1.0676,
      "step": 132100
    },
    {
      "epoch": 11.28178870114354,
      "grad_norm": 3.4214210510253906,
      "learning_rate": 1.2410536496558003e-05,
      "loss": 1.0755,
      "step": 132200
    },
    {
      "epoch": 11.290322580645162,
      "grad_norm": 3.627126693725586,
      "learning_rate": 1.2382090231552598e-05,
      "loss": 1.0674,
      "step": 132300
    },
    {
      "epoch": 11.298856460146784,
      "grad_norm": 3.993116617202759,
      "learning_rate": 1.2353643966547193e-05,
      "loss": 1.0702,
      "step": 132400
    },
    {
      "epoch": 11.307390339648403,
      "grad_norm": 3.6553077697753906,
      "learning_rate": 1.2325197701541788e-05,
      "loss": 1.0855,
      "step": 132500
    },
    {
      "epoch": 11.315924219150025,
      "grad_norm": 3.732982873916626,
      "learning_rate": 1.2296751436536383e-05,
      "loss": 1.0682,
      "step": 132600
    },
    {
      "epoch": 11.324458098651647,
      "grad_norm": 3.365415573120117,
      "learning_rate": 1.226830517153098e-05,
      "loss": 1.0761,
      "step": 132700
    },
    {
      "epoch": 11.332991978153268,
      "grad_norm": 3.350527286529541,
      "learning_rate": 1.2239858906525575e-05,
      "loss": 1.0579,
      "step": 132800
    },
    {
      "epoch": 11.34152585765489,
      "grad_norm": 3.5741214752197266,
      "learning_rate": 1.2211412641520168e-05,
      "loss": 1.0692,
      "step": 132900
    },
    {
      "epoch": 11.350059737156512,
      "grad_norm": 3.7589111328125,
      "learning_rate": 1.2182966376514763e-05,
      "loss": 1.0658,
      "step": 133000
    },
    {
      "epoch": 11.350059737156512,
      "eval_loss": 0.8670433759689331,
      "eval_runtime": 66.7147,
      "eval_samples_per_second": 591.624,
      "eval_steps_per_second": 73.957,
      "step": 133000
    }
  ],
  "logging_steps": 100,
  "max_steps": 175770,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.008703032723538e+17,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
